import gradio as gr
import torch
from PIL import Image
import time
import openvino as ov
from transformers.utils.chat_template_utils import render_jinja_template
from ov_paddleocr_vl import OVPaddleOCRVLForCausalLM
from image_processing_paddleocr_vl import PaddleOCRVLImageProcessor
import requests
from pathlib import Path
from urllib.parse import urlparse
import os

# åœ¨å¯¼å…¥åç«‹å³è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œé¿å…Gradioåˆå§‹åŒ–æ—¶çš„ç½‘ç»œè¯·æ±‚
os.environ.setdefault("GRADIO_ANALYTICS_ENABLED", "False")
os.environ.setdefault("GRADIO_SERVER_NAME", "127.0.0.1")
os.environ.setdefault("NO_PROXY", "127.0.0.1,localhost")
os.environ.setdefault("no_proxy", "127.0.0.1,localhost")

# å…¨å±€å˜é‡
paddleocr_vl_model = None
my_preprocessor = None

# ä»»åŠ¡æç¤ºè¯
PROMPTS = {
    "ocr": "OCR:",
    "table": "Table Recognition:",
    "formula": "Formula Recognition:",
    "chart": "Chart Recognition:",
}

# Chatæ¨¡æ¿ï¼ˆä»chat_template.jinjaæ–‡ä»¶è¯»å–ï¼‰
CHAT_TEMPLATE = '''{%- if not add_generation_prompt is defined -%}
    {%- set add_generation_prompt = true -%}
{%- endif -%}
{%- if not cls_token is defined -%}
    {%- set cls_token = "<|begin_of_sentence|>" -%}
{%- endif -%}
{%- if not eos_token is defined -%}
    {%- set eos_token = "</s>" -%}
{%- endif -%}
{%- if not image_token is defined -%}
    {%- set image_token = "<|IMAGE_START|><|IMAGE_PLACEHOLDER|><|IMAGE_END|>" -%}
{%- endif -%}
{{- cls_token -}}
{%- for message in messages -%}
    {%- if message["role"] == "user" -%}
        {{- "User: " -}}
        {%- for content in message["content"] -%}
            {%- if content["type"] == "image" -%}
                {{ image_token }}
            {%- endif -%}
        {%- endfor -%}
        {%- for content in message["content"] -%}
            {%- if content["type"] == "text" -%}
                {{ content["text"] }}
            {%- endif -%}
        {%- endfor -%}
        {{ "\\n" -}}
    {%- elif message["role"] == "assistant" -%}
        {{- "Assistant: " -}}
        {%- for content in message["content"] -%}
            {%- if content["type"] == "text" -%}
                {{ content["text"] }}
            {%- endif -%}
        {%- endfor -%}
        {{ eos_token -}}
    {%- elif message["role"] == "system" -%}
        {%- for content in message["content"] -%}
            {%- if content["type"] == "text" -%}
                {{ content["text"] + "\\n" }}
            {%- endif -%}
        {%- endfor -%}
    {%- endif -%}
{%- endfor -%}
{%- if add_generation_prompt -%}
    {{- "Assistant: " -}}
{%- endif -%}'''

def load_chat_template(template_path=None):
    """åŠ è½½chatæ¨¡æ¿"""
    global CHAT_TEMPLATE
    if template_path:
        try:
            with open(template_path, 'r', encoding='utf-8') as f:
                CHAT_TEMPLATE = f.read()
            return f"âœ… å·²ä»æ–‡ä»¶åŠ è½½æ¨¡æ¿: {template_path}"
        except Exception as e:
            return f"âŒ åŠ è½½æ¨¡æ¿å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿"
    return "ä½¿ç”¨é»˜è®¤æ¨¡æ¿"

def initialize_model(ov_model_path="./ov_paddleocr_vl_model", 
                     device_type="GPU", 
                     llm_int4_compress=False, 
                     vision_int8_quant=False, 
                     llm_int8_quant=False,
                     template_path=None):
    """åˆå§‹åŒ–æ¨¡å‹"""
    global paddleocr_vl_model, my_preprocessor
    
    try:
        # åŠ è½½chatæ¨¡æ¿
        if template_path:
            load_chat_template(template_path)
        
        # åˆå§‹åŒ–OpenVINOæ¨¡å‹
        core = ov.Core()
        llm_infer_list = []
        vision_infer = []
        
        paddleocr_vl_model = OVPaddleOCRVLForCausalLM(
            core=core,
            ov_model_path=ov_model_path,
            device=device_type,
            llm_int4_compress=llm_int4_compress,
            vision_int8_quant=vision_int8_quant,
            llm_int8_quant=llm_int8_quant,
            llm_infer_list=llm_infer_list,
            vision_infer=vision_infer
        )
        
        # åˆå§‹åŒ–å›¾åƒé¢„å¤„ç†å™¨
        my_preprocessor = PaddleOCRVLImageProcessor(
            resample=3,  # PIL.Image.Resampling.LANCZOS
            rescale_factor=0.00392156862745098,  # 1/255
            image_mean=[0.5, 0.5, 0.5],
            image_std=[0.5, 0.5, 0.5],
            min_pixels=147384,
            max_pixels=2822400,
            patch_size=14,
            temporal_patch_size=1,
            merge_size=2
        )
        
        return "âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸï¼"
    except Exception as e:
        return f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {str(e)}"

def load_image_from_source(image_source):
    """ä»ä¸åŒæ¥æºåŠ è½½å›¾ç‰‡ï¼šPIL Imageå¯¹è±¡ã€æœ¬åœ°è·¯å¾„æˆ–URL"""
    if image_source is None:
        return None
    
    # å¦‚æœå·²ç»æ˜¯PIL Imageå¯¹è±¡ï¼Œç›´æ¥è¿”å›
    if isinstance(image_source, Image.Image):
        return image_source
    
    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œåˆ¤æ–­æ˜¯URLè¿˜æ˜¯æœ¬åœ°è·¯å¾„
    if isinstance(image_source, str):
        # æ£€æŸ¥æ˜¯å¦æ˜¯URL
        parsed = urlparse(image_source)
        if parsed.scheme in ('http', 'https'):
            # ä»URLä¸‹è½½å›¾ç‰‡
            try:
                response = requests.get(image_source, stream=True, timeout=10)
                response.raise_for_status()
                image = Image.open(response.raw)
                return image
            except Exception as e:
                raise Exception(f"æ— æ³•ä»URLåŠ è½½å›¾ç‰‡: {str(e)}")
        else:
            # æœ¬åœ°æ–‡ä»¶è·¯å¾„
            try:
                path = Path(image_source)
                if not path.exists():
                    raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {image_source}")
                image = Image.open(image_source)
                return image
            except Exception as e:
                raise Exception(f"æ— æ³•ä»æœ¬åœ°è·¯å¾„åŠ è½½å›¾ç‰‡: {str(e)}")
    
    return image_source

def process_ocr(image, image_url_or_path, task_type, max_new_tokens, custom_prompt):
    """å¤„ç†OCRè¯†åˆ«"""
    global paddleocr_vl_model, my_preprocessor
    
    if paddleocr_vl_model is None or my_preprocessor is None:
        return "âŒ è¯·å…ˆåˆå§‹åŒ–æ¨¡å‹ï¼", None
    
    # ç¡®å®šä½¿ç”¨å“ªä¸ªå›¾ç‰‡æº
    image_source = None
    if image is not None:
        image_source = image
    elif image_url_or_path and image_url_or_path.strip():
        image_source = image_url_or_path.strip()
    
    if image_source is None:
        return "âŒ è¯·ä¸Šä¼ å›¾ç‰‡ã€è¾“å…¥å›¾ç‰‡è·¯å¾„æˆ–URLï¼", None
    
    try:
        # åŠ è½½å›¾ç‰‡ï¼ˆæ”¯æŒPIL Imageã€æœ¬åœ°è·¯å¾„æˆ–URLï¼‰
        loaded_image = load_image_from_source(image_source)
        if loaded_image is None:
            return "âŒ æ— æ³•åŠ è½½å›¾ç‰‡ï¼", None
        
        # å‡†å¤‡æç¤ºè¯
        if custom_prompt and custom_prompt.strip():
            prompt_text = custom_prompt.strip()
        else:
            prompt_text = PROMPTS.get(task_type, "OCR:")
        
        # è½¬æ¢å›¾ç‰‡ä¸ºRGB
        image_rgb = loaded_image.convert("RGB")
        
        # å›ºå®šè°ƒæ•´å›¾ç‰‡å¤§å°ä¸º1200x800ï¼ˆä¸ç”¨æˆ·ä»£ç ä¿æŒä¸€è‡´ï¼‰
        target_width = 1200
        target_height = 800
        image_rgb = image_rgb.resize((target_width, target_height), Image.Resampling.LANCZOS)
        
        # å‡†å¤‡æ¶ˆæ¯
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "image", "image": image_rgb},
                    {"type": "text", "text": prompt_text},
                ]
            }
        ]
        
        # ä½¿ç”¨render_jinja_templateå¤„ç†æ–‡æœ¬
        text, generation_indices = render_jinja_template(
            conversations=[messages],
            chat_template=CHAT_TEMPLATE,
            add_generation_prompt=True,
            return_tensors="pt",
        )
        
        # å¤„ç†å›¾åƒ
        images_info = my_preprocessor(images=image_rgb, return_tensors="pt")
        
        # å¤„ç†å›¾åƒå ä½ç¬¦
        if not isinstance(text, list):
            text = [text]
        
        index = 0
        for i in range(len(text)):
            while "<|IMAGE_PLACEHOLDER|>" in text[i]:
                placeholder_count = (
                    images_info['image_grid_thw'][index].prod()
                    // 2
                    // 2
                )
                text[i] = text[i].replace(
                    "<|IMAGE_PLACEHOLDER|>",
                    "<|placeholder|>" * placeholder_count,
                    1,
                )
                index += 1
            text[i] = text[i].replace("<|placeholder|>", "<|IMAGE_PLACEHOLDER|>")
        
        # Tokenizeæ–‡æœ¬
        text_inputs = paddleocr_vl_model.tokenizer(text, return_tensors="pt")
        
        # å‡†å¤‡ç”Ÿæˆé…ç½®
        generation_config = {
            "bos_token_id": paddleocr_vl_model.tokenizer.bos_token_id,
            "eos_token_id": paddleocr_vl_model.tokenizer.eos_token_id,
            "pad_token_id": paddleocr_vl_model.tokenizer.pad_token_id,
            "max_new_tokens": max_new_tokens,
            "do_sample": False,
        }
        
        # æ‰§è¡ŒOCRè¯†åˆ«
        start_time = time.perf_counter()
        response, history = paddleocr_vl_model.chat(
            input_ids=text_inputs["input_ids"],
            attention_mask=text_inputs["attention_mask"],
            pixel_values=images_info["pixel_values"],
            image_grid_thw=images_info["image_grid_thw"],
            generation_config=generation_config
        )
        elapsed_time = time.perf_counter() - start_time
        
        # æ ¼å¼åŒ–ç»“æœ
        result_text = f"""ğŸ“„ OCRè¯†åˆ«ç»“æœ:
{response}

â±ï¸ æ‰§è¡Œæ—¶é—´: {elapsed_time:.3f} ç§’ ({elapsed_time*1000:.2f} æ¯«ç§’)
"""
        
        return result_text, response
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        return f"âŒ è¯†åˆ«å¤±è´¥: {str(e)}\n\nè¯¦ç»†ä¿¡æ¯:\n{error_detail}", None

# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(title="PaddleOCR-VL OCRè¯†åˆ«ç³»ç»Ÿ", theme=gr.themes.Soft()) as demo:
    gr.Markdown(
        """
        # ğŸš€ PaddleOCR-VL OCRè¯†åˆ«ç³»ç»Ÿ
        
        åŸºäºOpenVINOçš„PaddleOCR-VLæ¨¡å‹OCRè¯†åˆ«ç•Œé¢
        
        ## ä½¿ç”¨è¯´æ˜
        1. é¦–å…ˆåœ¨"æ¨¡å‹è®¾ç½®"ä¸­åˆå§‹åŒ–æ¨¡å‹
        2. ä¸Šä¼ è¦è¯†åˆ«çš„å›¾ç‰‡
        3. é€‰æ‹©ä»»åŠ¡ç±»å‹æˆ–è¾“å…¥è‡ªå®šä¹‰æç¤ºè¯
        4. ç‚¹å‡»"å¼€å§‹è¯†åˆ«"æŒ‰é’®
        """
    )
    
    with gr.Tab("æ¨¡å‹è®¾ç½®"):
        with gr.Row():
            with gr.Column():
                ov_model_path_input = gr.Textbox(
                    label="OpenVINOæ¨¡å‹è·¯å¾„",
                    value="./ov_paddleocr_vl_model",
                    placeholder="è¾“å…¥OpenVINOæ¨¡å‹è·¯å¾„"
                )
                device_type = gr.Dropdown(
                    label="è®¾å¤‡ç±»å‹",
                    choices=["CPU", "GPU"],
                    value="GPU"
                )
                template_path_input = gr.Textbox(
                    label="Chatæ¨¡æ¿æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰",
                    value="",
                    placeholder="ç•™ç©ºä½¿ç”¨é»˜è®¤æ¨¡æ¿ï¼Œæˆ–è¾“å…¥æ¨¡æ¿æ–‡ä»¶è·¯å¾„"
                )
                llm_int4 = gr.Checkbox(label="LLM INT4å‹ç¼©", value=False)
                vision_int8 = gr.Checkbox(label="Vision INT8é‡åŒ–", value=False)
                llm_int8 = gr.Checkbox(label="LLM INT8é‡åŒ–", value=False)
                init_btn = gr.Button("åˆå§‹åŒ–æ¨¡å‹", variant="primary")
            with gr.Column():
                init_status = gr.Textbox(
                    label="åˆå§‹åŒ–çŠ¶æ€",
                    value="ç­‰å¾…åˆå§‹åŒ–...",
                    interactive=False,
                    lines=5
                )
    
    with gr.Tab("OCRè¯†åˆ«"):
        with gr.Row():
            with gr.Column():
                image_input = gr.Image(
                    label="ä¸Šä¼ å›¾ç‰‡ï¼ˆæ–¹å¼1ï¼šç›´æ¥ä¸Šä¼ ï¼‰",
                    type="pil",
                    sources=["upload", "clipboard"]
                )
                image_url_or_path = gr.Textbox(
                    label="å›¾ç‰‡è·¯å¾„æˆ–URLï¼ˆæ–¹å¼2ï¼šè¾“å…¥æœ¬åœ°è·¯å¾„æˆ–ç½‘ç»œURLï¼‰",
                    placeholder="ä¾‹å¦‚: ./image.jpg æˆ– https://example.com/image.png",
                    value="",
                    lines=1
                )
                gr.Markdown("**æç¤º**: å¯ä»¥ä½¿ç”¨æ–¹å¼1ä¸Šä¼ å›¾ç‰‡ï¼Œæˆ–ä½¿ç”¨æ–¹å¼2è¾“å…¥æœ¬åœ°æ–‡ä»¶è·¯å¾„æˆ–ç½‘ç»œå›¾ç‰‡URL")
                gr.Markdown("**æ³¨æ„**: å›¾ç‰‡ä¼šè‡ªåŠ¨è°ƒæ•´ä¸º1200x800å°ºå¯¸")
                task_type = gr.Dropdown(
                    label="ä»»åŠ¡ç±»å‹",
                    choices=["ocr", "table", "formula", "chart"],
                    value="ocr"
                )
                custom_prompt = gr.Textbox(
                    label="è‡ªå®šä¹‰æç¤ºè¯ï¼ˆå¯é€‰ï¼‰",
                    placeholder="ç•™ç©ºåˆ™ä½¿ç”¨é»˜è®¤æç¤ºè¯ï¼Œä¾‹å¦‚: OCR: æˆ– Table Recognition:",
                    lines=2
                )
                max_tokens = gr.Slider(
                    label="æœ€å¤§ç”Ÿæˆtokenæ•°",
                    minimum=128,
                    maximum=2048,
                    value=1024,
                    step=128
                )
                recognize_btn = gr.Button("å¼€å§‹è¯†åˆ«", variant="primary", size="lg")
            
            with gr.Column():
                result_output = gr.Textbox(
                    label="è¯†åˆ«ç»“æœ",
                    lines=20,
                    interactive=False
                )
                raw_result = gr.Textbox(
                    label="åŸå§‹ç»“æœï¼ˆä»…æ–‡æœ¬ï¼‰",
                    lines=5,
                    interactive=True
                )
    
    with gr.Tab("ä½¿ç”¨è¯´æ˜"):
        gr.Markdown(
            """
            ## ğŸ“– ä½¿ç”¨è¯´æ˜
            
            ### 1. æ¨¡å‹åˆå§‹åŒ–
            - **OpenVINOæ¨¡å‹è·¯å¾„**: è½¬æ¢åçš„OpenVINOæ¨¡å‹è·¯å¾„
            - **è®¾å¤‡ç±»å‹**: é€‰æ‹©CPUæˆ–GPUï¼ˆæ¨èGPUï¼‰
            - **Chatæ¨¡æ¿æ–‡ä»¶**: å¯é€‰ï¼Œç•™ç©ºä½¿ç”¨é»˜è®¤æ¨¡æ¿
            - **é‡åŒ–é€‰é¡¹**: æ ¹æ®éœ€è¦é€‰æ‹©æ˜¯å¦å¯ç”¨é‡åŒ–ä»¥æå‡æ€§èƒ½
            
            ### 2. OCRè¯†åˆ«
            - **ä¸Šä¼ å›¾ç‰‡ï¼ˆæ–¹å¼1ï¼‰**: æ”¯æŒä¸Šä¼ æˆ–ç²˜è´´å›¾ç‰‡
            - **å›¾ç‰‡è·¯å¾„æˆ–URLï¼ˆæ–¹å¼2ï¼‰**: 
              - è¾“å…¥æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼Œä¾‹å¦‚: `./image.jpg` æˆ– `C:/images/test.png`
              - è¾“å…¥ç½‘ç»œå›¾ç‰‡URLï¼Œä¾‹å¦‚: `https://example.com/image.png`
              - æ³¨æ„ï¼šå¦‚æœä½¿ç”¨æ–¹å¼1ä¸Šä¼ äº†å›¾ç‰‡ï¼Œæ–¹å¼2ä¼šè¢«å¿½ç•¥
            - **å›¾ç‰‡å°ºå¯¸**: å›¾ç‰‡ä¼šè‡ªåŠ¨è°ƒæ•´ä¸º1200x800å°ºå¯¸
            - **ä»»åŠ¡ç±»å‹**: 
              - `ocr`: æ™®é€šæ–‡å­—è¯†åˆ«
              - `table`: è¡¨æ ¼è¯†åˆ«
              - `formula`: å…¬å¼è¯†åˆ«
              - `chart`: å›¾è¡¨è¯†åˆ«
            - **è‡ªå®šä¹‰æç¤ºè¯**: å¯ä»¥è¾“å…¥è‡ªå®šä¹‰çš„æç¤ºè¯
            - **æœ€å¤§tokenæ•°**: æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„æœ€å¤§é•¿åº¦
            
            ### 3. ç»“æœæŸ¥çœ‹
            - **è¯†åˆ«ç»“æœ**: æ˜¾ç¤ºå®Œæ•´çš„è¯†åˆ«ç»“æœå’Œæ‰§è¡Œæ—¶é—´
            - **åŸå§‹ç»“æœ**: ä»…æ˜¾ç¤ºè¯†åˆ«å‡ºçš„æ–‡æœ¬å†…å®¹ï¼Œå¯ä»¥å¤åˆ¶
            
            ## âš ï¸ æ³¨æ„äº‹é¡¹
            - é¦–æ¬¡ä½¿ç”¨éœ€è¦å…ˆåˆå§‹åŒ–æ¨¡å‹
            - æ¨¡å‹åˆå§‹åŒ–å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´
            - è¯†åˆ«æ—¶é—´å–å†³äºå›¾ç‰‡å¤§å°å’Œæ¨¡å‹é…ç½®
            - æœ¬ç‰ˆæœ¬ä½¿ç”¨render_jinja_templateå’ŒPaddleOCRVLImageProcessor
            """
        )
    
    # ç»‘å®šäº‹ä»¶
    init_btn.click(
        fn=initialize_model,
        inputs=[ov_model_path_input, device_type, llm_int4, vision_int8, llm_int8, template_path_input],
        outputs=init_status
    )
    
    recognize_btn.click(
        fn=process_ocr,
        inputs=[image_input, image_url_or_path, task_type, max_tokens, custom_prompt],
        outputs=[result_output, raw_result]
    )

if __name__ == "__main__":
    import os
    import socket
    
    os.environ["GRADIO_SERVER_NAME"] = "127.0.0.1"
    os.environ["GRADIO_ANALYTICS_ENABLED"] = "False"
    os.environ["GRADIO_SERVER_PROXY"] = ""
    os.environ["NO_PROXY"] = "127.0.0.1,localhost"
    os.environ["no_proxy"] = "127.0.0.1,localhost"
    os.environ["GRADIO_SKIP_STARTUP_EVENTS"] = "1"
    
    def find_free_port(start_port=7860, max_attempts=10):
        """æŸ¥æ‰¾å¯ç”¨ç«¯å£"""
        for i in range(max_attempts):
            port = start_port + i
            try:
                with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                    s.bind(('127.0.0.1', port))
                    return port
            except OSError:
                continue
        return None
    
    try:
        print("=" * 60)
        print("æ­£åœ¨å¯åŠ¨PaddleOCR-VL OCRè¯†åˆ«ç³»ç»Ÿ...")
        print("=" * 60)
        
        # æŸ¥æ‰¾å¯ç”¨ç«¯å£
        port = find_free_port(7860)
        if port is None:
            print("âŒ æ— æ³•æ‰¾åˆ°å¯ç”¨ç«¯å£ï¼Œè¯·æ‰‹åŠ¨æŒ‡å®šç«¯å£")
            port = 7860
        
        print(f"è®¿é—®åœ°å€: http://127.0.0.1:{port}")
        print("=" * 60)
        
        # å°è¯•å¯åŠ¨ï¼Œå¦‚æœå¤±è´¥åˆ™å°è¯•å…¶ä»–ç«¯å£
        max_attempts = 3
        for attempt in range(max_attempts):
            try:
                demo.launch(
                    server_name="127.0.0.1",  # åªç›‘å¬æœ¬åœ°
                    server_port=port,          # ç«¯å£å·
                    share=False,               # ä¸åˆ›å»ºå…¬å…±é“¾æ¥
                    inbrowser=False,           # ä¸è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨ï¼ˆé¿å…å¯åŠ¨äº‹ä»¶é—®é¢˜ï¼‰
                    show_error=True,           # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
                    quiet=False,               # æ˜¾ç¤ºå¯åŠ¨ä¿¡æ¯
                    favicon_path=None,         # ä¸ä½¿ç”¨favicon
                    prevent_thread_lock=False,   # å…è®¸åœ¨åå°è¿è¡Œ
                    max_threads=1,             # é™åˆ¶çº¿ç¨‹æ•°
                )
                break  # æˆåŠŸå¯åŠ¨
            except Exception as e:
                if attempt < max_attempts - 1:
                    port = find_free_port(port + 1)
                    if port:
                        print(f"å°è¯•ç«¯å£ {port}...")
                        continue
                raise
        
    except Exception as e:
        print(f"\nâŒ å¯åŠ¨å¤±è´¥: {e}")
        print("\nå¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
        print("1. æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨:")
        print("   Windows: netstat -ano | findstr :7860")
        print("   Linux/Mac: lsof -i :7860")
        print("2. å°è¯•æ‰‹åŠ¨æŒ‡å®šç«¯å£:")
        print("   demo.launch(server_port=7861)")
        print("3. æ£€æŸ¥é˜²ç«å¢™/ä»£ç†è®¾ç½®:")
        print("   - ç¡®ä¿æ²¡æœ‰ä»£ç†é˜»æ­¢localhostè®¿é—®")
        print("   - ä¸´æ—¶å…³é—­é˜²ç«å¢™æµ‹è¯•")
        print("4. è®¾ç½®ç¯å¢ƒå˜é‡åé‡è¯•:")
        print("   set GRADIO_ANALYTICS_ENABLED=False")
        print("   set NO_PROXY=127.0.0.1,localhost")
        print("5. å¦‚æœé—®é¢˜æŒç»­ï¼Œå°è¯•æ›´æ–°Gradio:")
        print("   pip install --upgrade gradio")
        raise

