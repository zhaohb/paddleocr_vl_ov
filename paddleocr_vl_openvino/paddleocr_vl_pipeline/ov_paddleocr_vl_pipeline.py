"""
OpenVINO ç‰ˆæœ¬çš„ PaddleOCR-VL Pipeline å®ç°
"""

import cv2
import numpy as np
from pathlib import Path
from typing import Union, List, Optional, Dict, Any
from functools import partial
import random
from PIL import Image, ImageDraw, ImageFont
import openvino as ov
import os
import logging

# å°è¯•å¯¼å…¥ modelscopeï¼Œå¦‚æœæœªå®‰è£…åˆ™ç»™å‡ºæç¤º
try:
    from modelscope import snapshot_download
    MODELSCOPE_AVAILABLE = True
except ImportError:
    MODELSCOPE_AVAILABLE = False
    logging.warning("modelscope not installed. Auto-download feature will be disabled. Install with: pip install modelscope")

# å°è¯•å¯¼å…¥ modelscopeï¼Œå¦‚æœæœªå®‰è£…åˆ™ç»™å‡ºæç¤º
try:
    from modelscope import snapshot_download
    MODELSCOPE_AVAILABLE = True
except ImportError:
    MODELSCOPE_AVAILABLE = False
    logging.warning("modelscope not installed. Auto-download feature will be disabled. Install with: pip install modelscope")

# å¯¼å…¥å¸ƒå±€æ£€æµ‹ç›¸å…³å‡½æ•°
from ..pp_doclayoutv2.ov_pp_layoutv2_infer import (
    preprocess_image_doclayout,
    postprocess_detections_detr,
    postprocess_detections_paddle_nms,
    LayoutDetectionResult,
)
from ..pp_doclayoutv2.result import LayoutAnalysisResult

# å¯¼å…¥ VLM æ¨¡å‹
from ..paddleocr_vl.ov_paddleocr_vl import OVPaddleOCRVLForCausalLM

# å¯¼å…¥å›¾åƒå¤„ç†
from ..paddleocr_vl.image_processing_paddleocr_vl import PaddleOCRVLImageProcessor
from ..paddleocr_vl.uilts import (
    convert_otsl_to_html,
    crop_margin,
    filter_overlap_boxes,
    merge_blocks,
    post_process_for_spotting,
    tokenize_figure_of_table,
    truncate_repetitive_content,
    untokenize_figure_of_table,
)

# å›¾åƒæ ‡ç­¾å®šä¹‰ï¼ˆå‚è€ƒ PaddleXï¼‰
BLOCK_LABEL_MAP = {
    "image_labels": ["image", "figure"],
}

def gather_imgs(original_img: np.ndarray, layout_det_objs: List[Dict]) -> List[Dict]:
    """
    ä»å¸ƒå±€æ£€æµ‹ç»“æœä¸­æå–å›¾åƒåŒºåŸŸ
    
    Args:
        original_img: åŸå§‹å›¾åƒï¼ˆBGR æ ¼å¼ï¼‰
        layout_det_objs: å¸ƒå±€æ£€æµ‹ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« label, coordinate, score ç­‰å­—æ®µ
    
    Returns:
        List[Dict]: æå–çš„å›¾åƒåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« path, img, coordinate, score
    """
    imgs_in_doc = []
    for det_obj in layout_det_objs:
        if det_obj["label"] in BLOCK_LABEL_MAP["image_labels"]:
            label = det_obj["label"]
            x_min, y_min, x_max, y_max = list(map(int, det_obj["coordinate"]))
            img_path = f"imgs/img_in_{label}_box_{x_min}_{y_min}_{x_max}_{y_max}.jpg"
            # ä» BGR å›¾åƒä¸­æå–åŒºåŸŸå¹¶è½¬æ¢ä¸º RGBï¼ˆPIL Image éœ€è¦ RGBï¼‰
            img = Image.fromarray(original_img[y_min:y_max, x_min:x_max, ::-1])
            imgs_in_doc.append(
                {
                    "path": img_path,
                    "img": img,
                    "coordinate": (x_min, y_min, x_max, y_max),
                    "score": det_obj["score"],
                }
            )
    return imgs_in_doc

# å¯è§†åŒ–é¡ºåºæ ‡ç­¾ï¼ˆå‚è€ƒ PaddleXï¼‰
VISUALIZE_ORDE_LABELS = [
    "text",
    "formula",
    "inline_formula",
    "display_formula",
    "algorithm",
    "reference",
    "reference_content",
    "content",
    "abstract",
    "paragraph_title",
    "doc_title",
    "vertical_text",
    "ocr",
    "number",
    "footnote",
    "header",
    "header_image",
    "footer",
    "footer_image",
    "aside_text",
]

# PaddleX doc_vl: JSON çš„ order ç”Ÿæˆéœ€è¦è·³è¿‡çš„ label åˆ—è¡¨
SKIP_ORDER_LABELS = [
    "figure_title",
    "vision_footnote",
    "image",
    "chart",
    "table",
    "header",
    "header_image",
    "footer",
    "footer_image",
    "footnote",
    "aside_text",
]


def _sorted_layout_blocks_paddlex_style(blocks: List["PaddleOCRVLBlock"], image_width: int) -> List["PaddleOCRVLBlock"]:
    """
    å¯¹é½ PaddleX 1.5 `layout_parsing/utils.py::sorted_layout_boxes` çš„é˜…è¯»é¡ºåºæ’åºï¼š
    - å…ˆæŒ‰ (y1, x1) ç²—æ’
    - å†æŒ‰å·¦å³æ ï¼ˆleft/rightï¼‰åˆ†æ¡¶ï¼Œæå‡åŒæ æ–‡æœ¬çš„é˜…è¯»é¡ºåºä¸€è‡´æ€§

    Args:
        blocks: PaddleOCRVLBlock åˆ—è¡¨
        image_width: é¡µé¢å®½åº¦

    Returns:
        æ’åºåçš„ blocks
    """
    if not blocks or len(blocks) <= 1:
        return blocks

    w = float(image_width) if image_width else 0.0
    if w <= 0:
        return sorted(blocks, key=lambda b: (b.bbox[1], b.bbox[0]))

    # Sort on y first then x (PaddleX: sorted(res, key=lambda x: (y, x)))
    _boxes = sorted(blocks, key=lambda b: (b.bbox[1], b.bbox[0]))

    new_res: List[PaddleOCRVLBlock] = []
    res_left: List[PaddleOCRVLBlock] = []
    res_right: List[PaddleOCRVLBlock] = []

    i = 0
    while True:
        if i >= len(_boxes):
            break

        bbox = _boxes[i].bbox
        x1, y1, x2, y2 = bbox

        # PaddleX å·¦æ åˆ¤å®š
        if x1 < w / 4 and x2 < 3 * w / 5:
            res_left.append(_boxes[i])
            i += 1
        # PaddleX å³æ åˆ¤å®š
        elif x1 > 2 * w / 5:
            res_right.append(_boxes[i])
            i += 1
        else:
            # ç¢°åˆ°ä¸­é—´è·¨æ å—ï¼šå…ˆæŠŠå·¦å³æ æŒ‰ y åˆå¹¶ï¼Œå†åŠ å…¥è¯¥å—
            new_res += res_left
            new_res += res_right
            new_res.append(_boxes[i])
            res_left = []
            res_right = []
            i += 1

    # Flush remaining
    res_left = sorted(res_left, key=lambda b: b.bbox[1])
    res_right = sorted(res_right, key=lambda b: b.bbox[1])
    if res_left:
        new_res += res_left
    if res_right:
        new_res += res_right

    return new_res

# æ ¼å¼åŒ–å‡½æ•°ï¼ˆå‚è€ƒ PaddleXï¼‰
def format_title_func(block):
    """æ ¼å¼åŒ–æ ‡é¢˜"""
    import re
    title = block.content
    # ç®€å•çš„æ ‡é¢˜æ ¼å¼åŒ–
    title = title.rstrip(".")
    level = title.count(".") + 1 if "." in title else 1
    return f"#{'#' * level} {title}".replace("-\n", "").replace("\n", " ")

def format_para_title_func(block):
    """
    æ®µè½æ ‡é¢˜æ ¼å¼åŒ–ï¼ˆå¯¹é½ PaddleX `format_para_title_func` çš„ç”¨é€”ï¼‰ã€‚
    è¿™é‡Œä¿æŒå®ç°ç®€æ´ï¼šç»Ÿä¸€ç”¨äºŒçº§æ ‡é¢˜æ¸²æŸ“ã€‚
    """
    content = getattr(block, "content", "")
    return f"## {content}".replace("-\n", "").replace("\n", " ")

def format_centered_by_html(string):
    """HTML å±…ä¸­æ ¼å¼åŒ–"""
    return f'<div style="text-align: center;">{string}</div>'.replace("-\n", "").replace("\n", " ") + "\n"

def format_text_plain_func(block):
    """çº¯æ–‡æœ¬æ ¼å¼åŒ–"""
    return block.content

def format_image_scaled_by_html_func(block, original_image_width):
    """ç¼©æ”¾å›¾åƒ HTML æ ¼å¼åŒ–"""
    if block.image:
        image_path = block.image["path"]
        image_width = block.image["img"].width
        scale = int(image_width / original_image_width * 100)
        return '<img src="{}" alt="Image" width="{}%" />'.format(
            image_path.replace("-\n", "").replace("\n", " "), scale
        )
    return ""

def format_image_plain_func(block):
    """çº¯å›¾åƒæ ¼å¼åŒ–"""
    if block.image:
        image_path = block.image["path"]
        return "![]({})".format(image_path.replace("-\n", "").replace("\n", " "))
    return ""

def format_table_center_func(block):
    tabel_content = block.content

    tabel_content = tabel_content.replace(
        "<table>", "<table border=1 style='margin: auto; word-wrap: break-word;'>"
    )

    tabel_content = tabel_content.replace(
        "<th>", "<th style='text-align: center; word-wrap: break-word;'>"
    )
    tabel_content = tabel_content.replace(
        "<td>", "<td style='text-align: center; word-wrap: break-word;'>"
    )

    return tabel_content

def simplify_table_func(table_code):
    """ç®€åŒ–è¡¨æ ¼å‡½æ•°"""
    return "\n" + table_code.replace("<html>", "").replace("</html>", "").replace(
        "<body>", ""
    ).replace("</body>", "")

def format_first_line_func(block, templates, format_func, spliter):
    """æ ¼å¼åŒ–é¦–è¡Œ"""
    from functools import partial
    lines = block.content.split(spliter)
    for idx in range(len(lines)):
        line = lines[idx]
        if line.strip() == "":
            continue
        if line.lower() in templates:
            lines[idx] = format_func(line)
        break
    return spliter.join(lines)

def merge_formula_and_number(formula, formula_number):
    formula = formula.replace("$$", "")
    merge_formula = r"{} \tag*{{{}}}".format(formula, formula_number)
    return f"$${merge_formula}$$"

def fix_latex_syntax(text):
    """
    ä¿®å¤å¸¸è§çš„ LaTeX è¯­æ³•é”™è¯¯ï¼Œç‰¹åˆ«æ˜¯ VLM æ¨¡å‹ç”Ÿæˆçš„é”™è¯¯æ ¼å¼
    
    Args:
        text: åŒ…å« LaTeX å…¬å¼çš„æ–‡æœ¬
    
    Returns:
        ä¿®å¤åçš„æ–‡æœ¬
    """
    import re
    
    # ä¿®å¤ \inS, \inR, \inN ç­‰é”™è¯¯ï¼ˆåº”è¯¥æ˜¯ \in S, \in \mathbb{R}, \in \mathbb{N}ï¼‰
    # åŒ¹é…æ¨¡å¼ï¼š\in[A-Z]ï¼ˆå¦‚ \inS, \inR, \inNï¼‰
    def fix_in_symbol(match):
        full_match = match.group(0)
        letter = full_match[-1]  # è·å–æœ€åä¸€ä¸ªå­—æ¯
        
        # ç‰¹æ®Šå¤„ç†ï¼šR -> \mathbb{R}, N -> \mathbb{N}, Z -> \mathbb{Z}, Q -> \mathbb{Q}, C -> \mathbb{C}
        if letter in ['R', 'N', 'Z', 'Q', 'C']:
            return f"\\in \\mathbb{{{letter}}}"
        else:
            # å…¶ä»–æƒ…å†µï¼š\inS -> \in S
            return f"\\in {letter}"
    
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾å¹¶æ›¿æ¢
    # åŒ¹é… $...$ æˆ– $$...$$ ä¸­çš„å†…å®¹
    def fix_in_formula(match):
        formula_content = match.group(1)
        # ä¿®å¤ \in[A-Z] æ¨¡å¼
        formula_content = re.sub(r'\\in([A-Z])', fix_in_symbol, formula_content)
        return f"${formula_content}$"
    
    # ä¿®å¤è¡Œå†…å…¬å¼ $...$
    text = re.sub(r'\$([^$]+)\$', fix_in_formula, text)
    
    # ä¿®å¤å—çº§å…¬å¼ $$...$$
    def fix_in_display_formula(match):
        formula_content = match.group(1)
        # ä¿®å¤ \in[A-Z] æ¨¡å¼
        formula_content = re.sub(r'\\in([A-Z])', fix_in_symbol, formula_content)
        return f"$${formula_content}$$"
    
    text = re.sub(r'\$\$([^$]+)\$\$', fix_in_display_formula, text)
    
    return text

def format_chart2table_func(block):
    lines_list = block.content.split("\n")
    # get header and rows
    header = lines_list[0].split("|")
    rows = [line.split("|") for line in lines_list[1:]]
    # construct html table
    html = "<table border=1 style='margin: auto; width: max-content;'>\n"
    html += (
        "  <thead><tr>"
        + "".join(
            f"<th style='text-align: center;'>{cell.strip()}</th>" for cell in header
        )
        + "</tr></thead>\n"
    )
    html += "  <tbody>\n"
    for row in rows:
        html += (
            "    <tr>"
            + "".join(
                f"<td style='text-align: center;'>{cell.strip()}</td>" for cell in row
            )
            + "</tr>\n"
        )
    html += "  </tbody>\n"
    html += "</table>"
    return html

def build_handle_funcs_dict(
    *,
    text_func,
    image_func,
    chart_func,
    table_func,
    formula_func,
    seal_func,
):
    """
    Build a dictionary mapping block labels to their formatting functions.

    Args:
        text_func: Function to format text blocks.
        image_func: Function to format image blocks.
        chart_func: Function to format chart blocks.
        table_func: Function to format table blocks.
        formula_func: Function to format formula blocks.
        seal_func: Function to format seal blocks.

    Returns:
        dict: A mapping from block label to handler function.
    """
    return {
        "paragraph_title": format_para_title_func,
        "abstract_title": format_title_func,
        "reference_title": format_title_func,
        "content_title": format_title_func,
        "doc_title": lambda block: f"# {block.content}".replace("-\n", "").replace(
            "\n", " "
        ),
        "table_title": text_func,
        "figure_title": text_func,
        "chart_title": text_func,
        "vision_footnote": lambda block: block.content.replace("\n\n", "\n").replace(
            "\n", "\n\n"
        ),
        "text": lambda block: block.content.replace("\n\n", "\n").replace("\n", "\n\n"),
        "ocr": lambda block: block.content.replace("\n\n", "\n").replace("\n", "\n\n"),
        "vertical_text": lambda block: block.content.replace("\n\n", "\n").replace(
            "\n", "\n\n"
        ),
        "reference_content": lambda block: block.content.replace("\n\n", "\n").replace(
            "\n", "\n\n"
        ),
        "abstract": partial(
            format_first_line_func,
            templates=["æ‘˜è¦", "abstract"],
            format_func=lambda l: f"## {l}\n",
            spliter=" ",
        ),
        "content": lambda block: block.content.replace("-\n", "  \n").replace(
            "\n", "  \n"
        ),
        "image": image_func,
        "chart": chart_func,
        "formula": formula_func,
        "display_formula": formula_func,
        "inline_formula": formula_func,
        "table": table_func,
        "reference": partial(
            format_first_line_func,
            templates=["å‚è€ƒæ–‡çŒ®", "references"],
            format_func=lambda l: f"## {l}",
            spliter="\n",
        ),
        "algorithm": lambda block: block.content.strip("\n"),
        "seal": seal_func,
        "spotting": lambda block: block.content,
        "number": format_text_plain_func,
        "footnote": format_text_plain_func,
        "header": format_text_plain_func,
        "header_image": image_func,
        "footer": format_text_plain_func,
        "footer_image": image_func,
        "aside_text": format_text_plain_func,
    }


def get_show_color(label: str, order_label=False):
    """è·å–æ˜¾ç¤ºé¢œè‰²"""
    if order_label:
        label_colors = {
            "doc_title": (255, 248, 220, 100),
            "doc_title_text": (255, 239, 213, 100),
            "paragraph_title": (102, 102, 255, 100),
            "sub_paragraph_title": (102, 178, 255, 100),
            "vision": (153, 255, 51, 100),
            "vision_title": (144, 238, 144, 100),
            "vision_footnote": (144, 238, 144, 100),
            "normal_text": (153, 0, 76, 100),
            "cross_layout": (53, 218, 207, 100),
            "cross_reference": (221, 160, 221, 100),
        }
    else:
        label_colors = {
            "paragraph_title": (102, 102, 255, 100),
            "doc_title": (255, 248, 220, 100),
            "table_title": (255, 255, 102, 100),
            "figure_title": (102, 178, 255, 100),
            "chart_title": (221, 160, 221, 100),
            "vision_footnote": (144, 238, 144, 100),
            "text": (153, 0, 76, 100),
            "vertical_text": (153, 0, 76, 100),
            "inline_formula": (153, 0, 76, 100),
            "formula": (0, 255, 0, 100),
            "display_formula": (0, 255, 0, 100),
            "abstract": (255, 239, 213, 100),
            "content": (40, 169, 92, 100),
            "seal": (158, 158, 158, 100),
            "table": (204, 204, 0, 100),
            "image": (153, 255, 51, 100),
            "figure": (153, 255, 51, 100),
            "chart": (216, 191, 216, 100),
            "reference": (229, 255, 204, 100),
            "reference_content": (229, 255, 204, 100),
            "algorithm": (255, 250, 240, 100),
        }
    default_color = (158, 158, 158, 100)
    return label_colors.get(label, default_color)

# å®Œæ•´çš„ç»“æœç±»å®ç°ï¼ˆå‚è€ƒ PaddleXï¼‰
class PaddleOCRVLBlock(object):
    """PaddleOCRVL Block Class"""

    def __init__(
        self,
        label,
        bbox,
        content="",
        group_id=None,
        polygon_points=None,
        global_block_id=None,
        global_group_id=None,
    ) -> None:
        """
        Initialize a PaddleOCRVLBlock object.

        Args:
            label (str): Label assigned to the block.
            bbox (list): Bounding box coordinates of the block.
            content (str, optional): Content of the block. Defaults to an empty string.
        """
        self.label = label
        self.bbox = list(map(int, bbox))
        self.content = content
        self.image = None
        self.polygon_points = polygon_points
        self.group_id = group_id
        self.global_block_id = global_block_id
        self.global_group_id = global_group_id

    def __str__(self) -> str:
        """
        Return a string representation of the block.
        """
        _str = f"\n\n#################\nlabel:\t{self.label}\nbbox:\t{self.bbox}\ncontent:\t{self.content}\n#################"
        return _str

    def __repr__(self) -> str:
        """
        Return a string representation of the block.
        """
        _str = f"\n\n#################\nlabel:\t{self.label}\nbbox:\t{self.bbox}\ncontent:\t{self.content}\n#################"
        return _str


class PaddleOCRVLResult(dict):
    """
    PaddleOCRVLResult class for holding and formatting OCR/VL parsing results.
    å‚è€ƒ PaddleX çš„å®Œæ•´å®ç°
    """

    def __init__(self, data) -> None:
        """
        Initializes a new instance of the class with the specified data.

        Args:
            data: The input data for the parsing result.
        """
        super().__init__(data)
        self._save_funcs = []
        markdown_ignore_labels = self.get("model_settings", {}).get(
            "markdown_ignore_labels", []
        )
        # ç”¨äºå¯è§†åŒ–ï¼ˆlayout_order_resï¼‰â€”â€”ä¸å½±å“ JSON çš„ block_order è§„åˆ™
        self.visualize_order_labels = [
            label for label in VISUALIZE_ORDE_LABELS if label not in markdown_ignore_labels
        ]
        # å¯¹é½ PaddleXï¼šJSON çš„ block_order éœ€è¦è·³è¿‡è¿™äº› labels
        self.skip_order_labels = [label for label in SKIP_ORDER_LABELS + markdown_ignore_labels]

    def _get_input_fn(self):
        """è·å–è¾“å…¥æ–‡ä»¶å"""
        import time
        import random
        if self.get("input_path", None) is None:
            timestamp = int(time.time())
            random_number = random.randint(1000, 9999)
            fp = f"{timestamp}_{random_number}"
            return Path(fp).name
        fp = self["input_path"]
        return Path(fp).name

    def _to_img(self) -> dict:
        """
        è‡ªåŒ…å«ç‰ˆæœ¬ï¼ˆæ—  Paddle/PaddleX ä¾èµ–ï¼‰ï¼š
        - è‹¥ä¸Šæ¸¸ç»“æœå¯¹è±¡/å­—å…¸æä¾›äº† `img`ï¼Œåˆ™é€ä¼ æ”¶é›†ï¼›
        - spotting å¯è§†åŒ–ä»…ç”¨ PIL ç»˜åˆ¶ï¼ˆä¸ä¾èµ– SIMFANG_FONT / draw_box_txt_fine / get_minarea_rectï¼‰ã€‚
        """
        res_img_dict: dict = {}
        model_settings = self.get("model_settings", {})

        # doc_preprocessor_res
        if model_settings.get("use_doc_preprocessor", False):
            dpr = self.get("doc_preprocessor_res")
            if isinstance(dpr, dict) and isinstance(dpr.get("img"), dict):
                res_img_dict.update(dpr["img"])
            elif hasattr(dpr, "img") and isinstance(getattr(dpr, "img"), dict):
                res_img_dict.update(getattr(dpr, "img"))
            elif isinstance(dpr, list):
                for idx, item in enumerate(dpr):
                    if hasattr(item, "img") and isinstance(getattr(item, "img"), dict):
                        for k, v in getattr(item, "img").items():
                            res_img_dict[f"{k}_{idx}"] = v

        # layout_det_res
        if model_settings.get("use_layout_detection", False):
            ldr = self.get("layout_det_res")
            if isinstance(ldr, dict) and isinstance(ldr.get("img"), dict):
                if "res" in ldr["img"]:
                    res_img_dict["layout_det_res"] = ldr["img"]["res"]
            elif hasattr(ldr, "img"):
                img = getattr(ldr, "img")
                if isinstance(img, dict) and "res" in img:
                    res_img_dict["layout_det_res"] = img["res"]
            elif isinstance(ldr, list):
                for idx, item in enumerate(ldr):
                    if hasattr(item, "img"):
                        img = getattr(item, "img")
                        if isinstance(img, dict) and "res" in img:
                            res_img_dict[f"layout_det_res_{idx}"] = img["res"]

        # spotting å¯è§†åŒ–ï¼šå·¦ä¾§ç”»æ¡†/å¤šè¾¹å½¢ï¼Œå³ä¾§å†™æ–‡å­—
        spotting_res = self.get("spotting_res")
        if spotting_res and not isinstance(spotting_res, list):
            boxes = spotting_res.get("rec_polys", [])
            txts = spotting_res.get("rec_texts", [])
            output_img = (self.get("doc_preprocessor_res") or {}).get("output_img")
            if output_img is not None:
                image_bgr = output_img[:, :, ::-1]
                h, w = image_bgr.shape[0:2]
                img_left = Image.fromarray(image_bgr)
                img_right = Image.new("RGB", (w, h), (255, 255, 255))
                draw_left = ImageDraw.Draw(img_left)
                draw_right = ImageDraw.Draw(img_right)

                try:
                    font_size = int(0.018 * int(w)) + 2
                    font = ImageFont.truetype("arial.ttf", font_size, encoding="utf-8")
                except Exception:
                    font = ImageFont.load_default()

                random.seed(0)
                for box, txt in zip(boxes, txts):
                    try:
                        color = (
                            random.randint(0, 255),
                            random.randint(0, 255),
                            random.randint(0, 255),
                        )
                        if isinstance(txt, tuple):
                            txt = txt[0]
                        pts = np.array(box, dtype=np.int32)
                        if pts.ndim == 2 and pts.shape[1] == 2:
                            pts_list = [(int(x), int(y)) for x, y in pts.tolist()]
                        else:
                            pts_list = [(int(x), int(y)) for x, y in np.array(box).reshape(-1, 2).tolist()]

                        draw_left.polygon(pts_list, outline=color, width=3)
                        # æ–‡æœ¬ä½ç½®ï¼šå–æœ€å° (x,y)
                        xs = [p[0] for p in pts_list]
                        ys = [p[1] for p in pts_list]
                        tx, ty = (min(xs), min(ys)) if xs and ys else (0, 0)
                        draw_right.text((tx, ty), str(txt), fill=color, font=font)
                    except Exception:
                        continue

                img_left = Image.blend(Image.fromarray(image_bgr), img_left, 0.5)
                img_show = Image.new("RGB", (w * 2, h), (255, 255, 255))
                img_show.paste(img_left, (0, 0, w, h))
                img_show.paste(img_right, (w, 0, w * 2, h))
                res_img_dict["spotting_res_img"] = img_show

        return res_img_dict

    def _to_json(self, *args, **kwargs) -> dict:
        """
        è‡ªåŒ…å«ç‰ˆæœ¬ï¼ˆæ—  Paddle/PaddleX ä¾èµ–ï¼‰ï¼š
        - è¿”å›ç»“æ„å¯¹é½æœ¬å·¥ç¨‹å†å²ï¼š`{\"res\": data}`ï¼›
        - é€’å½’å°† numpy ç±»å‹è½¬æ¢ä¸º JSON å‹å¥½ç±»å‹ï¼›
        - æ”¯æŒ `keep_img=True`ï¼ˆå°† block.image åŸæ ·è¾“å‡ºï¼›é»˜è®¤ä¸è¾“å‡ºï¼‰ã€‚
        """
        _keep_img = bool(kwargs.pop("keep_img", False))

        def _to_jsonable(obj):
            if isinstance(obj, np.ndarray):
                return obj.tolist()
            if isinstance(obj, np.generic):
                return obj.item()
            if isinstance(obj, dict):
                return {k: _to_jsonable(v) for k, v in obj.items()}
            if isinstance(obj, (list, tuple)):
                return [_to_jsonable(x) for x in obj]
            return obj

        data = {}
        data["input_path"] = self.get("input_path")
        data["page_index"] = self.get("page_index")
        data["page_count"] = self.get("page_count")
        data["width"] = self.get("width")
        data["height"] = self.get("height")
        model_settings = self.get("model_settings", {})
        data["model_settings"] = model_settings
        use_seal_recognition = model_settings.get("use_seal_recognition", False)
        if model_settings.get("format_block_content", False):
            original_image_width = data["width"]
            use_ocr_for_image_block = model_settings.get("use_ocr_for_image_block", False)
            format_text_func = lambda block: format_centered_by_html(
                format_text_plain_func(block)
            )
            format_image_func = lambda block: format_centered_by_html(
                format_image_scaled_by_html_func(
                    block,
                    original_image_width=original_image_width,
                    show_ocr_content=use_ocr_for_image_block,
                ),
                remove_symbol=not use_ocr_for_image_block,
            )

            format_seal_func = lambda block: format_centered_by_html(
                format_image_scaled_by_html_func(
                    block,
                    original_image_width=original_image_width,
                    show_ocr_content=True,
                ),
                remove_symbol=use_seal_recognition,
            )

            if model_settings.get("use_chart_recognition", False):
                format_chart_func = format_chart2table_func
            else:
                format_chart_func = format_image_func

            if not model_settings.get("use_layout_detection", False):
                format_seal_func = format_text_func

            format_table_func = lambda block: "\n" + format_table_center_func(block)
            format_formula_func = lambda block: block.content

            handle_funcs_dict = build_handle_funcs_dict(
                text_func=format_text_func,
                image_func=format_image_func,
                chart_func=format_chart_func,
                table_func=format_table_func,
                formula_func=format_formula_func,
                seal_func=format_seal_func,
            )

        parsing_res_list = self.get("parsing_res_list", [])
        parsing_res_list_json = []
        order_index = 1
        for idx, parsing_res in enumerate(parsing_res_list):
            label = parsing_res.label
            if label not in self.skip_order_labels:
                order = order_index
                order_index += 1
            else:
                order = None
            res_dict = {
                "block_label": parsing_res.label,
                "block_content": parsing_res.content,
                "block_bbox": parsing_res.bbox,
                "block_id": idx,
                "block_order": order,
                "group_id": (
                    parsing_res.group_id if parsing_res.group_id is not None else idx
                ),
            }
            if (
                hasattr(parsing_res, "global_block_id")
                and parsing_res.global_block_id is not None
            ):
                res_dict["global_block_id"] = parsing_res.global_block_id
            if (
                hasattr(parsing_res, "global_group_id")
                and parsing_res.global_group_id is not None
            ):
                res_dict["global_group_id"] = parsing_res.global_group_id
            if parsing_res.polygon_points is not None:
                res_dict["block_polygon_points"] = _to_jsonable(parsing_res.polygon_points)

            if _keep_img and parsing_res.image is not None:
                res_dict["image"] = _to_jsonable(parsing_res.image)

            if model_settings.get("format_block_content", False):
                if handle_funcs_dict.get(parsing_res.label):
                    res_dict["block_content"] = handle_funcs_dict[parsing_res.label](
                        parsing_res
                    )
                else:
                    res_dict["block_content"] = parsing_res.content

            parsing_res_list_json.append(res_dict)
        data["parsing_res_list"] = parsing_res_list_json
        spotting_res = self.get("spotting_res")
        if spotting_res is not None:
            data["spotting_res"] = _to_jsonable(spotting_res)

        if model_settings.get("use_doc_preprocessor", False):
            dpr = self.get("doc_preprocessor_res")
            if isinstance(dpr, dict) and isinstance(dpr.get("json"), dict):
                data["doc_preprocessor_res"] = dpr["json"].get("res")
            elif hasattr(dpr, "json") and isinstance(getattr(dpr, "json"), dict):
                data["doc_preprocessor_res"] = getattr(dpr, "json").get("res", getattr(dpr, "json"))
            else:
                data["doc_preprocessor_res"] = _to_jsonable(dpr)

        if model_settings.get("use_layout_detection", False):
            ldr = self.get("layout_det_res")
            if isinstance(ldr, dict) and isinstance(ldr.get("json"), dict):
                data["layout_det_res"] = ldr["json"].get("res")
            elif hasattr(ldr, "json") and isinstance(getattr(ldr, "json"), dict):
                data["layout_det_res"] = getattr(ldr, "json").get("res", getattr(ldr, "json"))
            else:
                data["layout_det_res"] = _to_jsonable(ldr)

        return {"res": data}

    def _to_markdown(self, pretty=True, show_formula_number=False) -> dict:
        """
        Save the parsing result to a Markdown file.

        Args:
            pretty (Optional[bool]): whether to pretty markdown by HTML, default by True.
            show_formula_number (bool): whether to show formula numbers.

        Returns:
            dict: Markdown information with text and images.
        """
        model_settings = self.get("model_settings", {})

        # å¯¹é½ PaddleXï¼šä½¿ç”¨ widthï¼ˆå¯èƒ½ä¸º listï¼‰ä½œä¸ºåŸå›¾å®½åº¦åŸºå‡†
        use_ocr_for_image_block = model_settings.get("use_ocr_for_image_block", False)
        use_seal_recognition = model_settings.get("use_seal_recognition", False)
        if isinstance(self.get("width"), list):
            original_image_width = self.get("width")[0]
        else:
            original_image_width = self.get("width")

        if pretty:
            format_text_func = lambda block: format_centered_by_html(format_text_plain_func(block))
            format_image_func = lambda block: format_centered_by_html(
                format_image_scaled_by_html_func(block, original_image_width=original_image_width)
            )
            format_seal_func = lambda block: format_centered_by_html(
                format_image_scaled_by_html_func(block, original_image_width=original_image_width)
            )
        else:
            format_text_func = lambda block: block.content
            format_image_func = lambda block: format_image_plain_func(block)
            format_seal_func = lambda block: format_image_plain_func(block)

        format_chart_func = (
            format_chart2table_func if model_settings.get("use_chart_recognition", False) else format_image_func
        )

        # å¯¹é½ PaddleXï¼šè‹¥ä¸ä½¿ç”¨ layout detectionï¼Œåˆ™ seal èµ°æ–‡æœ¬ï¼ˆé¿å…è¾“å‡ºå›¾ç‰‡å ä½ï¼‰
        if not model_settings.get("use_layout_detection", False):
            format_seal_func = format_text_func

        if pretty:
            format_table_func = lambda block: "\n" + format_table_center_func(block)
        else:
            format_table_func = lambda block: simplify_table_func("\n" + block.content)

        format_formula_func = lambda block: block.content

        handle_funcs_dict = build_handle_funcs_dict(
            text_func=format_text_func,
            image_func=format_image_func,
            chart_func=format_chart_func,
            table_func=format_table_func,
            formula_func=format_formula_func,
            seal_func=format_seal_func,
        )
        for label in model_settings.get("markdown_ignore_labels", []):
            handle_funcs_dict.pop(label, None)

        markdown_content = ""
        markdown_info = {}
        markdown_info["markdown_images"] = {}
        parsing_res_list = self.get("parsing_res_list", [])
        for idx, block in enumerate(parsing_res_list):
            label = block.label
            if block.image is not None:
                markdown_info["markdown_images"][block.image["path"]] = block.image[
                    "img"
                ]
            handle_func = handle_funcs_dict.get(label, None)
            if (
                show_formula_number
                and (label == "display_formula" or label == "formula")
                and idx != len(parsing_res_list) - 1
            ):
                next_block = parsing_res_list[idx + 1]
                next_block_label = next_block.label
                if next_block_label == "formula_number":
                    block.content = merge_formula_and_number(
                        block.content, next_block.content
                    )
            if handle_func:
                markdown_content += (
                    "\n\n" + handle_func(block)
                    if markdown_content
                    else handle_func(block)
                )

        markdown_info["page_index"] = self.get("page_index")
        markdown_info["input_path"] = self.get("input_path")
        markdown_info["markdown_texts"] = markdown_content
        for img in self.get("imgs_in_doc", []):
            markdown_info["markdown_images"][img["path"]] = img["img"]

        return markdown_info

    @property
    def json(self) -> dict:
        """Property to get the JSON representation of the result."""
        return self._to_json()

    @property
    def img(self) -> dict:
        """Property to get the image representation of the result."""
        return self._to_img()

    @property
    def markdown(self) -> dict:
        """Property to get the markdown representation of the result."""
        return self._to_markdown()

    def save_to_json(self, save_path, indent=4, ensure_ascii=False):
        """Save the JSON representation of the object to a file."""
        import json
        save_path = Path(save_path)
        save_path.mkdir(parents=True, exist_ok=True)
        fn = self._get_input_fn()
        json_path = save_path / f"{Path(fn).stem}_res.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(self._to_json(), f, indent=indent, ensure_ascii=ensure_ascii)
        print(f"JSON saved to: {json_path}")

    def save_to_img(self, save_path, *args, **kwargs):
        """
        Save the image representation of the result to files.
        
        Args:
            save_path: The path to save the image(s). If the save path does not end with .jpg or .png, 
                      it appends the input path's stem and suffix to the save path.
            *args: Additional positional arguments that will be passed to the image writer.
            **kwargs: Additional keyword arguments that will be passed to the image writer.
        """
        import mimetypes
        
        def _is_image_file(file_path):
            mime_type, _ = mimetypes.guess_type(str(file_path))
            return mime_type is not None and mime_type.startswith("image/")
        
        img_dict = self._to_img()
        if not _is_image_file(save_path):
            fn = Path(self._get_input_fn())
            suffix = fn.suffix if _is_image_file(fn) else ".png"
            stem = fn.stem
            base_save_path = Path(save_path)
            base_save_path.mkdir(parents=True, exist_ok=True)
            for key in img_dict:
                if img_dict[key] is not None:
                    img_path = base_save_path / f"{stem}_{key}{suffix}"
                    self._save_image(img_path.as_posix(), img_dict[key], *args, **kwargs)
        else:
            if len(img_dict) > 1:
                import logging
                logging.warning(
                    f"The result has multiple img files need to be saved. But the `save_path` has been specified as `{save_path}`!"
                )
            # ä¿å­˜ç¬¬ä¸€ä¸ªé None çš„å›¾ç‰‡
            for key, img in img_dict.items():
                if img is not None:
                    self._save_image(save_path, img, *args, **kwargs)
                    break

    def save_to_markdown(self, save_path, pretty=True, show_formula_number=False, *args, **kwargs):
        """
        Save the markdown representation of the result to a file.
        
        Args:
            save_path: ä¿å­˜è·¯å¾„ï¼ˆç›®å½•æˆ–æ–‡ä»¶è·¯å¾„ï¼‰
            pretty: æ˜¯å¦ä½¿ç”¨ HTML ç¾åŒ– markdown
            show_formula_number: æ˜¯å¦æ˜¾ç¤ºå…¬å¼ç¼–å·
            *args: Additional positional arguments for saving.
            **kwargs: Additional keyword arguments for saving.
        """
        def _is_markdown_file(file_path) -> bool:
            """Check if a file is a markdown file based on its extension or MIME type."""
            markdown_extensions = {".md", ".markdown", ".mdown", ".mkd"}
            _, ext = os.path.splitext(str(file_path))
            if ext.lower() in markdown_extensions:
                return True
            import mimetypes
            mime_type, _ = mimetypes.guess_type(str(file_path))
            return mime_type == "text/markdown"
        
        import os
        import mimetypes
        
        if not _is_markdown_file(save_path):
            fn = Path(self._get_input_fn())
            suffix = fn.suffix if _is_markdown_file(fn) else ".md"
            stem = fn.stem
            base_save_path = Path(save_path)
            save_path = base_save_path / f"{stem}{suffix}"
            self.save_path = save_path
        else:
            self.save_path = save_path
        
        self._save_data(
            self._save_markdown_text,
            self._save_image,
            self.save_path,
            self._to_markdown(pretty=pretty, show_formula_number=show_formula_number),
            *args,
            **kwargs,
        )
    
    def _save_data(
        self,
        save_mkd_func,
        save_img_func,
        save_path,
        data,
        *args,
        **kwargs,
    ):
        """Internal method to save markdown and image data.
        
        Args:
            save_mkd_func: Function to save markdown text.
            save_img_func: Function to save image data.
            save_path: The base path where the data will be saved.
            data: The markdown data to save.
            *args: Additional positional arguments for saving.
            **kwargs: Additional keyword arguments for saving.
        """
        MARKDOWN_SAVE_KEYS = ["markdown_texts"]
        save_path = Path(save_path)
        if data is None:
            return
        for key, value in data.items():
            if key in MARKDOWN_SAVE_KEYS:
                save_mkd_func(save_path.as_posix(), value, *args, **kwargs)
            if isinstance(value, dict):
                base_save_path = save_path.parent
                for img_path, img_data in value.items():
                    save_img_func(
                        (base_save_path / img_path).as_posix(),
                        img_data,
                        *args,
                        **kwargs,
                    )
    
    def _save_markdown_text(self, out_path, text, *args, **kwargs):
        """Save markdown text to file."""
        Path(out_path).parent.mkdir(parents=True, exist_ok=True)
        with open(out_path, 'w', encoding='utf-8') as f:
            f.write(text)
    
    def _save_image(self, out_path, img_data, *args, **kwargs):
        """Save image data to file."""
        Path(out_path).parent.mkdir(parents=True, exist_ok=True)
        if isinstance(img_data, Image.Image):
            img_data.save(out_path)
        elif isinstance(img_data, np.ndarray):
            Image.fromarray(img_data).save(out_path)
        else:
            # å¦‚æœ img_data æ˜¯å…¶ä»–ç±»å‹ï¼Œå°è¯•è½¬æ¢
            try:
                if hasattr(img_data, 'save'):
                    img_data.save(out_path)
                else:
                    print(f"Warning: Cannot save image of type {type(img_data)}")
            except Exception as e:
                print(f"Warning: Failed to save image {out_path}: {e}")

    def print(self):
        """Print the result."""
        print(f"Input: {self.get('input_path')}")
        print(f"Page: {self.get('page_index')}/{self.get('page_count')}")
        print(f"Size: {self.get('width')}x{self.get('height')}")
        parsing_res_list = self.get("parsing_res_list", [])
        print(f"Blocks: {len(parsing_res_list)}")
        for i, block in enumerate(parsing_res_list):
            print(f"\nBlock {i+1}:")
            print(f"  Label: {block.label}")
            print(f"  BBox: {block.bbox}")
            content_preview = block.content[:100] + "..." if len(block.content) > 100 else block.content
            print(f"  Content: {content_preview}")


class PaddleOCRVL:
    """
    OpenVINO ç‰ˆæœ¬çš„ PaddleOCR-VL Pipeline
    ä½¿ç”¨ OpenVINO è¿›è¡Œå¸ƒå±€æ£€æµ‹å’Œ VLM æ¨ç†
    """
    
    # ModelScope æ¨¡å‹ ID
    LAYOUT_MODEL_ID = "zhaohb/PP-DocLayoutV2-ov"
    VLM_MODEL_ID = "zhaohb/PaddleOCR-Vl-OV"
    
    def __init__(
        self,
        layout_model_path: Optional[str] = None,
        vlm_model_path: Optional[str] = None,
        vlm_device: str = "CPU",
        layout_device: str = "NPU",
        use_layout_detection: bool = True,
        use_chart_recognition: bool = True,
        use_seal_recognition: bool = False,
        use_ocr_for_image_block: bool = False,
        merge_layout_blocks: bool = True,
        markdown_ignore_labels: Optional[List[str]] = None,
        cache_dir: Optional[str] = None,
        layout_precision: str = "fp16",
        llm_int4_compress: bool = False,
        vision_int8_quant: bool = True,
        llm_int8_compress: bool = True,
        llm_int8_quant: bool = True,
    ):
        """
        åˆå§‹åŒ– PaddleOCR-VL Pipeline
        
        Args:
            layout_model_path: å¸ƒå±€æ£€æµ‹æ¨¡å‹è·¯å¾„ï¼ˆOpenVINO IR .xml æ–‡ä»¶ï¼‰ï¼Œå¦‚æœä¸º None åˆ™è‡ªåŠ¨ä¸‹è½½
            vlm_model_path: VLM æ¨¡å‹è·¯å¾„ï¼ˆåŒ…å« vision.xml, vision_mlp.xml, llm_stateful.xml ç­‰çš„ç›®å½•ï¼‰ï¼Œå¦‚æœä¸º None åˆ™è‡ªåŠ¨ä¸‹è½½
            vlm_device: VLM æ¨¡å‹æ¨ç†è®¾å¤‡ ("CPU", "GPU", "AUTO")
            layout_device: å¸ƒå±€æ£€æµ‹æ¨¡å‹ï¼ˆPP-DocLayoutV2ï¼‰æ¨ç†è®¾å¤‡ï¼Œé»˜è®¤ "NPU" ("CPU", "GPU", "NPU", "AUTO")
            use_layout_detection: æ˜¯å¦ä½¿ç”¨å¸ƒå±€æ£€æµ‹
            use_chart_recognition: æ˜¯å¦ä½¿ç”¨å›¾è¡¨è¯†åˆ«
            merge_layout_blocks: æ˜¯å¦åˆå¹¶å¸ƒå±€å—
            markdown_ignore_labels: Markdown è¾“å‡ºä¸­å¿½ç•¥çš„æ ‡ç­¾åˆ—è¡¨
            cache_dir: ModelScope æ¨¡å‹ç¼“å­˜ç›®å½•ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨é»˜è®¤ç¼“å­˜ç›®å½•
            layout_precision: å¸ƒå±€æ£€æµ‹æ¨¡å‹ç²¾åº¦é€‰æ‹©ï¼Œé€‰é¡¹: "fp16", "fp32", "combined_fp16", "combined_fp32"
                - "fp16": FP16 ç²¾åº¦æ¨¡å‹ï¼ˆæ›´å¿«ï¼Œå†…å­˜å ç”¨æ›´ä½ï¼‰
                - "fp32": FP32 ç²¾åº¦æ¨¡å‹ï¼ˆæ›´å‡†ç¡®ï¼Œé»˜è®¤ï¼‰
                - "combined_fp16": FP16 åˆå¹¶æ¨¡å‹ï¼ˆåˆå¹¶äº† batch size å’Œ boxes èŠ‚ç‚¹ï¼‰
                - "combined_fp32": FP32 åˆå¹¶æ¨¡å‹ï¼ˆåˆå¹¶äº† batch size å’Œ boxes èŠ‚ç‚¹ï¼‰
                æ³¨æ„ï¼šå¦‚æœæŒ‡å®šäº† layout_model_path ä¸ºå…·ä½“çš„ .xml æ–‡ä»¶è·¯å¾„ï¼Œæ­¤å‚æ•°å°†è¢«å¿½ç•¥
        """
        self.vlm_device = vlm_device
        self.layout_device = layout_device
        self.use_layout_detection = use_layout_detection
        self.use_chart_recognition = use_chart_recognition
        # å¯¹é½ PaddleXï¼šseal / image-block OCR çš„é»˜è®¤å¼€å…³éœ€è¦ä¿å­˜åœ¨ pipeline ä¸Š
        self.use_seal_recognition = use_seal_recognition
        self.use_ocr_for_image_block = use_ocr_for_image_block
        self.merge_layout_blocks = merge_layout_blocks
        self.markdown_ignore_labels = markdown_ignore_labels or [
            "number", "footnote", "header", "header_image",
            "footer", "footer_image", "aside_text"
        ]
        self.cache_dir = cache_dir
        self.layout_precision = layout_precision
        
        # éªŒè¯ precision å‚æ•°
        valid_precisions = ["fp16", "fp32", "combined_fp16", "combined_fp32"]
        if layout_precision not in valid_precisions:
            raise ValueError(
                f"Unsupported layout_precision: {layout_precision}. "
                f"Supported options: {valid_precisions}"
            )
        
        # è‡ªåŠ¨ä¸‹è½½æˆ–éªŒè¯æ¨¡å‹è·¯å¾„
        if layout_model_path is None:
            if not MODELSCOPE_AVAILABLE:
                raise ImportError("modelscope is required for auto-download. Install with: pip install modelscope")
            print(f"ğŸ“¥ è‡ªåŠ¨ä¸‹è½½å¸ƒå±€æ£€æµ‹æ¨¡å‹: {self.LAYOUT_MODEL_ID} (precision: {layout_precision})")
            layout_model_path = self._download_layout_model()
        else:
            layout_model_path = self._ensure_layout_model(layout_model_path)
        
        if vlm_model_path is None:
            if not MODELSCOPE_AVAILABLE:
                raise ImportError("modelscope is required for auto-download. Install with: pip install modelscope")
            print(f"ğŸ“¥ è‡ªåŠ¨ä¸‹è½½ VLM æ¨¡å‹: {self.VLM_MODEL_ID}")
            vlm_model_path = self._download_vlm_model()
        else:
            vlm_model_path = self._ensure_vlm_model(vlm_model_path)
        
        self.layout_model_path = layout_model_path
        self.vlm_model_path = vlm_model_path
        
        # åˆå§‹åŒ– OpenVINO Core
        self.core = ov.Core()
        
        # åŠ è½½å¸ƒå±€æ£€æµ‹æ¨¡å‹
        if self.use_layout_detection:
            self._load_layout_model()
        
        # åŠ è½½ VLM æ¨¡å‹
        self._load_vlm_model(llm_int4_compress=llm_int4_compress, vision_int8_quant=vision_int8_quant, llm_int8_compress=llm_int8_compress, llm_int8_quant=llm_int8_quant)
        
        # ä¸éœ€è¦å•ç‹¬åˆå§‹åŒ–å›¾åƒå¤„ç†å™¨ï¼ŒVLM æ¨¡å‹å†…éƒ¨ä¼šå¤„ç†
    
    def _download_layout_model(self) -> str:
        """ä¸‹è½½å¸ƒå±€æ£€æµ‹æ¨¡å‹"""
        if not MODELSCOPE_AVAILABLE:
            raise ImportError("modelscope is required for auto-download. Install with: pip install modelscope")
        
        print(f"æ­£åœ¨ä» ModelScope ä¸‹è½½å¸ƒå±€æ£€æµ‹æ¨¡å‹: {self.LAYOUT_MODEL_ID}")
        model_dir = snapshot_download(self.LAYOUT_MODEL_ID, cache_dir=self.cache_dir)
        model_dir = Path(model_dir)
        xml_files: List[Path] = []
        
        # æ ¹æ® precision é€‰æ‹©å¯¹åº”çš„æ¨¡å‹æ–‡ä»¶
        precision_map = {
            "fp16": "pp_doclayoutv2_f16.xml",
            "fp32": "pp_doclayoutv2_f32.xml",
            "combined_fp16": "pp_doclayoutv2_f16_combined.xml",
            "combined_fp32": "pp_doclayoutv2_f32_combined.xml",
        }
        
        model_filename = precision_map.get(self.layout_precision)
        model_path = model_dir / model_filename if model_filename else None
        
        # å¦‚æœæŒ‡å®šçš„ç²¾åº¦æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•æŸ¥æ‰¾å…¶ä»–å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶
        if model_path is None or not model_path.exists():
            print(f"âš ï¸  æŒ‡å®šçš„ç²¾åº¦æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_filename if model_filename else 'N/A'}")
            # æŸ¥æ‰¾æ‰€æœ‰ .xml æ–‡ä»¶
            xml_files = list(model_dir.glob("*.xml"))
            if not xml_files:
                raise FileNotFoundError(
                    f"åœ¨ä¸‹è½½çš„æ¨¡å‹ç›®å½•ä¸­æœªæ‰¾åˆ° .xml æ–‡ä»¶: {model_dir}\n"
                    f"layout_precision={self.layout_precision}"
                )

            # ä¼˜å…ˆé€‰æ‹©åˆå¹¶ç‰ˆæœ¬ï¼ˆcombined_*ï¼‰
            combined_files = [f for f in xml_files if "combined" in f.name]
            if combined_files:
                model_path = combined_files[0]
                print(f"âš ï¸  ä½¿ç”¨æ‰¾åˆ°çš„åˆå¹¶æ¨¡å‹: {model_path.name}")
            else:
                # å¦åˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„æ–‡ä»¶
                model_path = xml_files[0]
                print(f"âš ï¸  ä½¿ç”¨æ‰¾åˆ°çš„æ¨¡å‹: {model_path.name}")
        else:
            print(f"âœ… ä½¿ç”¨æŒ‡å®šçš„ç²¾åº¦æ¨¡å‹: {model_filename}")
        
        # æ£€æŸ¥å¯¹åº”çš„ .bin æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        bin_path = model_path.with_suffix(".bin")
        if not bin_path.exists():
            raise FileNotFoundError(f"å¯¹åº”çš„ .bin æ–‡ä»¶ä¸å­˜åœ¨: {bin_path}")
        
        print(f"âœ… å¸ƒå±€æ£€æµ‹æ¨¡å‹å·²ä¸‹è½½åˆ°: {model_path}")
        return str(model_path)
    
    def _download_vlm_model(self) -> str:
        """ä¸‹è½½ VLM æ¨¡å‹"""
        if not MODELSCOPE_AVAILABLE:
            raise ImportError("modelscope is required for auto-download. Install with: pip install modelscope")
        
        print(f"æ­£åœ¨ä» ModelScope ä¸‹è½½ VLM æ¨¡å‹: {self.VLM_MODEL_ID}")
        model_dir = snapshot_download(self.VLM_MODEL_ID, cache_dir=self.cache_dir)
        
        # éªŒè¯å¿…è¦çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        required_files = ["vision.xml", "llm_stateful.xml", "llm_embd.xml"]
        model_path = Path(model_dir)
        missing_files = []
        for file_name in required_files:
            if not (model_path / file_name).exists():
                missing_files.append(file_name)
        
        if missing_files:
            raise FileNotFoundError(
                f"åœ¨ä¸‹è½½çš„æ¨¡å‹ç›®å½•ä¸­ç¼ºå°‘å¿…è¦çš„æ–‡ä»¶: {missing_files}\n"
                f"æ¨¡å‹ç›®å½•: {model_dir}"
            )
        
        print(f"âœ… VLM æ¨¡å‹å·²ä¸‹è½½åˆ°: {model_dir}")
        return str(model_dir)
    
    def _ensure_layout_model(self, model_path: str) -> str:
        """ç¡®ä¿å¸ƒå±€æ£€æµ‹æ¨¡å‹å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä¸‹è½½"""
        model_path_obj = Path(model_path)
        
        # å¦‚æœæ˜¯ç›®å½•ï¼Œæ ¹æ® precision æŸ¥æ‰¾å¯¹åº”çš„ .xml æ–‡ä»¶
        if model_path_obj.is_dir():
            # æ ¹æ® precision ä¼˜å…ˆçº§æœç´¢
            precision_map = {
                "fp16": ["pp_doclayoutv2_f16.xml", "*.xml"],
                "fp32": ["pp_doclayoutv2_f32.xml", "*.xml"],
                "combined_fp16": ["pp_doclayoutv2_f16_combined.xml", "pp_doclayoutv2_f16.xml", "*.xml"],
                "combined_fp32": ["pp_doclayoutv2_f32_combined.xml", "pp_doclayoutv2_f32.xml", "*.xml"],
            }
            
            search_patterns = precision_map.get(self.layout_precision, ["*.xml"])
            xml_file = None
            
            for pattern in search_patterns:
                if pattern == "*.xml":
                    xml_files = list(model_path_obj.glob(pattern))
                    if xml_files:
                        xml_file = xml_files[0]
                    break
                else:
                    candidate = model_path_obj / pattern
                    if candidate.exists():
                        xml_file = candidate
                        break
            
            if xml_file is None:
                print(f"âš ï¸  åœ¨æŒ‡å®šç›®å½•ä¸­æœªæ‰¾åˆ°åŒ¹é…çš„ .xml æ–‡ä»¶ï¼Œå°è¯•è‡ªåŠ¨ä¸‹è½½: {model_path}")
                return self._download_layout_model()
            
            # æ£€æŸ¥å¯¹åº”çš„ .bin æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            bin_path = xml_file.with_suffix(".bin")
            if not bin_path.exists():
                print(f"âš ï¸  å¯¹åº”çš„ .bin æ–‡ä»¶ä¸å­˜åœ¨: {bin_path}ï¼Œå°è¯•è‡ªåŠ¨ä¸‹è½½")
                return self._download_layout_model()
            
            return str(xml_file)
        
        # å¦‚æœæ˜¯æ–‡ä»¶è·¯å¾„ï¼Œæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not model_path_obj.exists():
            print(f"âš ï¸  æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•è‡ªåŠ¨ä¸‹è½½: {model_path}")
            return self._download_layout_model()
        
        # å¦‚æœæŒ‡å®šäº†å…·ä½“çš„ .xml æ–‡ä»¶è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨ï¼ˆå¿½ç•¥ precision å‚æ•°ï¼‰
        if model_path_obj.suffix.lower() == ".xml":
            bin_path = model_path_obj.with_suffix(".bin")
            if not bin_path.exists():
                print(f"âš ï¸  å¯¹åº”çš„ .bin æ–‡ä»¶ä¸å­˜åœ¨: {bin_path}ï¼Œå°è¯•è‡ªåŠ¨ä¸‹è½½")
                return self._download_layout_model()
            return model_path
        
        return model_path
    
    def _ensure_vlm_model(self, model_path: str) -> str:
        """ç¡®ä¿ VLM æ¨¡å‹å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä¸‹è½½"""
        model_path_obj = Path(model_path)
        
        if not model_path_obj.exists():
            print(f"âš ï¸  æ¨¡å‹ç›®å½•ä¸å­˜åœ¨ï¼Œå°è¯•è‡ªåŠ¨ä¸‹è½½: {model_path}")
            return self._download_vlm_model()
        
        # éªŒè¯å¿…è¦çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        required_files = ["vision.xml", "llm_stateful.xml", "llm_embd.xml"]
        missing_files = []
        for file_name in required_files:
            if not (model_path_obj / file_name).exists():
                missing_files.append(file_name)
        
        if missing_files:
            print(f"âš ï¸  æ¨¡å‹ç›®å½•ä¸­ç¼ºå°‘å¿…è¦çš„æ–‡ä»¶ {missing_files}ï¼Œå°è¯•è‡ªåŠ¨ä¸‹è½½")
            return self._download_vlm_model()
        
        return model_path
    
    def _load_layout_model(self):
        """åŠ è½½å¸ƒå±€æ£€æµ‹æ¨¡å‹"""
        model = self.core.read_model(self.layout_model_path)
        
        # æ·»åŠ é¢„å¤„ç†
        prep = ov.preprocess.PrePostProcessor(model)
        prep.input("image").tensor().set_layout(ov.Layout("NCHW"))
        prep.input("image").preprocess().scale([255, 255, 255])
        model = prep.build()
        
        # ç¼–è¯‘æ¨¡å‹ï¼ˆä½¿ç”¨ layout_deviceï¼‰
        self.layout_compiled_model = self.core.compile_model(model, self.layout_device)
        self.layout_request = self.layout_compiled_model.create_infer_request()
    
    def _load_vlm_model(self, llm_int4_compress=False, vision_int8_quant=True, llm_int8_compress=True, llm_int8_quant=True):
        """åŠ è½½ VLM æ¨¡å‹"""
        self.vlm_model = OVPaddleOCRVLForCausalLM(
            core=self.core,
            ov_model_path=self.vlm_model_path,
            device=self.vlm_device,
            llm_int4_compress=llm_int4_compress, 
            vision_int8_quant=vision_int8_quant, 
            llm_int8_compress=llm_int8_compress, 
            llm_int8_quant=llm_int8_quant, 
        )
    
    def predict(
        self,
        input: Union[str, List[str], np.ndarray, List[np.ndarray]],
        use_layout_detection: Optional[bool] = None,
        use_chart_recognition: Optional[bool] = None,
        use_seal_recognition: Optional[bool] = None,
        use_ocr_for_image_block: Optional[bool] = None,
        layout_threshold: Optional[Union[float, dict]] = None,
        layout_nms: Optional[bool] = None,
        layout_unclip_ratio: Optional[Union[float, tuple]] = None,
        layout_merge_bboxes_mode: Optional[str] = None,
        layout_shape_mode: Optional[str] = "auto",
        max_new_tokens: Optional[int] = None,
        prompt_label: str = "ocr",
        **kwargs,
    ):
        """
        é¢„æµ‹æ–‡æ¡£è§£æç»“æœ
        
        Args:
            input: è¾“å…¥å›¾åƒè·¯å¾„ã€å›¾åƒè·¯å¾„åˆ—è¡¨ã€numpy æ•°ç»„æˆ– numpy æ•°ç»„åˆ—è¡¨
            use_layout_detection: æ˜¯å¦ä½¿ç”¨å¸ƒå±€æ£€æµ‹ï¼ˆè¦†ç›–åˆå§‹åŒ–è®¾ç½®ï¼‰
            layout_threshold: å¸ƒå±€æ£€æµ‹é˜ˆå€¼
            layout_nms: æ˜¯å¦ä½¿ç”¨ NMS
            layout_unclip_ratio: åæ ‡æ‰©å±•æ¯”ä¾‹
            layout_merge_bboxes_mode: å¸ƒå±€æ¡†åˆå¹¶æ¨¡å¼
            max_new_tokens: æœ€å¤§ç”Ÿæˆ token æ•°
            **kwargs: å…¶ä»–å‚æ•°
        
        Yields:
            PaddleOCRVLResult: è§£æç»“æœå¯¹è±¡
        """
        # ç¡®å®šæ˜¯å¦ä½¿ç”¨å¸ƒå±€æ£€æµ‹
        if use_layout_detection is None:
            use_layout_detection = self.use_layout_detection

        # å¯¹é½ PaddleXï¼šNone è¡¨ç¤ºä½¿ç”¨åˆå§‹åŒ–é»˜è®¤å€¼
        if use_chart_recognition is None:
            use_chart_recognition = self.use_chart_recognition

        # å¯¹é½ PaddleXï¼šNone è¡¨ç¤ºä½¿ç”¨åˆå§‹åŒ–é»˜è®¤å€¼
        if use_seal_recognition is None:
            use_seal_recognition = self.use_seal_recognition

        # å¯¹é½ PaddleXï¼šNone è¡¨ç¤ºä½¿ç”¨åˆå§‹åŒ–é»˜è®¤å€¼
        if use_ocr_for_image_block is None:
            use_ocr_for_image_block = self.use_ocr_for_image_block

        # layout shape mode default
        if layout_shape_mode is None:
            layout_shape_mode = "auto"

        # å¯¹é½ PaddleXï¼šå…³é—­ layout_detection æ—¶ï¼Œprompt_label ä¼šå½±å“å¼€å¯çš„è¯†åˆ«åˆ†æ”¯
        if not use_layout_detection and isinstance(prompt_label, str):
            if prompt_label.lower() == "seal":
                use_seal_recognition = True
            elif prompt_label.lower() == "chart":
                use_chart_recognition = True
        
        # å¤„ç†è¾“å…¥
        if isinstance(input, str):
            inputs = [input]
        elif isinstance(input, np.ndarray):
            inputs = [input]
        elif isinstance(input, list):
            inputs = input
        else:
            raise ValueError(f"Unsupported input type: {type(input)}")
        
        # å¤„ç†æ¯ä¸ªè¾“å…¥
        for idx, inp in enumerate(inputs):
            # è¯»å–å›¾åƒ
            if isinstance(inp, str):
                image = cv2.imread(inp)
                input_path = inp
            elif isinstance(inp, np.ndarray):
                image = inp
                input_path = None
            else:
                raise ValueError(f"Unsupported input item type: {type(inp)}")
            
            if image is None:
                raise ValueError(f"Failed to load image: {inp}")
            
            # æ‰§è¡Œ CV å¤„ç†ï¼ˆå¸ƒå±€æ£€æµ‹ï¼‰
            results_cv = self._process_cv(
                image,
                input_path,
                use_layout_detection=use_layout_detection,
                layout_threshold=layout_threshold,
                layout_nms=layout_nms,
                layout_unclip_ratio=layout_unclip_ratio,
                layout_merge_bboxes_mode=layout_merge_bboxes_mode,
                layout_shape_mode=layout_shape_mode,
                prompt_label=prompt_label,
            )
            
            # æ‰§è¡Œ VLM å¤„ç†ï¼ˆå¸ƒå±€è§£æï¼‰
            result = self._process_vlm(
                results_cv,
                max_new_tokens=max_new_tokens,
                use_chart_recognition=use_chart_recognition,
                use_seal_recognition=use_seal_recognition,
                use_ocr_for_image_block=use_ocr_for_image_block,
                layout_shape_mode=layout_shape_mode,
            )
            
            yield result
    
    def _process_cv(
        self,
        image: np.ndarray,
        input_path: Optional[str],
        page_index: Optional[int] = None,
        use_layout_detection: bool = True,
        layout_threshold: Optional[Union[float, dict]] = None,
        layout_nms: Optional[bool] = None,
        layout_unclip_ratio: Optional[Union[float, tuple]] = None,
        layout_merge_bboxes_mode: Optional[str] = None,
        layout_shape_mode: str = "auto",
        prompt_label: str = "ocr",
    ):
        """
        å¤„ç†è®¡ç®—æœºè§†è§‰éƒ¨åˆ†ï¼ˆå¸ƒå±€æ£€æµ‹ï¼‰
        å‚è€ƒ PaddleX çš„å®ç°ï¼Œç¡®ä¿åŠŸèƒ½ä¸€è‡´
        
        Args:
            image: è¾“å…¥å›¾åƒï¼ˆBGR æ ¼å¼ï¼‰
            input_path: è¾“å…¥è·¯å¾„
            page_index: é¡µé¢ç´¢å¼•
            use_layout_detection: æ˜¯å¦ä½¿ç”¨å¸ƒå±€æ£€æµ‹
            layout_threshold: å¸ƒå±€æ£€æµ‹é˜ˆå€¼
            layout_nms: æ˜¯å¦ä½¿ç”¨ NMS
            layout_unclip_ratio: åæ ‡æ‰©å±•æ¯”ä¾‹
            layout_merge_bboxes_mode: å¸ƒå±€æ¡†åˆå¹¶æ¨¡å¼
            prompt_label: ä¸ä½¿ç”¨å¸ƒå±€æ£€æµ‹æ—¶çš„é»˜è®¤æ ‡ç­¾ï¼ˆé»˜è®¤ "ocr"ï¼‰
        
        Returns:
            dict: åŒ…å«å¸ƒå±€æ£€æµ‹ç»“æœçš„å­—å…¸ï¼Œæ ¼å¼ä¸ PaddleX ä¸€è‡´
        """
        # æ–‡æ¡£é¢„å¤„ç†ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œç›´æ¥ä½¿ç”¨åŸå›¾ï¼‰
        # å¦‚æœåç»­éœ€è¦æ–‡æ¡£é¢„å¤„ç†ï¼ˆå¦‚æ–¹å‘æ ¡æ­£ã€å»å¼¯æ›²ç­‰ï¼‰ï¼Œå¯ä»¥åœ¨è¿™é‡Œæ·»åŠ 
        doc_preprocessor_image = image.copy()
        doc_preprocessor_res = {"output_img": doc_preprocessor_image}
        
        # å¸ƒå±€æ£€æµ‹
        if use_layout_detection and self.use_layout_detection:
            # æ‰§è¡Œå¸ƒå±€æ£€æµ‹
            layout_det_res = self._layout_detection(
                doc_preprocessor_image,
                threshold=layout_threshold or 0.5,
                layout_nms=layout_nms if layout_nms is not None else True,
                layout_unclip_ratio=layout_unclip_ratio or [1.0, 1.0],
                layout_merge_bboxes_mode=layout_merge_bboxes_mode,
                layout_shape_mode=layout_shape_mode,
            )

            # æå–æ–‡æ¡£ä¸­çš„å›¾åƒï¼ˆå‚è€ƒ PaddleX çš„ gather_imgsï¼‰
            imgs_in_doc = gather_imgs(doc_preprocessor_image, layout_det_res["boxes"])
            
            # è®¾ç½® input_path å’Œ page_index
            layout_det_res["input_path"] = input_path
            layout_det_res["page_index"] = page_index
        else:
            # å¦‚æœä¸ä½¿ç”¨å¸ƒå±€æ£€æµ‹ï¼Œåˆ›å»ºå…¨å›¾æ¡†ï¼ˆå‚è€ƒ PaddleX çš„å®ç°ï¼‰
            h, w = doc_preprocessor_image.shape[:2]
            layout_det_res = {
                "input_path": input_path,
                "page_index": page_index,
                "boxes": [
                    {
                        "cls_id": 0,
                        "label": prompt_label.lower(),
                        "score": 1.0,
                        "coordinate": [0, 0, w, h],
                    }
                ],
            }
            # ä¸ä½¿ç”¨å¸ƒå±€æ£€æµ‹æ—¶ï¼Œä¸æå–å›¾åƒ
            imgs_in_doc = []
        
        # åˆ›å»º LayoutDetectionResult å¯¹è±¡å¹¶è·å– json å’Œ img
        import os
        layout_det_result_obj = LayoutDetectionResult(
            input_path=os.path.abspath(input_path) if input_path else None,
            boxes=layout_det_res["boxes"],
            page_index=page_index,
            input_img=doc_preprocessor_image
        )
        
        # å°† layout å¯è§†åŒ–ç»“æœå›¾ä¿å­˜åˆ° output ç›®å½•ï¼ˆç”¨æˆ·éœ€æ±‚ï¼‰ã€‚
        # åŒæ—¶ä¿ç•™ç¯å¢ƒå˜é‡è¦†ç›–ï¼šPADDLEOCR_VL_DEBUG_SAVE_DIR=/path/to/dir
        try:
            save_dir = os.environ.get("PADDLEOCR_VL_DEBUG_SAVE_DIR", "").strip()
            if not save_dir:
                # é»˜è®¤ä¿å­˜åˆ° paddleocr_vl_ov/outputï¼ˆä¸ç°æœ‰æµ‹è¯•è„šæœ¬è¾“å‡ºç›®å½•ä¿æŒä¸€è‡´ï¼‰
                save_dir = str(Path(__file__).resolve().parents[2] / "output")

            # é¿å…åŒåè¦†ç›–ï¼šåŠ å…¥ page_index
            base_name = Path(layout_det_result_obj._get_input_fn()).stem
            page_tag = f"_page_{int(page_index):04d}" if page_index is not None else ""
            out_file = Path(save_dir) / f"{base_name}{page_tag}_layout_res.png"
            layout_det_result_obj.save_to_img(save_path=out_file.as_posix())
        except Exception:
            pass
        
        return {
            "input_path": input_path,
            "page_index": page_index,
            "page_count": 1,
            "doc_preprocessor_image": doc_preprocessor_image,
            "doc_preprocessor_res": doc_preprocessor_res,
            "layout_det_results": [layout_det_res],
            "imgs_in_doc": [imgs_in_doc],
        }
    
    def _layout_detection(
        self,
        image: np.ndarray,
        threshold: Union[float, dict] = 0.5,
        layout_nms: bool = True,
        layout_unclip_ratio: Union[float, tuple] = None,
        layout_merge_bboxes_mode: str = None,
        layout_shape_mode: str = "auto",
    ):
        """
        æ‰§è¡Œå¸ƒå±€æ£€æµ‹
        
        Args:
            image: è¾“å…¥å›¾åƒï¼ˆBGR æ ¼å¼ï¼‰
            threshold: æ£€æµ‹é˜ˆå€¼
            layout_nms: æ˜¯å¦ä½¿ç”¨ NMS
            layout_unclip_ratio: åæ ‡æ‰©å±•æ¯”ä¾‹
            layout_merge_bboxes_mode: å¸ƒå±€æ¡†åˆå¹¶æ¨¡å¼
        
        Returns:
            dict: å¸ƒå±€æ£€æµ‹ç»“æœ
        """
        orig_h, orig_w = image.shape[:2]
        
        # é¢„å¤„ç†
        input_blob, scale_h, scale_w = preprocess_image_doclayout(image)
        
        # å‡†å¤‡è¾“å…¥
        input_tensors = self.layout_compiled_model.inputs
        input_data = {}
        
        # breakpoint()
        for inp in input_tensors:
            inp_name = inp.get_any_name()
            if inp_name == "im_shape":
                input_data[inp_name] = np.array([800, 800], dtype=np.float32)[np.newaxis, ...]
            elif inp_name == "image":
                input_data[inp_name] = input_blob
            elif inp_name == "scale_factor":
                input_data[inp_name] = np.array([[scale_h, scale_w]], dtype=np.float32)
        
        # å¦‚æœè¾“å…¥åç§°ä¸åŒ¹é…ï¼ŒæŒ‰é¡ºåºåˆ†é…
        if len(input_data) != len(input_tensors):
            input_data = {}
            input_data[input_tensors[0].get_any_name()] = np.array([800, 800], dtype=np.float32)[np.newaxis, ...]
            input_data[input_tensors[1].get_any_name()] = input_blob
            input_data[input_tensors[2].get_any_name()] = np.array([[scale_h, scale_w]], dtype=np.float32)
        
        # åˆ›å»º OpenVINO Tensor å¯¹è±¡
        input_tensors_ov = {}
        for inp in input_tensors:
            inp_name = inp.get_any_name()
            data = input_data[inp_name]
            input_tensors_ov[inp_name] = ov.Tensor(data)
        
        # æ‰§è¡Œæ¨ç†
        infer_result = self.layout_compiled_model(input_tensors_ov)
        output_tensors = self.layout_compiled_model.outputs
            # Extract output results
        output = []
        for out in output_tensors:
            output_tensor = infer_result[out]
            output_data = output_tensor.data
            output.append(output_data)
        
        # Post-processing
        if layout_unclip_ratio is None:
            layout_unclip_ratio = [1.0, 1.0]
        
        # Choose postprocess based on output shapes.
        out0 = np.array(output[0]) if len(output) > 0 else None
        out1 = np.array(output[1]) if len(output) > 1 else None
        if out0 is not None and out0.ndim == 2 and out0.shape[0] == 300 and out0.shape[1] in (6, 7) and out1 is not None and out1.size >= 1:
            # PaddleDetection exported (already NMS-ed) outputs
            results = postprocess_detections_paddle_nms(
                output,
                orig_h=orig_h,
                orig_w=orig_w,
                threshold=threshold,
                layout_nms=layout_nms,
                layout_unclip_ratio=layout_unclip_ratio,
                layout_merge_bboxes_mode=layout_merge_bboxes_mode,
                layout_shape_mode=layout_shape_mode,
            )
        else:
            # Fallback to DETR-style postprocess (older models)
            if output[0].ndim == 3:
                output[0] = np.squeeze(output[0], axis = 0)

            results = postprocess_detections_detr(
                output, scale_h, scale_w, orig_h, orig_w,
                threshold=threshold,
                layout_nms=layout_nms,
                layout_unclip_ratio=layout_unclip_ratio,
                layout_merge_bboxes_mode=layout_merge_bboxes_mode,
                layout_shape_mode=layout_shape_mode,
            )
        
        result_obj = LayoutAnalysisResult(
            {
                "input_path": None,
                "page_index": None,
                "input_img": image,
                "boxes": results,
            }
        )
        
        return result_obj
    
    def _get_label_name(self, cls_id: int) -> str:
        """è·å–æ ‡ç­¾åç§°"""
        label_list = [
            "abstract", "algorithm", "aside_text", "chart", "content", "display_formula",
            "doc_title", "figure_title", "footer", "footer_image", "footnote", "formula_number",
            "header", "header_image", "image", "inline_formula", "number", "paragraph_title",
            "reference", "reference_content", "seal", "table", "text", "vertical_text", "vision_footnote"
        ]
        if 0 <= cls_id < len(label_list):
            return label_list[cls_id]
        return "unknown"
    
    def _process_vlm(
        self,
        results_cv: dict,
        max_new_tokens: Optional[int] = None,
        use_chart_recognition: Optional[bool] = None,
        use_seal_recognition: Optional[bool] = None,
        use_ocr_for_image_block: Optional[bool] = None,
        layout_shape_mode: str = "auto",
    ):
        """
        å¤„ç†è§†è§‰è¯­è¨€æ¨¡å‹éƒ¨åˆ†ï¼ˆå¸ƒå±€è§£æï¼‰
        
        Args:
            results_cv: CV å¤„ç†ç»“æœ
            max_new_tokens: æœ€å¤§ç”Ÿæˆ token æ•°
        
        Returns:
            PaddleOCRVLResult: è§£æç»“æœå¯¹è±¡
        """
        (
            input_path,
            page_index,
            page_count,
            doc_preprocessor_image,
            doc_preprocessor_res,
            layout_det_results,
            imgs_in_doc,
        ) = (
            results_cv["input_path"],
            results_cv["page_index"],
            results_cv["page_count"],
            results_cv["doc_preprocessor_image"],
            results_cv["doc_preprocessor_res"],
            results_cv["layout_det_results"],
            results_cv["imgs_in_doc"],
        )
        
        # è·å–å¸ƒå±€è§£æç»“æœ
        parsing_res_lists, table_res_lists, spotting_res_lists, imgs_in_doc = self.get_layout_parsing_results(
            [doc_preprocessor_image],
            layout_det_results,
            imgs_in_doc,
            max_new_tokens=max_new_tokens or 4096,
            use_chart_recognition=bool(use_chart_recognition) if use_chart_recognition is not None else self.use_chart_recognition,
            use_seal_recognition=bool(use_seal_recognition) if use_seal_recognition is not None else self.use_seal_recognition,
            use_ocr_for_image_block=bool(use_ocr_for_image_block) if use_ocr_for_image_block is not None else self.use_ocr_for_image_block,
            layout_shape_mode=layout_shape_mode,
        )
        
        # ç»„è£…ç»“æœ
        parsing_res_list = parsing_res_lists[0] if parsing_res_lists else []
        table_res_list = table_res_lists[0] if table_res_lists else []
        spotting_res = spotting_res_lists[0] if spotting_res_lists else {}
        # Align with PaddleX doc_vl pipeline:
        # PaddleX does NOT reorder parsing_res_list here; it relies on layout_det_res["boxes"]
        # being already in the desired reading order.
        
        single_img_res = {
            "input_path": input_path,
            "page_index": page_index,
            "page_count": page_count,
            "width": doc_preprocessor_image.shape[1],
            "height": doc_preprocessor_image.shape[0],
            "doc_preprocessor_res": doc_preprocessor_res,
            "layout_det_res": layout_det_results[0] if layout_det_results else None,
            "table_res_list": table_res_list,
            "parsing_res_list": parsing_res_list,
            # å¯¹é½ PaddleXï¼šå°†æ¯é¡µ spotting_res å›å¡«åˆ° single_img_res
            "spotting_res": spotting_res,
            "imgs_in_doc": imgs_in_doc[0] if imgs_in_doc else [],
            "model_settings": {
                "use_doc_preprocessor": False,
                "use_layout_detection": self.use_layout_detection,
                "use_chart_recognition": bool(use_chart_recognition) if use_chart_recognition is not None else self.use_chart_recognition,
                "use_seal_recognition": bool(use_seal_recognition) if use_seal_recognition is not None else self.use_seal_recognition,
                "use_ocr_for_image_block": bool(use_ocr_for_image_block) if use_ocr_for_image_block is not None else self.use_ocr_for_image_block,
                "format_block_content": False,
                "merge_layout_blocks": self.merge_layout_blocks,
                "markdown_ignore_labels": self.markdown_ignore_labels,
                "return_layout_polygon_points": False if layout_shape_mode == "rect" else True,
            },
        }
        
        return PaddleOCRVLResult(single_img_res)
    
    def get_layout_parsing_results(
        self,
        images: List[np.ndarray],
        layout_det_results: List[dict],
        imgs_in_doc: List[List],
        max_new_tokens: int = 4096,
        use_chart_recognition: bool = False,
        use_seal_recognition: bool = False,
        use_ocr_for_image_block: bool = False,
        layout_shape_mode: str = "auto",
    ):
        """
        è·å–å¸ƒå±€è§£æç»“æœï¼ˆå‚è€ƒ PaddleX çš„å®ç°ï¼Œç¡®ä¿é€»è¾‘ä¸€è‡´ï¼‰
        
        Args:
            images: å›¾åƒåˆ—è¡¨
            layout_det_results: å¸ƒå±€æ£€æµ‹ç»“æœåˆ—è¡¨
            imgs_in_doc: æ–‡æ¡£ä¸­çš„å›¾åƒåˆ—è¡¨
            max_new_tokens: æœ€å¤§ç”Ÿæˆ token æ•°
        
        Returns:
            tuple: (parsing_res_lists, table_res_lists, spotting_res_list, imgs_in_doc)
        """
        # Align with PaddleX doc_vl pipeline:
        # - group VLM requests by (min_pixels, max_pixels)
        # - allow spotting branch
        has_spotting = False
        drop_figures_set = set()
        default_min_pixels = 112896
        default_max_pixels = 1003520

        batch_dict_by_pixel = {}
        id2pixel_key_map = {}
        image_path_to_obj_map = {}

        # å¯¹é½ PaddleXï¼š
        # - vis_image_labels: ç”¨äºå†³å®šæ˜¯å¦ç»™ block_info.image èµ‹å€¼ï¼ˆä¸æ˜¯å¦è¿›å…¥ VLM æ— å…³ï¼‰
        # - image_labels: ç”¨äºå†³å®šæ˜¯å¦è·³è¿‡ VLMï¼ˆåœ¨ image_labels å†…çš„ label ä¸è¿›å…¥ VLMï¼Œä½œä¸ºçº¯å›¾ç‰‡å—ï¼‰
        vis_image_labels = ["image", "header_image", "footer_image", "seal"]
        image_labels = [] if use_ocr_for_image_block else ["image", "header_image", "footer_image"]
        # å¯¹é½ PaddleXï¼šchart åˆ†æ”¯ç”±å…¥å‚å†³å®šï¼ˆpredict é‡Œ None->self é»˜è®¤ï¼‰
        if not use_chart_recognition:
            image_labels += ["chart"]
            vis_image_labels += ["chart"]
        # å¯¹é½ PaddleXï¼šseal åˆ†æ”¯ç”±å…¥å‚å†³å®šï¼ˆpredict é‡Œ None->self é»˜è®¤ï¼‰
        if not use_seal_recognition:
            image_labels += ["seal"]
        
        blocks = []
        for i, (image, layout_det_res, imgs_in_doc_for_img) in enumerate(zip(images, layout_det_results, imgs_in_doc)):
            layout_det_res = filter_overlap_boxes(layout_det_res, layout_shape_mode=layout_shape_mode)
            boxes = layout_det_res["boxes"]
            # å¯¹é½ PaddleXï¼šä¸åœ¨ parsing é˜¶æ®µé¢å¤–é‡æ’ boxesã€‚
            # PaddleX ç›´æ¥ä½¿ç”¨ layout_det_res["boxes"] çš„åŸå§‹é¡ºåºï¼ˆä»…åš filter_overlap_boxesï¼‰ï¼Œ
            # åç»­ crop/merge éƒ½ä¾èµ–è¯¥é¡ºåºï¼Œä»è€Œä¿è¯ parsing_res_list çš„å—é¡ºåºä¸€è‡´ã€‚
            
            # è£å‰ªå›¾åƒåŒºåŸŸ
            blocks_for_img = self._crop_by_boxes(image, boxes, layout_shape_mode=layout_shape_mode)

            # # ä¿å­˜è£å‰ªå›¾åƒä¸º jpgï¼ˆä¾¿äºè°ƒè¯•/æ ¸å¯¹ï¼‰
            # try:
            #     crop_dir = Path("output") / "cropped_blocks"
            #     crop_dir.mkdir(parents=True, exist_ok=True)
            #     for j, block in enumerate(blocks_for_img):
            #         block_img = block.get("img")
            #         if block_img is None:
            #             continue
            #         if not hasattr(block_img, "shape"):
            #             continue
            #         if getattr(block_img, "size", 0) == 0:
            #             continue

            #         label = str(block.get("label", "unknown"))
            #         safe_label = "".join(ch if ch.isalnum() or ch in ("_", "-", ".") else "_" for ch in label)

            #         # æ–‡ä»¶åï¼šé¡µåºå·_å—åºå·_label.jpgï¼ˆä¸åŒ…å«åæ ‡ï¼‰
            #         out_path = crop_dir / f"{i:03d}_{j:03d}_{safe_label}.jpg"

            #         img_to_save = block_img
            #         # ç¡®ä¿ uint8
            #         if isinstance(img_to_save, np.ndarray) and img_to_save.dtype != np.uint8:
            #             img_to_save = np.clip(img_to_save, 0, 255).astype(np.uint8)
            #         cv2.imwrite(out_path.as_posix(), img_to_save)
            # except Exception:
            #     # ä¿å­˜å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
            #     pass
            
            # åˆå¹¶å¸ƒå±€å—ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if self.merge_layout_blocks:
                blocks_for_img = merge_blocks(
                    blocks_for_img,
                    non_merge_labels=image_labels + ["table"],
                    layout_shape_mode=layout_shape_mode,
                )
            
            blocks.append(blocks_for_img)
            
            # å‡†å¤‡ VLM è¾“å…¥ï¼ˆå‚è€ƒ PaddleX doc_vlï¼‰
            for j, block in enumerate(blocks_for_img):
                block_img = block["img"]
                block_label = block["label"]
                
                if block_label not in image_labels and block_img is not None:
                    figure_token_map = {}
                    text_prompt = "OCR:"
                    min_pixels = default_min_pixels
                    max_pixels = default_max_pixels
                    drop_figures = []
                    
                    if block_label == "table":
                        text_prompt = "Table Recognition:"
                        block_img, figure_token_map, drop_figures = tokenize_figure_of_table(
                            block_img, block["box"], imgs_in_doc_for_img
                        )
                    elif block_label == "chart" and use_chart_recognition:
                        text_prompt = "Chart Recognition:"
                    elif "formula" in block_label and block_label != "formula_number":
                        text_prompt = "Formula Recognition:"
                        crop_img = crop_margin(block_img)
                        try:
                            w0, h0, _ = crop_img.shape
                            if w0 > 2 and h0 > 2:
                                block_img = crop_img
                        except Exception:
                            pass
                    elif block_label == "spotting":
                        text_prompt = "Spotting:"
                        has_spotting = True

                    pixel_key = (min_pixels, max_pixels)
                    if pixel_key not in batch_dict_by_pixel:
                        batch_dict_by_pixel[pixel_key] = {
                            "images": [],
                            "queries": [],
                            "figure_token_maps": [],
                            "vlm_block_ids": [],
                            "curr_vlm_block_idx": 0,
                        }
                    batch_dict_by_pixel[pixel_key]["images"].append(block_img)
                    batch_dict_by_pixel[pixel_key]["queries"].append(text_prompt)
                    batch_dict_by_pixel[pixel_key]["figure_token_maps"].append(figure_token_map)
                    batch_dict_by_pixel[pixel_key]["vlm_block_ids"].append((i, j))
                    id2pixel_key_map[(i, j)] = pixel_key
                    
                    drop_figures_set.update(drop_figures)  # å‚è€ƒ PaddleX ç¬¬ 277 è¡Œ

        # VLM æ¨ç†ï¼šæŒ‰ (min_pixels, max_pixels) åˆ†æ¡¶ï¼ˆå¯¹é½ PaddleX doc_vlï¼‰
        for pixel_key in batch_dict_by_pixel:
            min_pixels, max_pixels = pixel_key
            images_bucket = batch_dict_by_pixel[pixel_key]["images"]
            queries_bucket = batch_dict_by_pixel[pixel_key]["queries"]
            # Spotting åˆ†æ”¯ä¸å¼ºåˆ¶è¦†ç›– min/max_pixelsï¼ˆä¸ PaddleX è¡Œä¸ºä¸€è‡´ï¼‰
            vlm_kwargs = {"max_new_tokens": max_new_tokens}
            if not has_spotting:
                vlm_kwargs["min_pixels"] = min_pixels
                vlm_kwargs["max_pixels"] = max_pixels

            batch_results = self._vlm_predict(
                images_bucket,
                queries_bucket,
                **vlm_kwargs,
            )
            batch_dict_by_pixel[pixel_key]["vlm_results"] = batch_results
        
        # ç»„è£…è§£æç»“æœ
        parsing_res_lists = []
        table_res_lists = []
        spotting_res_list = []
        table_blocks = []
        
        for i, blocks_for_img in enumerate(blocks):
            parsing_res_list = []
            table_res_list = []
            spotting_res = {}
            
            for j, block in enumerate(blocks_for_img):
                block_img = block["img"]
                block_bbox = block["box"]
                block_label = block["label"]
                block_content = ""
                figure_token_map = {}

                if (i, j) in id2pixel_key_map:
                    pixel_key = id2pixel_key_map[(i, j)]
                    pixel_info = batch_dict_by_pixel[pixel_key]
                    curr_vlm_block_idx = pixel_info["curr_vlm_block_idx"]
                    assert curr_vlm_block_idx < len(pixel_info["vlm_block_ids"]) and pixel_info["vlm_block_ids"][curr_vlm_block_idx] == (i, j)
                    vl_rec_result = pixel_info["vlm_results"][curr_vlm_block_idx]
                    block_img4vl = pixel_info["images"][curr_vlm_block_idx]
                    figure_token_map = pixel_info["figure_token_maps"][curr_vlm_block_idx]
                    curr_vlm_block_idx += 1
                    pixel_info["curr_vlm_block_idx"] = curr_vlm_block_idx

                    vl_rec_result["image"] = block_img4vl
                    result_str = vl_rec_result.get("result", "")
                    if result_str is None:
                        result_str = ""
                    
                    # å¤„ç†é‡å¤å†…å®¹ï¼ˆå¯¹é½ PaddleX doc_vlï¼štable=5000 else 50ï¼‰
                    min_count = 5000 if block_label == "table" else 50
                    result_str = truncate_repetitive_content(result_str, min_count=min_count)
                    
                    # å¤„ç†å…¬å¼æ ¼å¼ï¼ˆå‚è€ƒ PaddleX ç¬¬ 338-350 è¡Œï¼‰
                    if ("\\(" in result_str and "\\)" in result_str) or (
                        "\\[" in result_str and "\\]" in result_str
                    ):
                        result_str = result_str.replace("$", "")
                        result_str = (
                            result_str.replace("\\(", " $ ")
                            .replace("\\)", " $")
                            .replace("\\[\\[", "\\[")
                            .replace("\\]\\]", "\\]")
                            .replace("\\[", " $$ ")
                            .replace("\\]", " $$ ")
                        )
                        if block_label == "formula_number":
                            result_str = result_str.replace("$", "")
                    
                    # ä¿®å¤ LaTeX è¯­æ³•é”™è¯¯ï¼ˆä¿®å¤ \inS, \inR ç­‰å¸¸è§é”™è¯¯ï¼‰
                    result_str = fix_latex_syntax(result_str)
                    
                    # å¤„ç†è¡¨æ ¼ï¼ˆå‚è€ƒ PaddleX ç¬¬ 351-357 è¡Œï¼‰
                    if block_label == "table":
                        html_str = convert_otsl_to_html(result_str)
                        if html_str != "":
                            result_str = html_str

                    if block_label == "spotting":
                        h_, w_ = block_img.shape[:2]
                        result_str, spotting_res = post_process_for_spotting(result_str, w_, h_)
                    
                    block_content = result_str
                
                block_info = PaddleOCRVLBlock(
                    label=block_label,
                    bbox=block_bbox,
                    content=block_content,
                    group_id=block.get("group_id", None),
                    polygon_points=block.get("polygon_points", None),
                )
                
                # è®¾ç½®å›¾ç‰‡ä¿¡æ¯ï¼ˆå¯¹é½ PaddleX doc_vlï¼šæ„é€  image_path_to_obj_map + drop_figures_setï¼‰
                # å½“ block_label åœ¨ image_labels ä¸­ä¸” block_img ä¸ä¸º None æ—¶ï¼Œè®¾ç½® block_info.image
                if block_label in vis_image_labels and block_img is not None:
                    x_min, y_min, x_max, y_max = list(map(int, block_bbox))
                    img_path = f"imgs/img_in_{block_label}_box_{x_min}_{y_min}_{x_max}_{y_max}.jpg"
                    image_path_to_obj_map[img_path] = block_info
                    # å¦‚æœå›¾ç‰‡åœ¨ drop_figures_set ä¸­ï¼Œè·³è¿‡è¿™ä¸ª blockï¼ˆå‚è€ƒ PaddleX ç¬¬ 370-379 è¡Œï¼‰
                    if img_path not in drop_figures_set:
                        # è½¬æ¢ BGR åˆ° RGBï¼ˆå¦‚æœ block_img æ˜¯ NumPy æ•°ç»„ï¼‰
                        if isinstance(block_img, np.ndarray):
                            block_img_rgb = cv2.cvtColor(block_img, cv2.COLOR_BGR2RGB)
                            block_info.image = {
                                "path": img_path,
                                "img": Image.fromarray(block_img_rgb),
                            }
                        elif isinstance(block_img, Image.Image):
                            block_info.image = {
                                "path": img_path,
                                "img": block_img,
                            }
                    else:
                        # å¦‚æœå›¾ç‰‡åœ¨ drop_figures_set ä¸­ï¼Œè·³è¿‡è¿™ä¸ª blockï¼ˆå‚è€ƒ PaddleX ç¬¬ 379 è¡Œï¼‰
                        continue
                
                parsing_res_list.append(block_info)
                if block_label == "table":
                    table_blocks.append({"figure_token_map": figure_token_map, "block": block_info})
            
            # å¯¹é½ PaddleXï¼štable å†…å®¹é‡Œå›å¡«å›¾ç‰‡ tokenï¼ˆéœ€è¦ image_path_to_obj_mapï¼‰
            for blk_info in table_blocks:
                blk = blk_info["block"]
                ftm = blk_info["figure_token_map"]
                blk.content = untokenize_figure_of_table(blk.content, ftm, image_path_to_obj_map)

            parsing_res_lists.append(parsing_res_list)
            table_res_lists.append(table_res_list)
            spotting_res_list.append(spotting_res)
        
        # å¯¹é½ PaddleXï¼ˆè§æäº¤ï¼šsupport save block_id/block_orderã€concatenate_pages/restructure_pagesï¼‰ï¼š
        # ä¸ºæ¯ä¸ª block åˆ†é…å…¨å±€ idï¼Œä¸”å½“ group_id ä¸ºç©ºæ—¶ä½¿ç”¨ global_block_id ä½œä¸ºé»˜è®¤ group_idã€‚
        global_block_id = 0
        for one_page_parsing in parsing_res_lists:
            for blk in one_page_parsing:
                if getattr(blk, "global_block_id", None) is None:
                    blk.global_block_id = global_block_id
                if getattr(blk, "global_group_id", None) is None:
                    blk.global_group_id = global_block_id
                if getattr(blk, "group_id", None) is None:
                    blk.group_id = global_block_id
                global_block_id += 1

        # å¯¹é½ PaddleXï¼šè·¨é¡µ merge_table åå›å†™ global_group_idï¼ˆè§ PaddleX layout_parsing/merge_table.pyï¼‰
        # ä»…å½“å­˜åœ¨å¤šé¡µæ—¶æ‰å°è¯•åˆå¹¶ï¼›best-effortï¼Œä¸å½±å“ä¸»æµç¨‹ã€‚
        if len(parsing_res_lists) > 1:
            try:
                parsing_res_lists = self._merge_tables_across_pages_paddlex(parsing_res_lists)
            except Exception as e:
                logging.warning(f"merge_tables_across_pages failed: {e}")

        return parsing_res_lists, table_res_lists, spotting_res_list, imgs_in_doc

    def _merge_tables_across_pages_paddlex(self, pages: List[List["PaddleOCRVLBlock"]]) -> List[List["PaddleOCRVLBlock"]]:
        """
        å¯¹é½ PaddleX `paddlex/inference/pipelines/layout_parsing/merge_table.py::merge_tables_across_pages`ï¼š
        - å¦‚æœç›¸é‚»ä¸¤é¡µçš„è¡¨æ ¼æ»¡è¶³â€œè·¨é¡µç»­è¡¨â€æ¡ä»¶ï¼Œåˆ™å°†å½“å‰é¡µè¡¨æ ¼å†…å®¹åˆå¹¶åˆ°ä¸Šä¸€é¡µè¡¨æ ¼ï¼›
        - å›å†™ï¼š`curr_block.content = ""` ä¸” `curr_block.global_group_id = prev_block.global_block_id`ï¼›
        - æœ€åå¯¹ global_group_id åšé“¾å¼å½’ä¸€åŒ–ï¼ˆæŒ‡å‘æœ€ç»ˆçš„ group rootï¼‰ã€‚
        """
        from bs4 import BeautifulSoup  # å·²åœ¨ç¯å¢ƒéªŒè¯å­˜åœ¨

        def full_to_half(text: str) -> str:
            result = []
            for char in text:
                code = ord(char)
                if 0xFF01 <= code <= 0xFF5E:
                    result.append(chr(code - 0xFEE0))
                else:
                    result.append(char)
            return "".join(result)

        def calculate_table_total_columns(soup):
            rows = soup.find_all("tr")
            if not rows:
                return 0
            max_cols = 0
            occupied = {}
            for row_idx, row in enumerate(rows):
                col_idx = 0
                cells = row.find_all(["td", "th"])
                if row_idx not in occupied:
                    occupied[row_idx] = {}
                for cell in cells:
                    while col_idx in occupied[row_idx]:
                        col_idx += 1
                    colspan = int(cell.get("colspan", 1))
                    rowspan = int(cell.get("rowspan", 1))
                    for r in range(row_idx, row_idx + rowspan):
                        if r not in occupied:
                            occupied[r] = {}
                        for c in range(col_idx, col_idx + colspan):
                            occupied[r][c] = True
                    col_idx += colspan
                    max_cols = max(max_cols, col_idx)
            return max_cols

        def calculate_row_columns(row):
            return sum(int(cell.get("colspan", 1)) for cell in row.find_all(["td", "th"]))

        def calculate_visual_columns(row):
            return len(row.find_all(["td", "th"]))

        def detect_table_headers(soup1, soup2, max_header_rows=5):
            rows1 = soup1.find_all("tr")
            rows2 = soup2.find_all("tr")
            min_rows = min(len(rows1), len(rows2), max_header_rows)
            header_rows = 0
            headers_match = True
            for i in range(min_rows):
                cells1 = rows1[i].find_all(["td", "th"])
                cells2 = rows2[i].find_all(["td", "th"])
                if len(cells1) != len(cells2):
                    headers_match = header_rows > 0
                    break
                match = True
                for c1, c2 in zip(cells1, cells2):
                    text1 = "".join(full_to_half(c1.get_text()).split())
                    text2 = "".join(full_to_half(c2.get_text()).split())
                    if text1 != text2 or int(c1.get("colspan", 1)) != int(c2.get("colspan", 1)):
                        match = False
                        break
                if match:
                    header_rows += 1
                else:
                    headers_match = header_rows > 0
                    break
            if header_rows == 0:
                headers_match = False
            return header_rows, headers_match

        def check_rows_match(soup1, soup2):
            rows1 = soup1.find_all("tr")
            rows2 = soup2.find_all("tr")
            if not rows1 or not rows2:
                return False
            last_row = rows1[-1]
            header_count, _ = detect_table_headers(soup1, soup2)
            first_data_row = rows2[header_count] if len(rows2) > header_count else None
            if not first_data_row:
                return False
            last_cols = calculate_row_columns(last_row)
            first_cols = calculate_row_columns(first_data_row)
            last_visual = calculate_visual_columns(last_row)
            first_visual = calculate_visual_columns(first_data_row)
            return last_cols == first_cols or last_visual == first_visual

        def is_skippable(block, allowed_labels):
            continue_keywords = ["continue", "continued", "cont'd", "ç»­", "contâ€˜d", "çºŒ"]
            if block.label in allowed_labels:
                return True
            b_text = str(getattr(block, "text", "") or "").lower()
            b_fig_title = str(getattr(block, "figure_title", "") or "").lower()
            b_doc_title = str(getattr(block, "doc_title", "") or "").lower()
            b_para_title = str(getattr(block, "paragraph_title", "") or "").lower()
            full_content = f"{b_text} {b_fig_title} {b_doc_title} {b_para_title}"
            if any(kw in full_content for kw in continue_keywords):
                return True
            return False

        def can_merge_tables(prev_page, prev_block, curr_page, curr_block):
            x0, y0, x1, y1 = prev_block.bbox
            prev_width = x1 - x0
            x2, y2, x3, y4 = curr_block.bbox
            curr_width = x3 - x2
            if curr_width == 0 or prev_width == 0:
                return False, None, None
            if abs(curr_width - prev_width) / min(curr_width, prev_width) >= 0.1:
                return False, None, None

            prev_index = prev_page.index(prev_block)
            allowed_follow = all(
                b.label in ["footer", "vision_footnote", "number", "footnote", "footer_image", "seal"]
                for b in prev_page[prev_index + 1 :]
            )
            if not allowed_follow:
                return False, None, None

            curr_index = curr_page.index(curr_block)
            curr_allowed_labels = ["header", "header_image", "number", "seal"]
            allowed_before = all(is_skippable(b, curr_allowed_labels) for b in curr_page[:curr_index])
            if not allowed_before:
                return False, None, None

            html_prev = prev_block.content
            html_curr = curr_block.content
            if not html_prev or not html_curr:
                return False, None, None
            soup_prev = BeautifulSoup(html_prev, "html.parser")
            soup_curr = BeautifulSoup(html_curr, "html.parser")

            total_cols_prev = calculate_table_total_columns(soup_prev)
            total_cols_curr = calculate_table_total_columns(soup_curr)
            tables_match = total_cols_prev == total_cols_curr
            rows_match = check_rows_match(soup_prev, soup_curr)
            return (tables_match or rows_match), soup_prev, soup_curr

        def perform_table_merge(soup_prev, soup_curr):
            header_count, _ = detect_table_headers(soup_prev, soup_curr)
            rows_prev = soup_prev.find_all("tr")
            rows_curr = soup_curr.find_all("tr")
            for row in rows_curr[header_count:]:
                row.extract()
                rows_prev[-1].parent.append(row)
            return str(soup_prev)

        # main merge loop (same as PaddleX)
        for i in range(len(pages) - 1, 0, -1):
            page_curr = pages[i]
            page_prev = pages[i - 1]

            curr_block = next((b for b in page_curr if b.label == "table"), None)
            prev_block = next((b for b in reversed(page_prev) if b.label == "table"), None)

            if curr_block and prev_block:
                can_merge, soup_prev, soup_curr = can_merge_tables(page_prev, prev_block, page_curr, curr_block)
            else:
                can_merge = False

            if can_merge:
                merged_html = perform_table_merge(soup_prev, soup_curr)
                prev_block.content = merged_html
                prev_block_global_id = prev_block.global_block_id
                curr_block.content = ""
                curr_block.global_group_id = prev_block_global_id

        # normalize global_group_id chain (same as PaddleX)
        all_blocks = [block for page in pages for block in page]
        for page in pages:
            for block in page:
                if block.global_block_id != block.global_group_id:
                    block.global_group_id = all_blocks[block.global_group_id].global_group_id

        return pages
    
    def _vlm_predict(
        self,
        block_imgs: List[np.ndarray],
        text_prompts: List[str],
        max_new_tokens: int = 4096,
        min_pixels: Optional[int] = None,
        max_pixels: Optional[int] = None,
        **kwargs,
    ):
        """
        ä½¿ç”¨ VLM æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼ˆå‚è€ƒ torch_ov_test.py çš„ OpenVINO æ¨ç†æ–¹å¼ï¼‰
        
        Args:
            block_imgs: å›¾åƒå—åˆ—è¡¨
            text_prompts: æ–‡æœ¬æç¤ºåˆ—è¡¨
            max_new_tokens: æœ€å¤§ç”Ÿæˆ token æ•°
        
        Returns:
            list: VLM é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        results = []
        
        # å‡†å¤‡ generation_config
        generation_config = {
            "bos_token_id": self.vlm_model.tokenizer.bos_token_id,
            "eos_token_id": self.vlm_model.tokenizer.eos_token_id,
            "pad_token_id": self.vlm_model.tokenizer.pad_token_id,
            "max_new_tokens": max_new_tokens,
            "do_sample": False,
        }

        for idx, (block_img, text_prompt) in enumerate(zip(block_imgs, text_prompts)):
            # è½¬æ¢å›¾åƒæ ¼å¼
            if isinstance(block_img, np.ndarray):
                if len(block_img.shape) == 2:
                    block_img = cv2.cvtColor(block_img, cv2.COLOR_GRAY2RGB)
                elif block_img.shape[2] == 3:
                    block_img = cv2.cvtColor(block_img, cv2.COLOR_BGR2RGB)
                pil_image = Image.fromarray(block_img)
            else:
                pil_image = block_img
            
            # # ä¿å­˜ pil_image ä¸ºå›¾ç‰‡
            # import os
            # output_dir = "output"
            # os.makedirs(output_dir, exist_ok=True)
            # save_path = os.path.join(output_dir, f"pil_image_{idx}.png")
            # pil_image.save(save_path)
            # print(f"Saved pil_image to: {save_path}")
            # # breakpoint()
            pil_image = pil_image.resize((1200, 800), Image.Resampling.LANCZOS)
            
            # å‡†å¤‡è¾“å…¥æ¶ˆæ¯ï¼ˆä¸ torch_ov_test.py ä¸€è‡´ï¼‰
            messages = [
                {
                    "role": "user",
                    "content": [
                        {"type": "image", "image": pil_image},
                        {"type": "text", "text": text_prompt},
                    ]
                }
            ]
            
            try:
                # ä½¿ç”¨ chat æ–¹æ³•è¿›è¡Œæ¨ç†ï¼ˆä¸ torch_ov_test.py ä¸€è‡´ï¼‰
                response, history = self.vlm_model.chat(
                    messages=messages,
                    generation_config=generation_config
                )
                result_str = response
            except Exception as e:
                # å¦‚æœ VLM æ¨ç†å¤±è´¥ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
                print(f"Warning: VLM inference failed: {e}")
                result_str = ""
            
            # print("result_str: ", result_str)
            results.append({"result": result_str})
        
        return results
    
    def _crop_by_boxes(
        self, image: np.ndarray, boxes: List[dict], layout_shape_mode: str = "auto"
    ) -> List[dict]:
        """
        æ ¹æ®æ¡†è£å‰ªå›¾åƒ
        
        Args:
            image: è¾“å…¥å›¾åƒ
            boxes: æ¡†åˆ—è¡¨
        
        Returns:
            list: è£å‰ªåçš„å›¾åƒå—åˆ—è¡¨
        """
        blocks = []
        h, w = image.shape[:2]
        
        for box_info in boxes:
            coordinate = box_info["coordinate"]
            xmin, ymin, xmax, ymax = map(int, coordinate)
            
            # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
            xmin = max(0, min(xmin, w))
            ymin = max(0, min(ymin, h))
            xmax = max(xmin, min(xmax, w))
            ymax = max(ymin, min(ymax, h))
            
            if xmax > xmin and ymax > ymin:
                img_crop = image[ymin:ymax, xmin:xmax].copy()
                out_info = {
                    "img": img_crop,
                    "label": box_info["label"],
                    "box": [xmin, ymin, xmax, ymax],
                    "score": box_info["score"],
                    # Align with PaddleX schema: keep polygon points for downstream json output
                    "polygon_points": box_info.get("polygon_points", None),
                }

                # å½“ layout_shape_mode != "rect" ä¸”å­˜åœ¨ polygon_points æ—¶ï¼Œä»ä¿ç•™ polygon_points ä¾›ä¸‹æ¸¸ä½¿ç”¨ï¼Œ
                # ä½†ä¸å¯¹è£å‰ªå›¾åƒåšâ€œå¤šè¾¹å½¢å¤–å¡«å……ä¸ºç™½è‰²â€çš„ mask å¤„ç†ï¼ˆæŒ‰éœ€æ±‚ï¼šä¸å¡«å……ï¼‰ã€‚
                if layout_shape_mode != "rect" and "polygon_points" in box_info:
                    out_info["polygon_points"] = box_info.get("polygon_points", None)

                blocks.append(out_info)
        
        return blocks
    
    
    def _calculate_projection_overlap_ratio(self, bbox1, bbox2, direction="horizontal"):
        """è®¡ç®—æŠ•å½±é‡å æ¯”ä¾‹ï¼ˆå‚è€ƒ PaddleXï¼‰"""
        start_index, end_index = (1, 3) if direction == "vertical" else (0, 2)
        intersection_start = max(bbox1[start_index], bbox2[start_index])
        intersection_end = min(bbox1[end_index], bbox2[end_index])
        overlap = intersection_end - intersection_start
        if overlap <= 0:
            return 0
        ref_width = max(bbox1[end_index], bbox2[end_index]) - min(
            bbox1[start_index], bbox2[start_index]
        )
        return overlap / ref_width if ref_width > 0 else 0.0
    
    def _calculate_overlap_ratio(self, bbox1, bbox2, mode="union"):
        """è®¡ç®—é‡å æ¯”ä¾‹ï¼ˆå‚è€ƒ PaddleXï¼‰"""
        bbox1 = np.array(bbox1)
        bbox2 = np.array(bbox2)

        x_min_inter = np.maximum(bbox1[0], bbox2[0])
        y_min_inter = np.maximum(bbox1[1], bbox2[1])
        x_max_inter = np.minimum(bbox1[2], bbox2[2])
        y_max_inter = np.minimum(bbox1[3], bbox2[3])

        inter_width = np.maximum(0, x_max_inter - x_min_inter)
        inter_height = np.maximum(0, y_max_inter - y_min_inter)

        inter_area = inter_width * inter_height

        bbox1_area = (bbox1[2] - bbox1[0]) * (bbox1[3] - bbox1[1])
        bbox2_area = (bbox2[2] - bbox2[0]) * (bbox2[3] - bbox2[1])

        if mode == "union":
            ref_area = bbox1_area + bbox2_area - inter_area
        elif mode == "small":
            ref_area = np.minimum(bbox1_area, bbox2_area)
        elif mode == "large":
            ref_area = np.maximum(bbox1_area, bbox2_area)
        else:
            raise ValueError(
                f"Invalid mode {mode}, must be one of ['union', 'small', 'large']."
            )

        if ref_area == 0:
            return 0.0

        return inter_area / ref_area
    
    def _to_pil_image(self, img):
        """è½¬æ¢ä¸º PIL Image"""
        if isinstance(img, Image.Image):
            return img
        return Image.fromarray(img)
    
    def _to_np_array(self, img):
        """è½¬æ¢ä¸º numpy array"""
        if isinstance(img, Image.Image):
            return np.array(img)
        return img
    
    def _calc_merged_wh(self, images):
        """è®¡ç®—åˆå¹¶åçš„å®½é«˜ï¼ˆå‚è€ƒ PaddleXï¼‰"""
        widths = [self._to_pil_image(img).width for img in images]
        heights = [self._to_pil_image(img).height for img in images]
        w = max(widths)
        h = sum(heights)
        return w, h
    
    def _merge_images(self, images, aligns="center"):
        """åˆå¹¶å›¾åƒï¼ˆå‚è€ƒ PaddleXï¼‰"""
        if not images:
            return None
        if len(images) == 1:
            return self._to_np_array(images[0])
        if isinstance(aligns, str):
            aligns = [aligns] * (len(images) - 1)
        if len(aligns) != len(images) - 1:
            raise ValueError("The length of aligns must be len(images) - 1")
        merged = self._to_pil_image(images[0])
        for i in range(1, len(images)):
            img2 = self._to_pil_image(images[i])
            align = aligns[i - 1]
            w = max(merged.width, img2.width)
            h = merged.height + img2.height
            new_img = Image.new("RGB", (w, h), (255, 255, 255))
            if align == "center":
                x1 = (w - merged.width) // 2
                x2 = (w - img2.width) // 2
            elif align == "right":
                x1 = w - merged.width
                x2 = w - img2.width
            else:  # left
                x1 = x2 = 0
            new_img.paste(merged, (x1, 0))
            new_img.paste(img2, (x2, merged.height))
            merged = new_img
        return self._to_np_array(merged)
    
    def close(self):
        """
        å…³é—­æ¨¡å‹ï¼Œå°½å¯èƒ½é‡Šæ”¾ OpenVINO / VLM ç›¸å…³èµ„æºã€‚
        """
        # VLM
        try:
            vlm = getattr(self, "vlm_model", None)
            if vlm is not None:
                for m in ("close", "release"):
                    fn = getattr(vlm, m, None)
                    if callable(fn):
                        try:
                            fn()
                        except Exception:
                            pass
                        break
        except Exception:
            pass
        try:
            self.vlm_model = None
        except Exception:
            pass

        # Layout (optional)
        for name in ("layout_request", "layout_compiled_model"):
            try:
                obj = getattr(self, name, None)
                if obj is not None:
                    for m in ("close", "release"):
                        fn = getattr(obj, m, None)
                        if callable(fn):
                            try:
                                fn()
                            except Exception:
                                pass
                            break
            except Exception:
                pass
            try:
                setattr(self, name, None)
            except Exception:
                pass

        try:
            self.core = None
        except Exception:
            pass

