"""
OpenVINO ç‰ˆæœ¬çš„ PaddleOCR-VL Pipeline å®ç°
"""

import cv2
import numpy as np
from pathlib import Path
from typing import Union, List, Optional, Dict, Any
from PIL import Image, ImageDraw, ImageFont
import openvino as ov
import os
import logging

# å°è¯•å¯¼å…¥ modelscopeï¼Œå¦‚æœæœªå®‰è£…åˆ™ç»™å‡ºæç¤º
try:
    from modelscope import snapshot_download
    MODELSCOPE_AVAILABLE = True
except ImportError:
    MODELSCOPE_AVAILABLE = False
    logging.warning("modelscope not installed. Auto-download feature will be disabled. Install with: pip install modelscope")

# å°è¯•å¯¼å…¥ modelscopeï¼Œå¦‚æœæœªå®‰è£…åˆ™ç»™å‡ºæç¤º
try:
    from modelscope import snapshot_download
    MODELSCOPE_AVAILABLE = True
except ImportError:
    MODELSCOPE_AVAILABLE = False
    logging.warning("modelscope not installed. Auto-download feature will be disabled. Install with: pip install modelscope")

# å¯¼å…¥å¸ƒå±€æ£€æµ‹ç›¸å…³å‡½æ•°
from ..pp_doclayoutv2.ov_pp_layoutv2_infer import (
    preprocess_image_doclayout,
    postprocess_detections_detr,
    postprocess_detections_paddle_nms,
    LayoutDetectionResult,
)

# å¯¼å…¥ VLM æ¨¡å‹
from ..paddleocr_vl.ov_paddleocr_vl import OVPaddleOCRVLForCausalLM

# å¯¼å…¥å›¾åƒå¤„ç†
from ..paddleocr_vl.image_processing_paddleocr_vl import PaddleOCRVLImageProcessor

# å›¾åƒæ ‡ç­¾å®šä¹‰ï¼ˆå‚è€ƒ PaddleXï¼‰
BLOCK_LABEL_MAP = {
    "image_labels": ["image", "figure"],
}

def gather_imgs(original_img: np.ndarray, layout_det_objs: List[Dict]) -> List[Dict]:
    """
    ä»å¸ƒå±€æ£€æµ‹ç»“æœä¸­æå–å›¾åƒåŒºåŸŸ
    
    Args:
        original_img: åŸå§‹å›¾åƒï¼ˆBGR æ ¼å¼ï¼‰
        layout_det_objs: å¸ƒå±€æ£€æµ‹ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« label, coordinate, score ç­‰å­—æ®µ
    
    Returns:
        List[Dict]: æå–çš„å›¾åƒåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« path, img, coordinate, score
    """
    imgs_in_doc = []
    for det_obj in layout_det_objs:
        if det_obj["label"] in BLOCK_LABEL_MAP["image_labels"]:
            label = det_obj["label"]
            x_min, y_min, x_max, y_max = list(map(int, det_obj["coordinate"]))
            img_path = f"imgs/img_in_{label}_box_{x_min}_{y_min}_{x_max}_{y_max}.jpg"
            # ä» BGR å›¾åƒä¸­æå–åŒºåŸŸå¹¶è½¬æ¢ä¸º RGBï¼ˆPIL Image éœ€è¦ RGBï¼‰
            img = Image.fromarray(original_img[y_min:y_max, x_min:x_max, ::-1])
            imgs_in_doc.append(
                {
                    "path": img_path,
                    "img": img,
                    "coordinate": (x_min, y_min, x_max, y_max),
                    "score": det_obj["score"],
                }
            )
    return imgs_in_doc

# å¯è§†åŒ–é¡ºåºæ ‡ç­¾ï¼ˆå‚è€ƒ PaddleXï¼‰
VISUALIZE_ORDE_LABELS = [
    "text",
    "formula",
    "inline_formula",
    "display_formula",
    "algorithm",
    "reference",
    "reference_content",
    "content",
    "abstract",
    "paragraph_title",
    "doc_title",
    "vertical_text",
    "ocr",
    "number",
    "footnote",
    "header",
    "header_image",
    "footer",
    "footer_image",
    "aside_text",
]

# æ ¼å¼åŒ–å‡½æ•°ï¼ˆå‚è€ƒ PaddleXï¼‰
def format_title_func(block):
    """æ ¼å¼åŒ–æ ‡é¢˜"""
    import re
    title = block.content
    # ç®€å•çš„æ ‡é¢˜æ ¼å¼åŒ–
    title = title.rstrip(".")
    level = title.count(".") + 1 if "." in title else 1
    return f"#{'#' * level} {title}".replace("-\n", "").replace("\n", " ")

def format_centered_by_html(string):
    """HTML å±…ä¸­æ ¼å¼åŒ–"""
    return f'<div style="text-align: center;">{string}</div>'.replace("-\n", "").replace("\n", " ") + "\n"

def format_text_plain_func(block):
    """çº¯æ–‡æœ¬æ ¼å¼åŒ–"""
    return block.content

def format_image_scaled_by_html_func(block, original_image_width):
    """ç¼©æ”¾å›¾åƒ HTML æ ¼å¼åŒ–"""
    if block.image:
        image_path = block.image["path"]
        image_width = block.image["img"].width
        scale = int(image_width / original_image_width * 100)
        return '<img src="{}" alt="Image" width="{}%" />'.format(
            image_path.replace("-\n", "").replace("\n", " "), scale
        )
    return ""

def format_image_plain_func(block):
    """çº¯å›¾åƒæ ¼å¼åŒ–"""
    if block.image:
        image_path = block.image["path"]
        return "![]({})".format(image_path.replace("-\n", "").replace("\n", " "))
    return ""

def format_table_center_func(block):
    """è¡¨æ ¼å±…ä¸­æ ¼å¼åŒ–"""
    tabel_content = block.content
    tabel_content = tabel_content.replace(
        "<table>", "<table border=1 style='margin: auto; width: max-content;'>"
    )
    tabel_content = tabel_content.replace("<th>", "<th style='text-align: center;'>")
    tabel_content = tabel_content.replace("<td>", "<td style='text-align: center;'>")
    return tabel_content

def simplify_table_func(table_code):
    """ç®€åŒ–è¡¨æ ¼å‡½æ•°"""
    return "\n" + table_code.replace("<html>", "").replace("</html>", "").replace(
        "<body>", ""
    ).replace("</body>", "")

def format_first_line_func(block, templates, format_func, spliter):
    """æ ¼å¼åŒ–é¦–è¡Œ"""
    from functools import partial
    lines = block.content.split(spliter)
    for idx in range(len(lines)):
        line = lines[idx]
        if line.strip() == "":
            continue
        if line.lower() in templates:
            lines[idx] = format_func(line)
        break
    return spliter.join(lines)

def merge_formula_and_number(formula, formula_number):
    """åˆå¹¶å…¬å¼å’Œå…¬å¼ç¼–å·"""
    formula = formula.replace("$$", "")
    merge_formula = r"{} \tag*{{{}}}".format(formula, formula_number)
    return f"$${merge_formula}$$"

def fix_latex_syntax(text):
    """
    ä¿®å¤å¸¸è§çš„ LaTeX è¯­æ³•é”™è¯¯ï¼Œç‰¹åˆ«æ˜¯ VLM æ¨¡å‹ç”Ÿæˆçš„é”™è¯¯æ ¼å¼
    
    Args:
        text: åŒ…å« LaTeX å…¬å¼çš„æ–‡æœ¬
    
    Returns:
        ä¿®å¤åçš„æ–‡æœ¬
    """
    import re
    
    # ä¿®å¤ \inS, \inR, \inN ç­‰é”™è¯¯ï¼ˆåº”è¯¥æ˜¯ \in S, \in \mathbb{R}, \in \mathbb{N}ï¼‰
    # åŒ¹é…æ¨¡å¼ï¼š\in[A-Z]ï¼ˆå¦‚ \inS, \inR, \inNï¼‰
    def fix_in_symbol(match):
        full_match = match.group(0)
        letter = full_match[-1]  # è·å–æœ€åä¸€ä¸ªå­—æ¯
        
        # ç‰¹æ®Šå¤„ç†ï¼šR -> \mathbb{R}, N -> \mathbb{N}, Z -> \mathbb{Z}, Q -> \mathbb{Q}, C -> \mathbb{C}
        if letter in ['R', 'N', 'Z', 'Q', 'C']:
            return f"\\in \\mathbb{{{letter}}}"
        else:
            # å…¶ä»–æƒ…å†µï¼š\inS -> \in S
            return f"\\in {letter}"
    
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾å¹¶æ›¿æ¢
    # åŒ¹é… $...$ æˆ– $$...$$ ä¸­çš„å†…å®¹
    def fix_in_formula(match):
        formula_content = match.group(1)
        # ä¿®å¤ \in[A-Z] æ¨¡å¼
        formula_content = re.sub(r'\\in([A-Z])', fix_in_symbol, formula_content)
        return f"${formula_content}$"
    
    # ä¿®å¤è¡Œå†…å…¬å¼ $...$
    text = re.sub(r'\$([^$]+)\$', fix_in_formula, text)
    
    # ä¿®å¤å—çº§å…¬å¼ $$...$$
    def fix_in_display_formula(match):
        formula_content = match.group(1)
        # ä¿®å¤ \in[A-Z] æ¨¡å¼
        formula_content = re.sub(r'\\in([A-Z])', fix_in_symbol, formula_content)
        return f"$${formula_content}$$"
    
    text = re.sub(r'\$\$([^$]+)\$\$', fix_in_display_formula, text)
    
    return text

def format_chart2table_func(block):
    """å›¾è¡¨è½¬è¡¨æ ¼æ ¼å¼åŒ–"""
    lines_list = block.content.split("\n")
    header = lines_list[0].split("|")
    rows = [line.split("|") for line in lines_list[1:]]
    html = "<table border=1 style='margin: auto; width: max-content;'>\n"
    html += (
        "  <thead><tr>"
        + "".join(
            f"<th style='text-align: center;'>{cell.strip()}</th>" for cell in header
        )
        + "</tr></thead>\n"
    )
    html += "  <tbody>\n"
    for row in rows:
        html += (
            "    <tr>"
            + "".join(
                f"<td style='text-align: center;'>{cell.strip()}</td>" for cell in row
            )
            + "</tr>\n"
        )
    html += "  </tbody>\n"
    html += "</table>"
    return html

def build_handle_funcs_dict(
    *,
    text_func,
    image_func,
    chart_func,
    table_func,
    formula_func,
    seal_func,
):
    """æ„å»ºå¤„ç†å‡½æ•°å­—å…¸"""
    from functools import partial
    return {
        "paragraph_title": format_title_func,
        "abstract_title": format_title_func,
        "reference_title": format_title_func,
        "content_title": format_title_func,
        "doc_title": lambda block: f"# {block.content}".replace("-\n", "").replace("\n", " "),
        "table_title": text_func,
        "figure_title": text_func,
        "chart_title": text_func,
        "vision_footnote": lambda block: block.content.replace("\n\n", "\n").replace("\n", "\n\n"),
        "text": lambda block: block.content.replace("\n\n", "\n").replace("\n", "\n\n"),
        "ocr": lambda block: block.content.replace("\n\n", "\n").replace("\n", "\n\n"),
        "vertical_text": lambda block: block.content.replace("\n\n", "\n").replace("\n", "\n\n"),
        "reference_content": lambda block: block.content.replace("\n\n", "\n").replace("\n", "\n\n"),
        "abstract": partial(
            format_first_line_func,
            templates=["æ‘˜è¦", "abstract"],
            format_func=lambda l: f"## {l}\n",
            spliter=" ",
        ),
        "content": lambda block: block.content.replace("-\n", "  \n").replace("\n", "  \n"),
        "image": image_func,
        "chart": chart_func,
        "formula": formula_func,
        "display_formula": formula_func,
        "inline_formula": formula_func,
        "table": table_func,
        "reference": partial(
            format_first_line_func,
            templates=["å‚è€ƒæ–‡çŒ®", "references"],
            format_func=lambda l: f"## {l}",
            spliter="\n",
        ),
        "algorithm": lambda block: block.content.strip("\n"),
        "seal": seal_func,
        "number": format_text_plain_func,
        "footnote": format_text_plain_func,
        "header": format_text_plain_func,
        "header_image": image_func,
        "footer": format_text_plain_func,
        "footer_image": image_func,
        "aside_text": format_text_plain_func,
    }

def get_show_color(label: str, order_label=False):
    """è·å–æ˜¾ç¤ºé¢œè‰²"""
    if order_label:
        label_colors = {
            "doc_title": (255, 248, 220, 100),
            "doc_title_text": (255, 239, 213, 100),
            "paragraph_title": (102, 102, 255, 100),
            "sub_paragraph_title": (102, 178, 255, 100),
            "vision": (153, 255, 51, 100),
            "vision_title": (144, 238, 144, 100),
            "vision_footnote": (144, 238, 144, 100),
            "normal_text": (153, 0, 76, 100),
            "cross_layout": (53, 218, 207, 100),
            "cross_reference": (221, 160, 221, 100),
        }
    else:
        label_colors = {
            "paragraph_title": (102, 102, 255, 100),
            "doc_title": (255, 248, 220, 100),
            "table_title": (255, 255, 102, 100),
            "figure_title": (102, 178, 255, 100),
            "chart_title": (221, 160, 221, 100),
            "vision_footnote": (144, 238, 144, 100),
            "text": (153, 0, 76, 100),
            "vertical_text": (153, 0, 76, 100),
            "inline_formula": (153, 0, 76, 100),
            "formula": (0, 255, 0, 100),
            "display_formula": (0, 255, 0, 100),
            "abstract": (255, 239, 213, 100),
            "content": (40, 169, 92, 100),
            "seal": (158, 158, 158, 100),
            "table": (204, 204, 0, 100),
            "image": (153, 255, 51, 100),
            "figure": (153, 255, 51, 100),
            "chart": (216, 191, 216, 100),
            "reference": (229, 255, 204, 100),
            "reference_content": (229, 255, 204, 100),
            "algorithm": (255, 250, 240, 100),
        }
    default_color = (158, 158, 158, 100)
    return label_colors.get(label, default_color)

# å®Œæ•´çš„ç»“æœç±»å®ç°ï¼ˆå‚è€ƒ PaddleXï¼‰
class PaddleOCRVLBlock(object):
    """PaddleOCRVL Block Classï¼ˆå‚è€ƒ PaddleX å®ç°ï¼‰"""

    def __init__(self, label, bbox, content="", group_id=None) -> None:
        """
        Initialize a PaddleOCRVLBlock object.

        Args:
            label (str): Label assigned to the block.
            bbox (list): Bounding box coordinates of the block.
            content (str, optional): Content of the block. Defaults to an empty string.
            group_id: Group ID for the block.
        """
        self.label = label
        self.bbox = list(map(int, bbox))
        self.content = content
        self.image = None
        self.group_id = group_id

    def __str__(self) -> str:
        """
        Return a string representation of the block.
        """
        _str = f"\n\n#################\nlabel:\t{self.label}\nbbox:\t{self.bbox}\ncontent:\t{self.content}\n#################"
        return _str

    def __repr__(self) -> str:
        """
        Return a string representation of the block.
        """
        _str = f"\n\n#################\nlabel:\t{self.label}\nbbox:\t{self.bbox}\ncontent:\t{self.content}\n#################"
        return _str


class PaddleOCRVLResult(dict):
    """
    PaddleOCRVLResult class for holding and formatting OCR/VL parsing results.
    å‚è€ƒ PaddleX çš„å®Œæ•´å®ç°
    """

    def __init__(self, data) -> None:
        """
        Initializes a new instance of the class with the specified data.

        Args:
            data: The input data for the parsing result.
        """
        super().__init__(data)
        self._save_funcs = []
        markdown_ignore_labels = self.get("model_settings", {}).get(
            "markdown_ignore_labels", []
        )
        self.visualize_order_labels = [
            label
            for label in VISUALIZE_ORDE_LABELS
            if label not in markdown_ignore_labels
        ]

    def _get_input_fn(self):
        """è·å–è¾“å…¥æ–‡ä»¶å"""
        import time
        import random
        if self.get("input_path", None) is None:
            timestamp = int(time.time())
            random_number = random.randint(1000, 9999)
            fp = f"{timestamp}_{random_number}"
            return Path(fp).name
        fp = self["input_path"]
        return Path(fp).name

    def _to_img(self) -> dict:
        """
        Convert the parsing result to a dictionary of images.

        Returns:
            dict: Keys are names, values are numpy arrays (images).
        """
        res_img_dict = {}
        model_settings = self.get("model_settings", {})
        if model_settings.get("use_doc_preprocessor", False):
            doc_preprocessor_res = self.get("doc_preprocessor_res", {})
            if isinstance(doc_preprocessor_res, dict) and "img" in doc_preprocessor_res:
                for key, value in doc_preprocessor_res["img"].items():
                    res_img_dict[key] = value
        if model_settings.get("use_layout_detection", False):
            layout_det_res = self.get("layout_det_res")
            if layout_det_res and isinstance(layout_det_res, dict) and "img" in layout_det_res:
                res_img_dict["layout_det_res"] = layout_det_res["img"].get("res")

        # for layout ordering image
        doc_preprocessor_res = self.get("doc_preprocessor_res", {})
        output_img = doc_preprocessor_res.get("output_img")
        if output_img is not None:
            image = Image.fromarray(output_img[:, :, ::-1])
            draw = ImageDraw.Draw(image, "RGBA")
            font_size = int(0.018 * int(image.width)) + 2
            try:
                font = ImageFont.truetype("arial.ttf", font_size, encoding="utf-8")
            except:
                font = ImageFont.load_default()
            parsing_result = self.get("parsing_res_list", [])

            order_index = 0
            for block in parsing_result:
                bbox = block.bbox
                label = block.label
                fill_color = get_show_color(label, False)
                draw.rectangle(bbox, fill=fill_color)
                if label in self.visualize_order_labels:
                    text_position = (bbox[2] + 2, bbox[1] - font_size // 2)
                    if int(image.width) - bbox[2] < font_size:
                        text_position = (
                            int(bbox[2] - font_size * 1.1),
                            bbox[1] - font_size // 2,
                        )
                    draw.text(text_position, str(order_index + 1), font=font, fill="red")
                    order_index += 1

            res_img_dict["layout_order_res"] = image

        return res_img_dict

    def _to_json(self) -> dict:
        """
        Converts the object's data to a JSON dictionary.

        Returns:
            dict: A dictionary containing the object's data in JSON format.
        """
        import copy
        data = {}
        data["input_path"] = self.get("input_path")
        data["page_index"] = self.get("page_index")
        data["page_count"] = self.get("page_count")
        data["width"] = self.get("width")
        data["height"] = self.get("height")
        model_settings = self.get("model_settings", {})
        data["model_settings"] = model_settings
        
        if model_settings.get("format_block_content", False):
            doc_preprocessor_res = self.get("doc_preprocessor_res", {})
            output_img = doc_preprocessor_res.get("output_img")
            original_image_width = output_img.shape[1] if output_img is not None else 500
            format_text_func = lambda block: format_centered_by_html(
                format_text_plain_func(block)
            )
            format_image_func = lambda block: format_centered_by_html(
                format_image_scaled_by_html_func(
                    block,
                    original_image_width=original_image_width,
                )
            )

            if model_settings.get("use_chart_recognition", False):
                format_chart_func = format_chart2table_func
            else:
                format_chart_func = format_image_func

            format_seal_func = format_image_func
            format_table_func = lambda block: "\n" + format_table_center_func(block)
            format_formula_func = lambda block: block.content

            handle_funcs_dict = build_handle_funcs_dict(
                text_func=format_text_func,
                image_func=format_image_func,
                chart_func=format_chart_func,
                table_func=format_table_func,
                formula_func=format_formula_func,
                seal_func=format_seal_func,
            )

        parsing_res_list = self.get("parsing_res_list", [])
        parsing_res_list_json = []
        order_index = 1
        for idx, parsing_res in enumerate(parsing_res_list):
            label = parsing_res.label
            if label in self.visualize_order_labels:
                order = order_index
                order_index += 1
            else:
                order = None
            res_dict = {
                "block_label": parsing_res.label,
                "block_content": parsing_res.content,
                "block_bbox": parsing_res.bbox,
                "block_id": idx,
                "block_order": order,
                "group_id": (
                    parsing_res.group_id if parsing_res.group_id is not None else idx
                ),
            }
            if model_settings.get("format_block_content", False):
                if handle_funcs_dict.get(parsing_res.label):
                    res_dict["block_content"] = handle_funcs_dict[parsing_res.label](
                        parsing_res
                    )
                else:
                    res_dict["block_content"] = parsing_res.content

            parsing_res_list_json.append(res_dict)
        data["parsing_res_list"] = parsing_res_list_json
        
        if model_settings.get("use_doc_preprocessor", False):
            doc_preprocessor_res = self.get("doc_preprocessor_res", {})
            if isinstance(doc_preprocessor_res, dict) and "json" in doc_preprocessor_res:
                data["doc_preprocessor_res"] = doc_preprocessor_res["json"].get("res")
        if model_settings.get("use_layout_detection", False):
            layout_det_res = self.get("layout_det_res")
            if layout_det_res and isinstance(layout_det_res, dict) and "json" in layout_det_res:
                data["layout_det_res"] = layout_det_res["json"].get("res")
        
        return {"res": data}

    def _to_markdown(self, pretty=True, show_formula_number=False) -> dict:
        """
        Save the parsing result to a Markdown file.

        Args:
            pretty (Optional[bool]): whether to pretty markdown by HTML, default by True.
            show_formula_number (bool): whether to show formula numbers.

        Returns:
            dict: Markdown information with text and images.
        """
        doc_preprocessor_res = self.get("doc_preprocessor_res", {})
        output_img = doc_preprocessor_res.get("output_img")
        original_image_width = output_img.shape[1] if output_img is not None else 500

        if pretty:
            format_text_func = lambda block: format_centered_by_html(
                format_text_plain_func(block)
            )
            format_image_func = lambda block: format_centered_by_html(
                format_image_scaled_by_html_func(
                    block,
                    original_image_width=original_image_width,
                )
            )
        else:
            format_text_func = lambda block: block.content
            format_image_func = format_image_plain_func

        model_settings = self.get("model_settings", {})
        format_chart_func = (
            format_chart2table_func
            if model_settings.get("use_chart_recognition", False)
            else format_image_func
        )

        if pretty:
            format_table_func = lambda block: "\n" + format_table_center_func(block)
        else:
            format_table_func = lambda block: simplify_table_func("\n" + block.content)

        format_formula_func = lambda block: block.content
        format_seal_func = format_image_func

        handle_funcs_dict = build_handle_funcs_dict(
            text_func=format_text_func,
            image_func=format_image_func,
            chart_func=format_chart_func,
            table_func=format_table_func,
            formula_func=format_formula_func,
            seal_func=format_seal_func,
        )
        for label in model_settings.get("markdown_ignore_labels", []):
            handle_funcs_dict.pop(label, None)

        markdown_content = ""
        markdown_info = {}
        markdown_info["markdown_images"] = {}
        parsing_res_list = self.get("parsing_res_list", [])
        for idx, block in enumerate(parsing_res_list):
            label = block.label
            if block.image is not None:
                markdown_info["markdown_images"][block.image["path"]] = block.image[
                    "img"
                ]
            handle_func = handle_funcs_dict.get(label, None)
            if (
                show_formula_number
                and (label == "display_formula" or label == "formula")
                and idx != len(parsing_res_list) - 1
            ):
                next_block = parsing_res_list[idx + 1]
                next_block_label = next_block.label
                if next_block_label == "formula_number":
                    block.content = merge_formula_and_number(
                        block.content, next_block.content
                    )
            if handle_func:
                markdown_content += (
                    "\n\n" + handle_func(block)
                    if markdown_content
                    else handle_func(block)
                )

        markdown_info["page_index"] = self.get("page_index")
        markdown_info["input_path"] = self.get("input_path")
        markdown_info["markdown_texts"] = markdown_content
        for img in self.get("imgs_in_doc", []):
            markdown_info["markdown_images"][img["path"]] = img["img"]

        return markdown_info

    @property
    def json(self) -> dict:
        """Property to get the JSON representation of the result."""
        return self._to_json()

    @property
    def img(self) -> dict:
        """Property to get the image representation of the result."""
        return self._to_img()

    @property
    def markdown(self) -> dict:
        """Property to get the markdown representation of the result."""
        return self._to_markdown()

    def save_to_json(self, save_path, indent=4, ensure_ascii=False):
        """Save the JSON representation of the object to a file."""
        import json
        save_path = Path(save_path)
        save_path.mkdir(parents=True, exist_ok=True)
        fn = self._get_input_fn()
        json_path = save_path / f"{Path(fn).stem}_res.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(self._to_json(), f, indent=indent, ensure_ascii=ensure_ascii)
        print(f"JSON saved to: {json_path}")

    def save_to_img(self, save_path, *args, **kwargs):
        """
        Save the image representation of the result to files.
        
        Args:
            save_path: The path to save the image(s). If the save path does not end with .jpg or .png, 
                      it appends the input path's stem and suffix to the save path.
            *args: Additional positional arguments that will be passed to the image writer.
            **kwargs: Additional keyword arguments that will be passed to the image writer.
        """
        import mimetypes
        
        def _is_image_file(file_path):
            mime_type, _ = mimetypes.guess_type(str(file_path))
            return mime_type is not None and mime_type.startswith("image/")
        
        img_dict = self._to_img()
        if not _is_image_file(save_path):
            fn = Path(self._get_input_fn())
            suffix = fn.suffix if _is_image_file(fn) else ".png"
            stem = fn.stem
            base_save_path = Path(save_path)
            base_save_path.mkdir(parents=True, exist_ok=True)
            for key in img_dict:
                if img_dict[key] is not None:
                    img_path = base_save_path / f"{stem}_{key}{suffix}"
                    self._save_image(img_path.as_posix(), img_dict[key], *args, **kwargs)
        else:
            if len(img_dict) > 1:
                import logging
                logging.warning(
                    f"The result has multiple img files need to be saved. But the `save_path` has been specified as `{save_path}`!"
                )
            # ä¿å­˜ç¬¬ä¸€ä¸ªé None çš„å›¾ç‰‡
            for key, img in img_dict.items():
                if img is not None:
                    self._save_image(save_path, img, *args, **kwargs)
                    break

    def save_to_markdown(self, save_path, pretty=True, show_formula_number=False, *args, **kwargs):
        """
        Save the markdown representation of the result to a file.
        
        Args:
            save_path: ä¿å­˜è·¯å¾„ï¼ˆç›®å½•æˆ–æ–‡ä»¶è·¯å¾„ï¼‰
            pretty: æ˜¯å¦ä½¿ç”¨ HTML ç¾åŒ– markdown
            show_formula_number: æ˜¯å¦æ˜¾ç¤ºå…¬å¼ç¼–å·
            *args: Additional positional arguments for saving.
            **kwargs: Additional keyword arguments for saving.
        """
        def _is_markdown_file(file_path) -> bool:
            """Check if a file is a markdown file based on its extension or MIME type."""
            markdown_extensions = {".md", ".markdown", ".mdown", ".mkd"}
            _, ext = os.path.splitext(str(file_path))
            if ext.lower() in markdown_extensions:
                return True
            import mimetypes
            mime_type, _ = mimetypes.guess_type(str(file_path))
            return mime_type == "text/markdown"
        
        import os
        import mimetypes
        
        if not _is_markdown_file(save_path):
            fn = Path(self._get_input_fn())
            suffix = fn.suffix if _is_markdown_file(fn) else ".md"
            stem = fn.stem
            base_save_path = Path(save_path)
            save_path = base_save_path / f"{stem}{suffix}"
            self.save_path = save_path
        else:
            self.save_path = save_path
        
        self._save_data(
            self._save_markdown_text,
            self._save_image,
            self.save_path,
            self._to_markdown(pretty=pretty, show_formula_number=show_formula_number),
            *args,
            **kwargs,
        )
    
    def _save_data(
        self,
        save_mkd_func,
        save_img_func,
        save_path,
        data,
        *args,
        **kwargs,
    ):
        """Internal method to save markdown and image data.
        
        Args:
            save_mkd_func: Function to save markdown text.
            save_img_func: Function to save image data.
            save_path: The base path where the data will be saved.
            data: The markdown data to save.
            *args: Additional positional arguments for saving.
            **kwargs: Additional keyword arguments for saving.
        """
        MARKDOWN_SAVE_KEYS = ["markdown_texts"]
        save_path = Path(save_path)
        if data is None:
            return
        for key, value in data.items():
            if key in MARKDOWN_SAVE_KEYS:
                save_mkd_func(save_path.as_posix(), value, *args, **kwargs)
            if isinstance(value, dict):
                base_save_path = save_path.parent
                for img_path, img_data in value.items():
                    save_img_func(
                        (base_save_path / img_path).as_posix(),
                        img_data,
                        *args,
                        **kwargs,
                    )
    
    def _save_markdown_text(self, out_path, text, *args, **kwargs):
        """Save markdown text to file."""
        Path(out_path).parent.mkdir(parents=True, exist_ok=True)
        with open(out_path, 'w', encoding='utf-8') as f:
            f.write(text)
    
    def _save_image(self, out_path, img_data, *args, **kwargs):
        """Save image data to file."""
        Path(out_path).parent.mkdir(parents=True, exist_ok=True)
        if isinstance(img_data, Image.Image):
            img_data.save(out_path)
        elif isinstance(img_data, np.ndarray):
            Image.fromarray(img_data).save(out_path)
        else:
            # å¦‚æœ img_data æ˜¯å…¶ä»–ç±»å‹ï¼Œå°è¯•è½¬æ¢
            try:
                if hasattr(img_data, 'save'):
                    img_data.save(out_path)
                else:
                    print(f"Warning: Cannot save image of type {type(img_data)}")
            except Exception as e:
                print(f"Warning: Failed to save image {out_path}: {e}")

    def print(self):
        """Print the result."""
        print(f"Input: {self.get('input_path')}")
        print(f"Page: {self.get('page_index')}/{self.get('page_count')}")
        print(f"Size: {self.get('width')}x{self.get('height')}")
        parsing_res_list = self.get("parsing_res_list", [])
        print(f"Blocks: {len(parsing_res_list)}")
        for i, block in enumerate(parsing_res_list):
            print(f"\nBlock {i+1}:")
            print(f"  Label: {block.label}")
            print(f"  BBox: {block.bbox}")
            content_preview = block.content[:100] + "..." if len(block.content) > 100 else block.content
            print(f"  Content: {content_preview}")


class PaddleOCRVL:
    """
    OpenVINO ç‰ˆæœ¬çš„ PaddleOCR-VL Pipeline
    ä½¿ç”¨ OpenVINO è¿›è¡Œå¸ƒå±€æ£€æµ‹å’Œ VLM æ¨ç†
    """
    
    # ModelScope æ¨¡å‹ ID
    LAYOUT_MODEL_ID = "zhaohb/PP-DocLayoutV2-ov"
    VLM_MODEL_ID = "zhaohb/PaddleOCR-Vl-OV"
    
    def __init__(
        self,
        layout_model_path: Optional[str] = None,
        vlm_model_path: Optional[str] = None,
        vlm_device: str = "CPU",
        layout_device: str = "NPU",
        use_layout_detection: bool = True,
        use_chart_recognition: bool = True,
        merge_layout_blocks: bool = True,
        markdown_ignore_labels: Optional[List[str]] = None,
        cache_dir: Optional[str] = None,
        layout_precision: str = "fp16",
        llm_int4_compress: bool = False,
        vision_int8_quant: bool = True,
        llm_int8_compress: bool = True,
        llm_int8_quant: bool = True,
    ):
        """
        åˆå§‹åŒ– PaddleOCR-VL Pipeline
        
        Args:
            layout_model_path: å¸ƒå±€æ£€æµ‹æ¨¡å‹è·¯å¾„ï¼ˆOpenVINO IR .xml æ–‡ä»¶ï¼‰ï¼Œå¦‚æœä¸º None åˆ™è‡ªåŠ¨ä¸‹è½½
            vlm_model_path: VLM æ¨¡å‹è·¯å¾„ï¼ˆåŒ…å« vision.xml, vision_mlp.xml, llm_stateful.xml ç­‰çš„ç›®å½•ï¼‰ï¼Œå¦‚æœä¸º None åˆ™è‡ªåŠ¨ä¸‹è½½
            vlm_device: VLM æ¨¡å‹æ¨ç†è®¾å¤‡ ("CPU", "GPU", "AUTO")
            layout_device: å¸ƒå±€æ£€æµ‹æ¨¡å‹ï¼ˆPP-DocLayoutV2ï¼‰æ¨ç†è®¾å¤‡ï¼Œé»˜è®¤ "NPU" ("CPU", "GPU", "NPU", "AUTO")
            use_layout_detection: æ˜¯å¦ä½¿ç”¨å¸ƒå±€æ£€æµ‹
            use_chart_recognition: æ˜¯å¦ä½¿ç”¨å›¾è¡¨è¯†åˆ«
            merge_layout_blocks: æ˜¯å¦åˆå¹¶å¸ƒå±€å—
            markdown_ignore_labels: Markdown è¾“å‡ºä¸­å¿½ç•¥çš„æ ‡ç­¾åˆ—è¡¨
            cache_dir: ModelScope æ¨¡å‹ç¼“å­˜ç›®å½•ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨é»˜è®¤ç¼“å­˜ç›®å½•
            layout_precision: å¸ƒå±€æ£€æµ‹æ¨¡å‹ç²¾åº¦é€‰æ‹©ï¼Œé€‰é¡¹: "fp16", "fp32", "combined_fp16", "combined_fp32"
                - "fp16": FP16 ç²¾åº¦æ¨¡å‹ï¼ˆæ›´å¿«ï¼Œå†…å­˜å ç”¨æ›´ä½ï¼‰
                - "fp32": FP32 ç²¾åº¦æ¨¡å‹ï¼ˆæ›´å‡†ç¡®ï¼Œé»˜è®¤ï¼‰
                - "combined_fp16": FP16 åˆå¹¶æ¨¡å‹ï¼ˆåˆå¹¶äº† batch size å’Œ boxes èŠ‚ç‚¹ï¼‰
                - "combined_fp32": FP32 åˆå¹¶æ¨¡å‹ï¼ˆåˆå¹¶äº† batch size å’Œ boxes èŠ‚ç‚¹ï¼‰
                æ³¨æ„ï¼šå¦‚æœæŒ‡å®šäº† layout_model_path ä¸ºå…·ä½“çš„ .xml æ–‡ä»¶è·¯å¾„ï¼Œæ­¤å‚æ•°å°†è¢«å¿½ç•¥
        """
        self.vlm_device = vlm_device
        self.layout_device = layout_device
        self.use_layout_detection = use_layout_detection
        self.use_chart_recognition = use_chart_recognition
        self.merge_layout_blocks = merge_layout_blocks
        self.markdown_ignore_labels = markdown_ignore_labels or [
            "number", "footnote", "header", "header_image",
            "footer", "footer_image", "aside_text"
        ]
        self.cache_dir = cache_dir
        self.layout_precision = layout_precision
        
        # éªŒè¯ precision å‚æ•°
        valid_precisions = ["fp16", "fp32", "combined_fp16", "combined_fp32"]
        if layout_precision not in valid_precisions:
            raise ValueError(
                f"Unsupported layout_precision: {layout_precision}. "
                f"Supported options: {valid_precisions}"
            )
        
        # è‡ªåŠ¨ä¸‹è½½æˆ–éªŒè¯æ¨¡å‹è·¯å¾„
        if layout_model_path is None:
            if not MODELSCOPE_AVAILABLE:
                raise ImportError("modelscope is required for auto-download. Install with: pip install modelscope")
            print(f"ğŸ“¥ è‡ªåŠ¨ä¸‹è½½å¸ƒå±€æ£€æµ‹æ¨¡å‹: {self.LAYOUT_MODEL_ID} (precision: {layout_precision})")
            layout_model_path = self._download_layout_model()
        else:
            layout_model_path = self._ensure_layout_model(layout_model_path)
        
        if vlm_model_path is None:
            if not MODELSCOPE_AVAILABLE:
                raise ImportError("modelscope is required for auto-download. Install with: pip install modelscope")
            print(f"ğŸ“¥ è‡ªåŠ¨ä¸‹è½½ VLM æ¨¡å‹: {self.VLM_MODEL_ID}")
            vlm_model_path = self._download_vlm_model()
        else:
            vlm_model_path = self._ensure_vlm_model(vlm_model_path)
        
        self.layout_model_path = layout_model_path
        self.vlm_model_path = vlm_model_path
        
        # åˆå§‹åŒ– OpenVINO Core
        self.core = ov.Core()
        
        # åŠ è½½å¸ƒå±€æ£€æµ‹æ¨¡å‹
        if self.use_layout_detection:
            self._load_layout_model()
        
        # åŠ è½½ VLM æ¨¡å‹
        self._load_vlm_model(llm_int4_compress=llm_int4_compress, vision_int8_quant=vision_int8_quant, llm_int8_compress=llm_int8_compress, llm_int8_quant=llm_int8_quant)
        
        # ä¸éœ€è¦å•ç‹¬åˆå§‹åŒ–å›¾åƒå¤„ç†å™¨ï¼ŒVLM æ¨¡å‹å†…éƒ¨ä¼šå¤„ç†
    
    def _download_layout_model(self) -> str:
        """ä¸‹è½½å¸ƒå±€æ£€æµ‹æ¨¡å‹"""
        if not MODELSCOPE_AVAILABLE:
            raise ImportError("modelscope is required for auto-download. Install with: pip install modelscope")
        
        print(f"æ­£åœ¨ä» ModelScope ä¸‹è½½å¸ƒå±€æ£€æµ‹æ¨¡å‹: {self.LAYOUT_MODEL_ID}")
        model_dir = snapshot_download(self.LAYOUT_MODEL_ID, cache_dir=self.cache_dir)
        model_dir = Path(model_dir)
        xml_files: List[Path] = []
        
        # æ ¹æ® precision é€‰æ‹©å¯¹åº”çš„æ¨¡å‹æ–‡ä»¶
        precision_map = {
            "fp16": "pp_doclayoutv2_f16.xml",
            "fp32": "pp_doclayoutv2_f32.xml",
            "combined_fp16": "pp_doclayoutv2_f16_combined.xml",
            "combined_fp32": "pp_doclayoutv2_f32_combined.xml",
        }
        
        model_filename = precision_map.get(self.layout_precision)
        model_path = model_dir / model_filename if model_filename else None
        
        # å¦‚æœæŒ‡å®šçš„ç²¾åº¦æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•æŸ¥æ‰¾å…¶ä»–å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶
        if model_path is None or not model_path.exists():
            print(f"âš ï¸  æŒ‡å®šçš„ç²¾åº¦æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_filename if model_filename else 'N/A'}")
            # æŸ¥æ‰¾æ‰€æœ‰ .xml æ–‡ä»¶
            xml_files = list(model_dir.glob("*.xml"))
            if not xml_files:
                raise FileNotFoundError(
                    f"åœ¨ä¸‹è½½çš„æ¨¡å‹ç›®å½•ä¸­æœªæ‰¾åˆ° .xml æ–‡ä»¶: {model_dir}\n"
                    f"layout_precision={self.layout_precision}"
                )

            # ä¼˜å…ˆé€‰æ‹©åˆå¹¶ç‰ˆæœ¬ï¼ˆcombined_*ï¼‰
            combined_files = [f for f in xml_files if "combined" in f.name]
            if combined_files:
                model_path = combined_files[0]
                print(f"âš ï¸  ä½¿ç”¨æ‰¾åˆ°çš„åˆå¹¶æ¨¡å‹: {model_path.name}")
            else:
                # å¦åˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„æ–‡ä»¶
                model_path = xml_files[0]
                print(f"âš ï¸  ä½¿ç”¨æ‰¾åˆ°çš„æ¨¡å‹: {model_path.name}")
        else:
            print(f"âœ… ä½¿ç”¨æŒ‡å®šçš„ç²¾åº¦æ¨¡å‹: {model_filename}")
        
        # æ£€æŸ¥å¯¹åº”çš„ .bin æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        bin_path = model_path.with_suffix(".bin")
        if not bin_path.exists():
            raise FileNotFoundError(f"å¯¹åº”çš„ .bin æ–‡ä»¶ä¸å­˜åœ¨: {bin_path}")
        
        print(f"âœ… å¸ƒå±€æ£€æµ‹æ¨¡å‹å·²ä¸‹è½½åˆ°: {model_path}")
        return str(model_path)
    
    def _download_vlm_model(self) -> str:
        """ä¸‹è½½ VLM æ¨¡å‹"""
        if not MODELSCOPE_AVAILABLE:
            raise ImportError("modelscope is required for auto-download. Install with: pip install modelscope")
        
        print(f"æ­£åœ¨ä» ModelScope ä¸‹è½½ VLM æ¨¡å‹: {self.VLM_MODEL_ID}")
        model_dir = snapshot_download(self.VLM_MODEL_ID, cache_dir=self.cache_dir)
        
        # éªŒè¯å¿…è¦çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        required_files = ["vision.xml", "llm_stateful.xml", "llm_embd.xml"]
        model_path = Path(model_dir)
        missing_files = []
        for file_name in required_files:
            if not (model_path / file_name).exists():
                missing_files.append(file_name)
        
        if missing_files:
            raise FileNotFoundError(
                f"åœ¨ä¸‹è½½çš„æ¨¡å‹ç›®å½•ä¸­ç¼ºå°‘å¿…è¦çš„æ–‡ä»¶: {missing_files}\n"
                f"æ¨¡å‹ç›®å½•: {model_dir}"
            )
        
        print(f"âœ… VLM æ¨¡å‹å·²ä¸‹è½½åˆ°: {model_dir}")
        return str(model_dir)
    
    def _ensure_layout_model(self, model_path: str) -> str:
        """ç¡®ä¿å¸ƒå±€æ£€æµ‹æ¨¡å‹å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä¸‹è½½"""
        model_path_obj = Path(model_path)
        
        # å¦‚æœæ˜¯ç›®å½•ï¼Œæ ¹æ® precision æŸ¥æ‰¾å¯¹åº”çš„ .xml æ–‡ä»¶
        if model_path_obj.is_dir():
            # æ ¹æ® precision ä¼˜å…ˆçº§æœç´¢
            precision_map = {
                "fp16": ["pp_doclayoutv2_f16.xml", "*.xml"],
                "fp32": ["pp_doclayoutv2_f32.xml", "*.xml"],
                "combined_fp16": ["pp_doclayoutv2_f16_combined.xml", "pp_doclayoutv2_f16.xml", "*.xml"],
                "combined_fp32": ["pp_doclayoutv2_f32_combined.xml", "pp_doclayoutv2_f32.xml", "*.xml"],
            }
            
            search_patterns = precision_map.get(self.layout_precision, ["*.xml"])
            xml_file = None
            
            for pattern in search_patterns:
                if pattern == "*.xml":
                    xml_files = list(model_path_obj.glob(pattern))
                    if xml_files:
                        xml_file = xml_files[0]
                    break
                else:
                    candidate = model_path_obj / pattern
                    if candidate.exists():
                        xml_file = candidate
                        break
            
            if xml_file is None:
                print(f"âš ï¸  åœ¨æŒ‡å®šç›®å½•ä¸­æœªæ‰¾åˆ°åŒ¹é…çš„ .xml æ–‡ä»¶ï¼Œå°è¯•è‡ªåŠ¨ä¸‹è½½: {model_path}")
                return self._download_layout_model()
            
            # æ£€æŸ¥å¯¹åº”çš„ .bin æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            bin_path = xml_file.with_suffix(".bin")
            if not bin_path.exists():
                print(f"âš ï¸  å¯¹åº”çš„ .bin æ–‡ä»¶ä¸å­˜åœ¨: {bin_path}ï¼Œå°è¯•è‡ªåŠ¨ä¸‹è½½")
                return self._download_layout_model()
            
            return str(xml_file)
        
        # å¦‚æœæ˜¯æ–‡ä»¶è·¯å¾„ï¼Œæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not model_path_obj.exists():
            print(f"âš ï¸  æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•è‡ªåŠ¨ä¸‹è½½: {model_path}")
            return self._download_layout_model()
        
        # å¦‚æœæŒ‡å®šäº†å…·ä½“çš„ .xml æ–‡ä»¶è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨ï¼ˆå¿½ç•¥ precision å‚æ•°ï¼‰
        if model_path_obj.suffix.lower() == ".xml":
            bin_path = model_path_obj.with_suffix(".bin")
            if not bin_path.exists():
                print(f"âš ï¸  å¯¹åº”çš„ .bin æ–‡ä»¶ä¸å­˜åœ¨: {bin_path}ï¼Œå°è¯•è‡ªåŠ¨ä¸‹è½½")
                return self._download_layout_model()
            return model_path
        
        return model_path
    
    def _ensure_vlm_model(self, model_path: str) -> str:
        """ç¡®ä¿ VLM æ¨¡å‹å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä¸‹è½½"""
        model_path_obj = Path(model_path)
        
        if not model_path_obj.exists():
            print(f"âš ï¸  æ¨¡å‹ç›®å½•ä¸å­˜åœ¨ï¼Œå°è¯•è‡ªåŠ¨ä¸‹è½½: {model_path}")
            return self._download_vlm_model()
        
        # éªŒè¯å¿…è¦çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        required_files = ["vision.xml", "llm_stateful.xml", "llm_embd.xml"]
        missing_files = []
        for file_name in required_files:
            if not (model_path_obj / file_name).exists():
                missing_files.append(file_name)
        
        if missing_files:
            print(f"âš ï¸  æ¨¡å‹ç›®å½•ä¸­ç¼ºå°‘å¿…è¦çš„æ–‡ä»¶ {missing_files}ï¼Œå°è¯•è‡ªåŠ¨ä¸‹è½½")
            return self._download_vlm_model()
        
        return model_path
    
    def _load_layout_model(self):
        """åŠ è½½å¸ƒå±€æ£€æµ‹æ¨¡å‹"""
        model = self.core.read_model(self.layout_model_path)
        
        # æ·»åŠ é¢„å¤„ç†
        prep = ov.preprocess.PrePostProcessor(model)
        prep.input("image").tensor().set_layout(ov.Layout("NCHW"))
        prep.input("image").preprocess().scale([255, 255, 255])
        model = prep.build()
        
        # ç¼–è¯‘æ¨¡å‹ï¼ˆä½¿ç”¨ layout_deviceï¼‰
        self.layout_compiled_model = self.core.compile_model(model, self.layout_device)
        self.layout_request = self.layout_compiled_model.create_infer_request()
    
    def _load_vlm_model(self, llm_int4_compress=False, vision_int8_quant=True, llm_int8_compress=True, llm_int8_quant=True):
        """åŠ è½½ VLM æ¨¡å‹"""
        self.vlm_model = OVPaddleOCRVLForCausalLM(
            core=self.core,
            ov_model_path=self.vlm_model_path,
            device=self.vlm_device,
            llm_int4_compress=llm_int4_compress, 
            vision_int8_quant=vision_int8_quant, 
            llm_int8_compress=llm_int8_compress, 
            llm_int8_quant=llm_int8_quant, 
        )
    
    def predict(
        self,
        input: Union[str, List[str], np.ndarray, List[np.ndarray]],
        use_layout_detection: Optional[bool] = None,
        layout_threshold: Optional[Union[float, dict]] = None,
        layout_nms: Optional[bool] = None,
        layout_unclip_ratio: Optional[Union[float, tuple]] = None,
        layout_merge_bboxes_mode: Optional[str] = None,
        max_new_tokens: Optional[int] = None,
        prompt_label: str = "ocr",
        **kwargs,
    ):
        """
        é¢„æµ‹æ–‡æ¡£è§£æç»“æœ
        
        Args:
            input: è¾“å…¥å›¾åƒè·¯å¾„ã€å›¾åƒè·¯å¾„åˆ—è¡¨ã€numpy æ•°ç»„æˆ– numpy æ•°ç»„åˆ—è¡¨
            use_layout_detection: æ˜¯å¦ä½¿ç”¨å¸ƒå±€æ£€æµ‹ï¼ˆè¦†ç›–åˆå§‹åŒ–è®¾ç½®ï¼‰
            layout_threshold: å¸ƒå±€æ£€æµ‹é˜ˆå€¼
            layout_nms: æ˜¯å¦ä½¿ç”¨ NMS
            layout_unclip_ratio: åæ ‡æ‰©å±•æ¯”ä¾‹
            layout_merge_bboxes_mode: å¸ƒå±€æ¡†åˆå¹¶æ¨¡å¼
            max_new_tokens: æœ€å¤§ç”Ÿæˆ token æ•°
            **kwargs: å…¶ä»–å‚æ•°
        
        Yields:
            PaddleOCRVLResult: è§£æç»“æœå¯¹è±¡
        """
        # ç¡®å®šæ˜¯å¦ä½¿ç”¨å¸ƒå±€æ£€æµ‹
        if use_layout_detection is None:
            use_layout_detection = self.use_layout_detection
        
        # å¤„ç†è¾“å…¥
        if isinstance(input, str):
            inputs = [input]
        elif isinstance(input, np.ndarray):
            inputs = [input]
        elif isinstance(input, list):
            inputs = input
        else:
            raise ValueError(f"Unsupported input type: {type(input)}")
        
        # å¤„ç†æ¯ä¸ªè¾“å…¥
        for idx, inp in enumerate(inputs):
            # è¯»å–å›¾åƒ
            if isinstance(inp, str):
                image = cv2.imread(inp)
                input_path = inp
            elif isinstance(inp, np.ndarray):
                image = inp
                input_path = None
            else:
                raise ValueError(f"Unsupported input item type: {type(inp)}")
            
            if image is None:
                raise ValueError(f"Failed to load image: {inp}")
            
            # æ‰§è¡Œ CV å¤„ç†ï¼ˆå¸ƒå±€æ£€æµ‹ï¼‰
            results_cv = self._process_cv(
                image,
                input_path,
                use_layout_detection=use_layout_detection,
                layout_threshold=layout_threshold,
                layout_nms=layout_nms,
                layout_unclip_ratio=layout_unclip_ratio,
                layout_merge_bboxes_mode=layout_merge_bboxes_mode,
                prompt_label=prompt_label,
            )
            
            # æ‰§è¡Œ VLM å¤„ç†ï¼ˆå¸ƒå±€è§£æï¼‰
            result = self._process_vlm(
                results_cv,
                max_new_tokens=max_new_tokens,
            )
            
            yield result
    
    def _process_cv(
        self,
        image: np.ndarray,
        input_path: Optional[str],
        page_index: Optional[int] = None,
        use_layout_detection: bool = True,
        layout_threshold: Optional[Union[float, dict]] = None,
        layout_nms: Optional[bool] = None,
        layout_unclip_ratio: Optional[Union[float, tuple]] = None,
        layout_merge_bboxes_mode: Optional[str] = None,
        prompt_label: str = "ocr",
    ):
        """
        å¤„ç†è®¡ç®—æœºè§†è§‰éƒ¨åˆ†ï¼ˆå¸ƒå±€æ£€æµ‹ï¼‰
        å‚è€ƒ PaddleX çš„å®ç°ï¼Œç¡®ä¿åŠŸèƒ½ä¸€è‡´
        
        Args:
            image: è¾“å…¥å›¾åƒï¼ˆBGR æ ¼å¼ï¼‰
            input_path: è¾“å…¥è·¯å¾„
            page_index: é¡µé¢ç´¢å¼•
            use_layout_detection: æ˜¯å¦ä½¿ç”¨å¸ƒå±€æ£€æµ‹
            layout_threshold: å¸ƒå±€æ£€æµ‹é˜ˆå€¼
            layout_nms: æ˜¯å¦ä½¿ç”¨ NMS
            layout_unclip_ratio: åæ ‡æ‰©å±•æ¯”ä¾‹
            layout_merge_bboxes_mode: å¸ƒå±€æ¡†åˆå¹¶æ¨¡å¼
            prompt_label: ä¸ä½¿ç”¨å¸ƒå±€æ£€æµ‹æ—¶çš„é»˜è®¤æ ‡ç­¾ï¼ˆé»˜è®¤ "ocr"ï¼‰
        
        Returns:
            dict: åŒ…å«å¸ƒå±€æ£€æµ‹ç»“æœçš„å­—å…¸ï¼Œæ ¼å¼ä¸ PaddleX ä¸€è‡´
        """
        # æ–‡æ¡£é¢„å¤„ç†ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œç›´æ¥ä½¿ç”¨åŸå›¾ï¼‰
        # å¦‚æœåç»­éœ€è¦æ–‡æ¡£é¢„å¤„ç†ï¼ˆå¦‚æ–¹å‘æ ¡æ­£ã€å»å¼¯æ›²ç­‰ï¼‰ï¼Œå¯ä»¥åœ¨è¿™é‡Œæ·»åŠ 
        doc_preprocessor_image = image.copy()
        doc_preprocessor_res = {"output_img": doc_preprocessor_image}
        
        # å¸ƒå±€æ£€æµ‹
        if use_layout_detection and self.use_layout_detection:
            # æ‰§è¡Œå¸ƒå±€æ£€æµ‹
            layout_det_res = self._layout_detection(
                doc_preprocessor_image,
                threshold=layout_threshold or 0.5,
                layout_nms=layout_nms if layout_nms is not None else True,
                layout_unclip_ratio=layout_unclip_ratio or [1.0, 1.0],
                layout_merge_bboxes_mode=layout_merge_bboxes_mode,
            )
            
            # è¿‡æ»¤é‡å æ¡†
            layout_det_res = self._filter_overlap_boxes(layout_det_res)
            
            # æå–æ–‡æ¡£ä¸­çš„å›¾åƒï¼ˆå‚è€ƒ PaddleX çš„ gather_imgsï¼‰
            imgs_in_doc = gather_imgs(doc_preprocessor_image, layout_det_res["boxes"])
            
            # è®¾ç½® input_path å’Œ page_index
            layout_det_res["input_path"] = input_path
            layout_det_res["page_index"] = page_index
        else:
            # å¦‚æœä¸ä½¿ç”¨å¸ƒå±€æ£€æµ‹ï¼Œåˆ›å»ºå…¨å›¾æ¡†ï¼ˆå‚è€ƒ PaddleX çš„å®ç°ï¼‰
            h, w = doc_preprocessor_image.shape[:2]
            layout_det_res = {
                "input_path": input_path,
                "page_index": page_index,
                "boxes": [
                    {
                        "cls_id": 0,
                        "label": prompt_label.lower(),
                        "score": 1.0,
                        "coordinate": [0, 0, w, h],
                    }
                ],
            }
            # ä¸ä½¿ç”¨å¸ƒå±€æ£€æµ‹æ—¶ï¼Œä¸æå–å›¾åƒ
            imgs_in_doc = []
        
        # åˆ›å»º LayoutDetectionResult å¯¹è±¡å¹¶è·å– json å’Œ img
        import os
        layout_det_result_obj = LayoutDetectionResult(
            input_path=os.path.abspath(input_path) if input_path else None,
            boxes=layout_det_res["boxes"],
            page_index=page_index,
            input_img=doc_preprocessor_image
        )
        
        # NOTE: PaddleX ä¸ä¼šåœ¨è¿™é‡Œå¼ºåˆ¶è½ç›˜ä¿å­˜å¯è§†åŒ–å›¾ç‰‡ã€‚
        # ä¹‹å‰ç¡¬ç¼–ç ä¿å­˜åˆ° "output" ä¼šå¯¼è‡´å¤š PDF/å¤šé¡µç»“æœäº’ç›¸è¦†ç›–ï¼ˆä¾‹å¦‚ page_0001_res.png é‡å¤ï¼‰ã€‚
        # ä»…åœ¨æ˜¾å¼è®¾ç½®ç¯å¢ƒå˜é‡æ—¶ä¿å­˜ï¼Œä¾¿äºè°ƒè¯•ã€‚
        debug_save_dir = os.environ.get("PADDLEOCR_VL_DEBUG_SAVE_DIR", "").strip()
        if debug_save_dir:
            try:
                layout_det_result_obj.save_to_img(save_path=debug_save_dir)
            except Exception:
                pass
        
        return {
            "input_path": input_path,
            "page_index": page_index,
            "page_count": 1,
            "doc_preprocessor_image": doc_preprocessor_image,
            "doc_preprocessor_res": doc_preprocessor_res,
            "layout_det_results": [layout_det_res],
            "imgs_in_doc": [imgs_in_doc],
        }
    
    def _layout_detection(
        self,
        image: np.ndarray,
        threshold: Union[float, dict] = 0.5,
        layout_nms: bool = True,
        layout_unclip_ratio: Union[float, tuple] = None,
        layout_merge_bboxes_mode: str = None,
    ):
        """
        æ‰§è¡Œå¸ƒå±€æ£€æµ‹
        
        Args:
            image: è¾“å…¥å›¾åƒï¼ˆBGR æ ¼å¼ï¼‰
            threshold: æ£€æµ‹é˜ˆå€¼
            layout_nms: æ˜¯å¦ä½¿ç”¨ NMS
            layout_unclip_ratio: åæ ‡æ‰©å±•æ¯”ä¾‹
            layout_merge_bboxes_mode: å¸ƒå±€æ¡†åˆå¹¶æ¨¡å¼
        
        Returns:
            dict: å¸ƒå±€æ£€æµ‹ç»“æœ
        """
        orig_h, orig_w = image.shape[:2]
        
        # é¢„å¤„ç†
        input_blob, scale_h, scale_w = preprocess_image_doclayout(image)
        
        # å‡†å¤‡è¾“å…¥
        input_tensors = self.layout_compiled_model.inputs
        input_data = {}
        
        for inp in input_tensors:
            inp_name = inp.get_any_name()
            if inp_name == "im_shape":
                input_data[inp_name] = np.array([800, 800], dtype=np.float32)[np.newaxis, ...]
            elif inp_name == "image":
                input_data[inp_name] = input_blob
            elif inp_name == "scale_factor":
                input_data[inp_name] = np.array([[scale_h, scale_w]], dtype=np.float32)
        
        # å¦‚æœè¾“å…¥åç§°ä¸åŒ¹é…ï¼ŒæŒ‰é¡ºåºåˆ†é…
        if len(input_data) != len(input_tensors):
            input_data = {}
            input_data[input_tensors[0].get_any_name()] = np.array([800, 800], dtype=np.float32)[np.newaxis, ...]
            input_data[input_tensors[1].get_any_name()] = input_blob
            input_data[input_tensors[2].get_any_name()] = np.array([[scale_h, scale_w]], dtype=np.float32)
        
        # åˆ›å»º OpenVINO Tensor å¯¹è±¡
        input_tensors_ov = {}
        for inp in input_tensors:
            inp_name = inp.get_any_name()
            data = input_data[inp_name]
            input_tensors_ov[inp_name] = ov.Tensor(data)
        
        # æ‰§è¡Œæ¨ç†
        result = self.layout_compiled_model(input_tensors_ov)
        
        # æå–è¾“å‡ºç»“æœ
        output = []
        output_tensors = self.layout_compiled_model.outputs
        for out in output_tensors:
            output_tensor = result[out]
            output.append(output_tensor.data)
        
        # åå¤„ç†ï¼šæ ¹æ®è¾“å‡ºå½¢çŠ¶é€‰æ‹©åå¤„ç†å‡½æ•°
        out0 = np.array(output[0]) if len(output) > 0 else None
        out1 = np.array(output[1]) if len(output) > 1 else None
        if out0 is not None and out0.ndim == 2 and out0.shape[0] == 300 and out0.shape[1] in (6, 7) and out1 is not None and out1.size >= 1:
            # PaddleDetection exported (already NMS-ed) outputs
            boxes = postprocess_detections_paddle_nms(
                output,
                orig_h=orig_h,
                orig_w=orig_w,
                threshold=threshold,
                layout_nms=layout_nms,
                layout_unclip_ratio=layout_unclip_ratio,
                layout_merge_bboxes_mode=layout_merge_bboxes_mode,
            )
        else:
            # Fallback to DETR-style postprocess (older models)
            # Handle 3D arrays with batch dimension of 1: squeeze the first dimension
            if output[0].ndim == 3:
                output[0] = np.squeeze(output[0], axis=0)
            if len(output) > 1 and output[1].ndim == 3:
                output[1] = np.squeeze(output[1], axis=0)
            
        boxes = postprocess_detections_detr(
            output,
            scale_h,
            scale_w,
            orig_h,
            orig_w,
            threshold=threshold,
            layout_nms=layout_nms,
            layout_unclip_ratio=layout_unclip_ratio,
            layout_merge_bboxes_mode=layout_merge_bboxes_mode,
        )
        
        # è½¬æ¢ä¸ºç»“æœæ ¼å¼
        # postprocess_detections_detr å¯èƒ½è¿”å›å­—å…¸åˆ—è¡¨ï¼ˆrestructured_boxesï¼‰æˆ–ç©ºåˆ—è¡¨
        if len(boxes) == 0:
            layout_det_res = {
                "input_path": None,
                "page_index": None,
                "boxes": [],
            }
        elif isinstance(boxes[0], dict):
            # å¦‚æœå·²ç»æ˜¯å­—å…¸æ ¼å¼ï¼ˆrestructured_boxes è¿”å›çš„ï¼‰ï¼Œç›´æ¥ä½¿ç”¨
            layout_det_res = {
                "input_path": None,
                "page_index": None,
                "boxes": boxes,
            }
        else:
            # å¦‚æœæ˜¯ numpy æ•°ç»„æ ¼å¼ï¼Œè½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            layout_det_res = {
                "input_path": None,
                "page_index": None,
                "boxes": [
                    {
                        "cls_id": int(box[0]),
                        "label": self._get_label_name(int(box[0])),
                        "score": float(box[1]),
                        "coordinate": [float(box[2]), float(box[3]), float(box[4]), float(box[5])],
                    }
                    for box in boxes
                ],
            }
        
        return layout_det_res
    
    def _get_label_name(self, cls_id: int) -> str:
        """è·å–æ ‡ç­¾åç§°"""
        label_list = [
            "abstract", "algorithm", "aside_text", "chart", "content", "display_formula",
            "doc_title", "figure_title", "footer", "footer_image", "footnote", "formula_number",
            "header", "header_image", "image", "inline_formula", "number", "paragraph_title",
            "reference", "reference_content", "seal", "table", "text", "vertical_text", "vision_footnote"
        ]
        if 0 <= cls_id < len(label_list):
            return label_list[cls_id]
        return "unknown"
    
    def _process_vlm(
        self,
        results_cv: dict,
        max_new_tokens: Optional[int] = None,
    ):
        """
        å¤„ç†è§†è§‰è¯­è¨€æ¨¡å‹éƒ¨åˆ†ï¼ˆå¸ƒå±€è§£æï¼‰
        
        Args:
            results_cv: CV å¤„ç†ç»“æœ
            max_new_tokens: æœ€å¤§ç”Ÿæˆ token æ•°
        
        Returns:
            PaddleOCRVLResult: è§£æç»“æœå¯¹è±¡
        """
        (
            input_path,
            page_index,
            page_count,
            doc_preprocessor_image,
            doc_preprocessor_res,
            layout_det_results,
            imgs_in_doc,
        ) = (
            results_cv["input_path"],
            results_cv["page_index"],
            results_cv["page_count"],
            results_cv["doc_preprocessor_image"],
            results_cv["doc_preprocessor_res"],
            results_cv["layout_det_results"],
            results_cv["imgs_in_doc"],
        )
        
        # è·å–å¸ƒå±€è§£æç»“æœ
        parsing_res_lists, table_res_lists, imgs_in_doc = self.get_layout_parsing_results(
            [doc_preprocessor_image],
            layout_det_results,
            imgs_in_doc,
            max_new_tokens=max_new_tokens or 4096,
        )
        
        # ç»„è£…ç»“æœ
        parsing_res_list = parsing_res_lists[0] if parsing_res_lists else []
        table_res_list = table_res_lists[0] if table_res_lists else []
        
        single_img_res = {
            "input_path": input_path,
            "page_index": page_index,
            "page_count": page_count,
            "width": doc_preprocessor_image.shape[1],
            "height": doc_preprocessor_image.shape[0],
            "doc_preprocessor_res": doc_preprocessor_res,
            "layout_det_res": layout_det_results[0] if layout_det_results else None,
            "table_res_list": table_res_list,
            "parsing_res_list": parsing_res_list,
            "imgs_in_doc": imgs_in_doc[0] if imgs_in_doc else [],
            "model_settings": {
                "use_doc_preprocessor": False,
                "use_layout_detection": self.use_layout_detection,
                "use_chart_recognition": self.use_chart_recognition,
                "format_block_content": False,
                "merge_layout_blocks": self.merge_layout_blocks,
                "markdown_ignore_labels": self.markdown_ignore_labels,
            },
        }
        
        return PaddleOCRVLResult(single_img_res)
    
    def get_layout_parsing_results(
        self,
        images: List[np.ndarray],
        layout_det_results: List[dict],
        imgs_in_doc: List[List],
        max_new_tokens: int = 4096,
    ):
        """
        è·å–å¸ƒå±€è§£æç»“æœï¼ˆå‚è€ƒ PaddleX çš„å®ç°ï¼Œç¡®ä¿é€»è¾‘ä¸€è‡´ï¼‰
        
        Args:
            images: å›¾åƒåˆ—è¡¨
            layout_det_results: å¸ƒå±€æ£€æµ‹ç»“æœåˆ—è¡¨
            imgs_in_doc: æ–‡æ¡£ä¸­çš„å›¾åƒåˆ—è¡¨
            max_new_tokens: æœ€å¤§ç”Ÿæˆ token æ•°
        
        Returns:
            tuple: (parsing_res_lists, table_res_lists, imgs_in_doc)
        """
        blocks = []
        block_imgs = []
        text_prompts = []
        vlm_block_ids = []
        figure_token_maps = []
        drop_figures_set = set()  # å‚è€ƒ PaddleX ç¬¬ 239 è¡Œ
        
        image_labels = ["image", "header_image", "footer_image", "seal"]
        if not self.use_chart_recognition:
            image_labels.append("chart")
        
        for i, (image, layout_det_res, imgs_in_doc_for_img) in enumerate(
            zip(images, layout_det_results, imgs_in_doc)
        ):
            boxes = layout_det_res["boxes"]
            
            # è£å‰ªå›¾åƒåŒºåŸŸ
            blocks_for_img = self._crop_by_boxes(image, boxes)
            
            # åˆå¹¶å¸ƒå±€å—ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if self.merge_layout_blocks:
                blocks_for_img = self._merge_blocks(
                    blocks_for_img, non_merge_labels=image_labels + ["table"]
                )
            
            blocks.append(blocks_for_img)
            
            # å‡†å¤‡ VLM è¾“å…¥ï¼ˆå‚è€ƒ PaddleX ç¬¬ 254-277 è¡Œï¼‰
            for j, block in enumerate(blocks_for_img):
                block_img = block["img"]
                block_label = block["label"]
                
                if block_label not in image_labels and block_img is not None:
                    figure_token_map = {}
                    text_prompt = "OCR:"
                    drop_figures = []
                    
                    if block_label == "table":
                        text_prompt = "Table Recognition:"
                        # å¯¹äº tableï¼Œéœ€è¦å¤„ç†è¡¨æ ¼ä¸­çš„å›¾ç‰‡ï¼ˆå‚è€ƒ PaddleX ç¬¬ 261-267 è¡Œï¼‰
                        try:
                            from ..paddleocr_vl.uilts import (
                                tokenize_figure_of_table,
                            )
                            block_img, figure_token_map, drop_figures = (
                                tokenize_figure_of_table(
                                    block_img, block["box"], imgs_in_doc_for_img
                                )
                            )
                        except ImportError:
                            # å¦‚æœæ— æ³•å¯¼å…¥ï¼Œä½¿ç”¨ç©ºå®ç°
                            pass
                    elif block_label == "chart" and self.use_chart_recognition:
                        text_prompt = "Chart Recognition:"
                    elif "formula" in block_label and block_label != "formula_number":
                        text_prompt = "Formula Recognition:"
                        # å¯¹äº formulaï¼Œè£å‰ªè¾¹è·ï¼ˆå‚è€ƒ PaddleX ç¬¬ 272 è¡Œï¼‰
                        try:
                            from ..paddleocr_vl.uilts import (
                                crop_margin,
                            )
                            block_img = crop_margin(block_img)
                        except ImportError:
                            # å¦‚æœæ— æ³•å¯¼å…¥ï¼Œè·³è¿‡è£å‰ª
                            pass
                    
                    block_imgs.append(block_img)
                    text_prompts.append(text_prompt)
                    figure_token_maps.append(figure_token_map)
                    vlm_block_ids.append((i, j))
                    drop_figures_set.update(drop_figures)  # å‚è€ƒ PaddleX ç¬¬ 277 è¡Œ
        
        # æ‰“å° image å¤§å°ã€label å’Œ queryï¼ˆå‚è€ƒ pipeline.pyï¼‰
        for idx, (block_img, text_prompt, (i, j)) in enumerate(zip(block_imgs, text_prompts, vlm_block_ids)):
            block_label = blocks[i][j]["label"]
            if hasattr(block_img, 'shape'):
                img_size = block_img.shape
            elif hasattr(block_img, 'size'):
                img_size = block_img.size
            else:
                img_size = "unknown"
            # print(f"[VLM Input {idx}] Image size: {img_size}, Label: {block_label}, Query: {text_prompt}")
        
        # VLM æ¨ç†
        if block_imgs:
            vl_rec_results = self._vlm_predict(
                block_imgs,
                text_prompts,
                max_new_tokens=max_new_tokens,
            )
        else:
            vl_rec_results = []
        
        # ç»„è£…è§£æç»“æœ
        parsing_res_lists = []
        table_res_lists = []
        curr_vlm_block_idx = 0
        
        for i, blocks_for_img in enumerate(blocks):
            parsing_res_list = []
            table_res_list = []
            
            for j, block in enumerate(blocks_for_img):
                block_img = block["img"]
                block_bbox = block["box"]
                block_label = block["label"]
                block_content = ""
                
                if curr_vlm_block_idx < len(vlm_block_ids) and vlm_block_ids[curr_vlm_block_idx] == (i, j):
                    vl_rec_result = vl_rec_results[curr_vlm_block_idx]
                    figure_token_map = figure_token_maps[curr_vlm_block_idx]
                    block_img4vl = block_imgs[curr_vlm_block_idx]
                    curr_vlm_block_idx += 1
                    vl_rec_result["image"] = block_img4vl  # å‚è€ƒ PaddleX ç¬¬ 333 è¡Œ
                    result_str = vl_rec_result.get("result", "")
                    if result_str is None:
                        result_str = ""
                    
                    # å¤„ç†é‡å¤å†…å®¹ï¼ˆå‚è€ƒ PaddleX ç¬¬ 337 è¡Œï¼‰
                    try:
                        from ..paddleocr_vl.uilts import (
                            truncate_repetitive_content,
                        )
                        result_str = truncate_repetitive_content(result_str)
                    except ImportError:
                        pass
                    
                    # å¤„ç†å…¬å¼æ ¼å¼ï¼ˆå‚è€ƒ PaddleX ç¬¬ 338-350 è¡Œï¼‰
                    if ("\\(" in result_str and "\\)" in result_str) or (
                        "\\[" in result_str and "\\]" in result_str
                    ):
                        result_str = result_str.replace("$", "")
                        result_str = (
                            result_str.replace("\\(", " $ ")
                            .replace("\\)", " $ ")
                            .replace("\\[", " $$ ")
                            .replace("\\]", " $$ ")
                        )
                        if block_label == "formula_number":
                            result_str = result_str.replace("$", "")
                    
                    # ä¿®å¤ LaTeX è¯­æ³•é”™è¯¯ï¼ˆä¿®å¤ \inS, \inR ç­‰å¸¸è§é”™è¯¯ï¼‰
                    result_str = fix_latex_syntax(result_str)
                    
                    # å¤„ç†è¡¨æ ¼ï¼ˆå‚è€ƒ PaddleX ç¬¬ 351-357 è¡Œï¼‰
                    if block_label == "table":
                        try:
                            from ..paddleocr_vl.uilts import (
                                convert_otsl_to_html,
                                untokenize_figure_of_table,
                            )
                            html_str = convert_otsl_to_html(result_str)
                            if html_str != "":
                                result_str = html_str
                            result_str = untokenize_figure_of_table(
                                result_str, figure_token_map
                            )
                        except ImportError:
                            pass
                    
                    block_content = result_str
                
                block_info = PaddleOCRVLBlock(
                    label=block_label,
                    bbox=block_bbox,
                    content=block_content,
                    group_id=block.get("group_id", None),
                )
                
                # è®¾ç½®å›¾ç‰‡ä¿¡æ¯ï¼ˆå‚è€ƒ PaddleX çš„å®ç°ï¼Œç¬¬ 367-379 è¡Œï¼‰
                # å½“ block_label åœ¨ image_labels ä¸­ä¸” block_img ä¸ä¸º None æ—¶ï¼Œè®¾ç½® block_info.image
                image_labels = ["image", "header_image", "footer_image", "seal"]
                if not self.use_chart_recognition:
                    image_labels.append("chart")
                
                if block_label in image_labels and block_img is not None:
                    x_min, y_min, x_max, y_max = list(map(int, block_bbox))
                    img_path = f"imgs/img_in_{block_label}_box_{x_min}_{y_min}_{x_max}_{y_max}.jpg"
                    # å¦‚æœå›¾ç‰‡åœ¨ drop_figures_set ä¸­ï¼Œè·³è¿‡è¿™ä¸ª blockï¼ˆå‚è€ƒ PaddleX ç¬¬ 370-379 è¡Œï¼‰
                    if img_path not in drop_figures_set:
                        # è½¬æ¢ BGR åˆ° RGBï¼ˆå¦‚æœ block_img æ˜¯ NumPy æ•°ç»„ï¼‰
                        if isinstance(block_img, np.ndarray):
                            block_img_rgb = cv2.cvtColor(block_img, cv2.COLOR_BGR2RGB)
                            block_info.image = {
                                "path": img_path,
                                "img": Image.fromarray(block_img_rgb),
                            }
                        elif isinstance(block_img, Image.Image):
                            block_info.image = {
                                "path": img_path,
                                "img": block_img,
                            }
                    else:
                        # å¦‚æœå›¾ç‰‡åœ¨ drop_figures_set ä¸­ï¼Œè·³è¿‡è¿™ä¸ª blockï¼ˆå‚è€ƒ PaddleX ç¬¬ 379 è¡Œï¼‰
                        continue
                
                parsing_res_list.append(block_info)
            
            parsing_res_lists.append(parsing_res_list)
            table_res_lists.append(table_res_list)
        
        return parsing_res_lists, table_res_lists, imgs_in_doc
    
    def _vlm_predict(
        self,
        block_imgs: List[np.ndarray],
        text_prompts: List[str],
        max_new_tokens: int = 4096,
    ):
        """
        ä½¿ç”¨ VLM æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼ˆå‚è€ƒ torch_ov_test.py çš„ OpenVINO æ¨ç†æ–¹å¼ï¼‰
        
        Args:
            block_imgs: å›¾åƒå—åˆ—è¡¨
            text_prompts: æ–‡æœ¬æç¤ºåˆ—è¡¨
            max_new_tokens: æœ€å¤§ç”Ÿæˆ token æ•°
        
        Returns:
            list: VLM é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        results = []
        
        # å‡†å¤‡ generation_config
        generation_config = {
            "bos_token_id": self.vlm_model.tokenizer.bos_token_id,
            "eos_token_id": self.vlm_model.tokenizer.eos_token_id,
            "pad_token_id": self.vlm_model.tokenizer.pad_token_id,
            "max_new_tokens": max_new_tokens,
            "do_sample": False,
        }
        
        for idx, (block_img, text_prompt) in enumerate(zip(block_imgs, text_prompts)):
            # è½¬æ¢å›¾åƒæ ¼å¼
            if isinstance(block_img, np.ndarray):
                if len(block_img.shape) == 2:
                    block_img = cv2.cvtColor(block_img, cv2.COLOR_GRAY2RGB)
                elif block_img.shape[2] == 3:
                    block_img = cv2.cvtColor(block_img, cv2.COLOR_BGR2RGB)
                pil_image = Image.fromarray(block_img)
            else:
                pil_image = block_img
            
            # # ä¿å­˜ pil_image ä¸ºå›¾ç‰‡
            # import os
            # output_dir = "output"
            # os.makedirs(output_dir, exist_ok=True)
            # save_path = os.path.join(output_dir, f"pil_image_{idx}.png")
            # pil_image.save(save_path)
            # print(f"Saved pil_image to: {save_path}")
            # # breakpoint()

            pil_image = pil_image.resize((1200, 800), Image.Resampling.LANCZOS)
            
            # å‡†å¤‡è¾“å…¥æ¶ˆæ¯ï¼ˆä¸ torch_ov_test.py ä¸€è‡´ï¼‰
            messages = [
                {
                    "role": "user",
                    "content": [
                        {"type": "image", "image": pil_image},
                        {"type": "text", "text": text_prompt},
                    ]
                }
            ]
            
            try:
                # ä½¿ç”¨ chat æ–¹æ³•è¿›è¡Œæ¨ç†ï¼ˆä¸ torch_ov_test.py ä¸€è‡´ï¼‰
                response, history = self.vlm_model.chat(
                    messages=messages,
                    generation_config=generation_config
                )
                result_str = response
            except Exception as e:
                # å¦‚æœ VLM æ¨ç†å¤±è´¥ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
                print(f"Warning: VLM inference failed: {e}")
                result_str = ""
            
            # print("result_str: ", result_str)
            results.append({"result": result_str})
        
        return results
    
    def _crop_by_boxes(self, image: np.ndarray, boxes: List[dict]) -> List[dict]:
        """
        æ ¹æ®æ¡†è£å‰ªå›¾åƒ
        
        Args:
            image: è¾“å…¥å›¾åƒ
            boxes: æ¡†åˆ—è¡¨
        
        Returns:
            list: è£å‰ªåçš„å›¾åƒå—åˆ—è¡¨
        """
        blocks = []
        h, w = image.shape[:2]
        
        for box in boxes:
            coordinate = box["coordinate"]
            xmin, ymin, xmax, ymax = map(int, coordinate)
            
            # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
            xmin = max(0, min(xmin, w))
            ymin = max(0, min(ymin, h))
            xmax = max(xmin, min(xmax, w))
            ymax = max(ymin, min(ymax, h))
            
            if xmax > xmin and ymax > ymin:
                cropped = image[ymin:ymax, xmin:xmax].copy()
                blocks.append({
                    "img": cropped,
                    "label": box["label"],
                    "box": [xmin, ymin, xmax, ymax],
                    "score": box["score"],
                })
        
        return blocks
    
    def _filter_overlap_boxes(self, layout_det_res: dict) -> dict:
        """
        è¿‡æ»¤é‡å æ¡†ï¼ˆå®Œæ•´å®ç°ï¼Œä¸ PaddleX åŠŸèƒ½ä¸€è‡´ï¼‰
        
        Args:
            layout_det_res: å¸ƒå±€æ£€æµ‹ç»“æœ
        
        Returns:
            dict: è¿‡æ»¤åçš„å¸ƒå±€æ£€æµ‹ç»“æœ
        """
        from copy import deepcopy
        
        # è¾…åŠ©å‡½æ•°ï¼šè®¡ç®—è¾¹ç•Œæ¡†é¢ç§¯
        def calculate_bbox_area(bbox):
            x1, y1, x2, y2 = map(float, bbox)
            area = abs((x2 - x1) * (y2 - y1))
            return area
        
        # è¾…åŠ©å‡½æ•°ï¼šè®¡ç®—é‡å æ¯”ä¾‹ï¼ˆä½¿ç”¨ small æ¨¡å¼ï¼‰
        def calculate_overlap_ratio(bbox1, bbox2):
            x_min_inter = max(bbox1[0], bbox2[0])
            y_min_inter = max(bbox1[1], bbox2[1])
            x_max_inter = min(bbox1[2], bbox2[2])
            y_max_inter = min(bbox1[3], bbox2[3])
            inter_width = max(0, x_max_inter - x_min_inter)
            inter_height = max(0, y_max_inter - y_min_inter)
            inter_area = inter_width * inter_height
            bbox1_area = calculate_bbox_area(bbox1)
            bbox2_area = calculate_bbox_area(bbox2)
            # ä½¿ç”¨ small æ¨¡å¼ï¼šå–ä¸¤ä¸ªæ¡†é¢ç§¯çš„æœ€å°å€¼ä½œä¸ºå‚è€ƒ
            ref_area = min(bbox1_area, bbox2_area)
            return inter_area / ref_area if ref_area > 0 else 0.0
        
        layout_det_res_filtered = deepcopy(layout_det_res)
        
        # æ’é™¤ reference æ ‡ç­¾çš„æ¡†
        boxes = [
            box for box in layout_det_res_filtered["boxes"] if box["label"] != "reference"
        ]
        dropped_indexes = set()
        
        # éå†æ‰€æœ‰æ¡†å¯¹ï¼Œæ£€æŸ¥é‡å 
        for i in range(len(boxes)):
            for j in range(i + 1, len(boxes)):
                if i in dropped_indexes or j in dropped_indexes:
                    continue
                
                overlap_ratio = calculate_overlap_ratio(
                    boxes[i]["coordinate"], boxes[j]["coordinate"]
                )
                
                # å¦‚æœé‡å æ¯”ä¾‹ > 0.7ï¼Œéœ€è¦å¤„ç†
                if overlap_ratio > 0.7:
                    box_area_i = calculate_bbox_area(boxes[i]["coordinate"])
                    box_area_j = calculate_bbox_area(boxes[j]["coordinate"])
                    
                    # ç‰¹æ®Šæƒ…å†µï¼šå¦‚æœä¸€ä¸ªæ˜¯ image æ ‡ç­¾ï¼Œå¦ä¸€ä¸ªä¸æ˜¯ï¼Œåˆ™è·³è¿‡
                    if (
                        (boxes[i]["label"] == "image" or boxes[j]["label"] == "image")
                        and boxes[i]["label"] != boxes[j]["label"]
                    ):
                        continue
                    
                    # ä¿ç•™é¢ç§¯è¾ƒå¤§çš„æ¡†ï¼Œä¸¢å¼ƒé¢ç§¯è¾ƒå°çš„æ¡†
                    if box_area_i >= box_area_j:
                        dropped_indexes.add(j)
                    else:
                        dropped_indexes.add(i)
        
        # è¿‡æ»¤æ‰è¢«æ ‡è®°ä¸ºä¸¢å¼ƒçš„æ¡†
        layout_det_res_filtered["boxes"] = [
            box for idx, box in enumerate(boxes) if idx not in dropped_indexes
        ]
        
        return layout_det_res_filtered
    
    def _merge_blocks(self, blocks: List[dict], non_merge_labels: List[str]) -> List[dict]:
        """
        åˆå¹¶å¸ƒå±€å—
        å‚è€ƒ PaddleX çš„ merge_blocks å®ç°ï¼Œç¡®ä¿åŠŸèƒ½å®Œå…¨ä¸€è‡´
        
        Args:
            blocks: å›¾åƒå—åˆ—è¡¨
            non_merge_labels: ä¸åˆå¹¶çš„æ ‡ç­¾åˆ—è¡¨
        
        Returns:
            list: åˆå¹¶åçš„å›¾åƒå—åˆ—è¡¨
        """
        # åˆ†ç¦»éœ€è¦åˆå¹¶å’Œä¸éœ€è¦åˆå¹¶çš„å—
        blocks_to_merge = []
        non_merge_blocks = {}
        for idx, block in enumerate(blocks):
            if block["label"] in non_merge_labels:
                non_merge_blocks[idx] = block
            else:
                blocks_to_merge.append((idx, block))

        merged_groups = []
        current_group = []
        current_indices = []
        current_aligns = []

        def is_aligned(a1, a2):
            return abs(a1 - a2) <= 5

        def get_alignment(block_bbox, prev_bbox):
            if is_aligned(block_bbox[0], prev_bbox[0]):
                return "left"
            elif is_aligned(block_bbox[2], prev_bbox[2]):
                return "right"
            else:
                return "center"

        def overlapwith_other_box(block_idx, prev_idx, blocks):
            prev_bbox = blocks[prev_idx]["box"]
            block_bbox = blocks[block_idx]["box"]
            x1 = min(prev_bbox[0], block_bbox[0])
            y1 = min(prev_bbox[1], block_bbox[1])
            x2 = max(prev_bbox[2], block_bbox[2])
            y2 = max(prev_bbox[3], block_bbox[3])
            min_box = [x1, y1, x2, y2]
            for idx, other_block in enumerate(blocks):
                if idx in [block_idx, prev_idx]:
                    continue
                other_bbox = other_block["box"]
                if self._calculate_overlap_ratio(min_box, other_bbox) > 0:
                    return True
            return False

        for i, (idx, block) in enumerate(blocks_to_merge):
            if not current_group:
                current_group = [block]
                current_indices = [idx]
                current_aligns = []
                continue

            prev_idx, prev_block = blocks_to_merge[i - 1]
            prev_bbox = prev_block["box"]
            prev_label = prev_block["label"]
            block_bbox = block["box"]
            block_label = block["label"]

            iou_h = self._calculate_projection_overlap_ratio(block_bbox, prev_bbox, "horizontal")
            is_cross = (
                iou_h == 0
                and block_label == "text"
                and block_label == prev_label
                and block_bbox[0] > prev_bbox[2]
                and block_bbox[1] < prev_bbox[3]
                and block_bbox[0] - prev_bbox[2]
                < max(prev_bbox[2] - prev_bbox[0], block_bbox[2] - block_bbox[0]) * 0.3
            )
            is_updown_align = (
                iou_h > 0
                and block_label in ["text"]
                and block_label == prev_label
                and block_bbox[3] >= prev_bbox[1]
                and abs(block_bbox[1] - prev_bbox[3])
                < max(prev_bbox[3] - prev_bbox[1], block_bbox[3] - block_bbox[1]) * 0.5
                and (
                    is_aligned(block_bbox[0], prev_bbox[0])
                    ^ is_aligned(block_bbox[2], prev_bbox[2])
                )
                and overlapwith_other_box(idx, prev_idx, blocks)
            )
            if is_cross:
                align_mode = "center"
            elif is_updown_align:
                align_mode = get_alignment(block_bbox, prev_bbox)
            else:
                align_mode = None

            if is_cross or is_updown_align:
                current_group.append(block)
                current_indices.append(idx)
                current_aligns.append(align_mode)
            else:
                merged_groups.append((current_indices, current_aligns))
                current_group = [block]
                current_indices = [idx]
                current_aligns = []
        if current_group:
            merged_groups.append((current_indices, current_aligns))

        group_ranges = []
        for group_indices, aligns in merged_groups:
            start, end = min(group_indices), max(group_indices)
            group_ranges.append((start, end, group_indices, aligns))

        result_blocks = []
        used_indices = set()
        idx = 0
        while idx < len(blocks):
            group_found = False
            for start, end, group_indices, aligns in group_ranges:
                if idx == start and all(i not in used_indices for i in group_indices):
                    group_found = True
                    imgs = [blocks[i]["img"] for i in group_indices]
                    merge_aligns = aligns if aligns else []
                    w, h = self._calc_merged_wh(imgs)
                    aspect_ratio = h / w if w != 0 else float("inf")
                    if aspect_ratio >= 3:
                        for j, block_idx in enumerate(group_indices):
                            block = blocks[block_idx].copy()
                            block["img"] = blocks[block_idx]["img"]
                            block["merge_aligns"] = None
                            result_blocks.append(block)
                            used_indices.add(block_idx)
                    else:
                        merged_img = self._merge_images(imgs, merge_aligns)
                        for j, block_idx in enumerate(group_indices):
                            block = blocks[block_idx].copy()
                            block["img"] = merged_img if j == 0 else None
                            block["merge_aligns"] = merge_aligns if j == 0 else None
                            block["group_id"] = group_indices[0]
                            result_blocks.append(block)
                            used_indices.add(block_idx)
                    insert_list = []
                    for n_idx in range(start + 1, end):
                        if n_idx in non_merge_blocks:
                            insert_list.append(n_idx)
                    for n_idx in insert_list:
                        result_blocks.append(non_merge_blocks[n_idx])
                        used_indices.add(n_idx)
                    idx = end + 1
                    break
            if group_found:
                continue
            if idx in non_merge_blocks and idx not in used_indices:
                result_blocks.append(non_merge_blocks[idx])
                used_indices.add(idx)
            idx += 1
        return result_blocks
    
    def _calculate_projection_overlap_ratio(self, bbox1, bbox2, direction="horizontal"):
        """è®¡ç®—æŠ•å½±é‡å æ¯”ä¾‹ï¼ˆå‚è€ƒ PaddleXï¼‰"""
        start_index, end_index = (1, 3) if direction == "vertical" else (0, 2)
        intersection_start = max(bbox1[start_index], bbox2[start_index])
        intersection_end = min(bbox1[end_index], bbox2[end_index])
        overlap = intersection_end - intersection_start
        if overlap <= 0:
            return 0
        ref_width = max(bbox1[end_index], bbox2[end_index]) - min(
            bbox1[start_index], bbox2[start_index]
        )
        return overlap / ref_width if ref_width > 0 else 0.0
    
    def _calculate_overlap_ratio(self, bbox1, bbox2, mode="union"):
        """è®¡ç®—é‡å æ¯”ä¾‹ï¼ˆå‚è€ƒ PaddleXï¼‰"""
        bbox1 = np.array(bbox1)
        bbox2 = np.array(bbox2)

        x_min_inter = np.maximum(bbox1[0], bbox2[0])
        y_min_inter = np.maximum(bbox1[1], bbox2[1])
        x_max_inter = np.minimum(bbox1[2], bbox2[2])
        y_max_inter = np.minimum(bbox1[3], bbox2[3])

        inter_width = np.maximum(0, x_max_inter - x_min_inter)
        inter_height = np.maximum(0, y_max_inter - y_min_inter)

        inter_area = inter_width * inter_height

        bbox1_area = (bbox1[2] - bbox1[0]) * (bbox1[3] - bbox1[1])
        bbox2_area = (bbox2[2] - bbox2[0]) * (bbox2[3] - bbox2[1])

        if mode == "union":
            ref_area = bbox1_area + bbox2_area - inter_area
        elif mode == "small":
            ref_area = np.minimum(bbox1_area, bbox2_area)
        elif mode == "large":
            ref_area = np.maximum(bbox1_area, bbox2_area)
        else:
            raise ValueError(
                f"Invalid mode {mode}, must be one of ['union', 'small', 'large']."
            )

        if ref_area == 0:
            return 0.0

        return inter_area / ref_area
    
    def _to_pil_image(self, img):
        """è½¬æ¢ä¸º PIL Image"""
        if isinstance(img, Image.Image):
            return img
        return Image.fromarray(img)
    
    def _to_np_array(self, img):
        """è½¬æ¢ä¸º numpy array"""
        if isinstance(img, Image.Image):
            return np.array(img)
        return img
    
    def _calc_merged_wh(self, images):
        """è®¡ç®—åˆå¹¶åçš„å®½é«˜ï¼ˆå‚è€ƒ PaddleXï¼‰"""
        widths = [self._to_pil_image(img).width for img in images]
        heights = [self._to_pil_image(img).height for img in images]
        w = max(widths)
        h = sum(heights)
        return w, h
    
    def _merge_images(self, images, aligns="center"):
        """åˆå¹¶å›¾åƒï¼ˆå‚è€ƒ PaddleXï¼‰"""
        if not images:
            return None
        if len(images) == 1:
            return self._to_np_array(images[0])
        if isinstance(aligns, str):
            aligns = [aligns] * (len(images) - 1)
        if len(aligns) != len(images) - 1:
            raise ValueError("The length of aligns must be len(images) - 1")
        merged = self._to_pil_image(images[0])
        for i in range(1, len(images)):
            img2 = self._to_pil_image(images[i])
            align = aligns[i - 1]
            w = max(merged.width, img2.width)
            h = merged.height + img2.height
            new_img = Image.new("RGB", (w, h), (255, 255, 255))
            if align == "center":
                x1 = (w - merged.width) // 2
                x2 = (w - img2.width) // 2
            elif align == "right":
                x1 = w - merged.width
                x2 = w - img2.width
            else:  # left
                x1 = x2 = 0
            new_img.paste(merged, (x1, 0))
            new_img.paste(img2, (x2, merged.height))
            merged = new_img
        return self._to_np_array(merged)
    
    def close(self):
        """
        å…³é—­æ¨¡å‹ï¼Œå°½å¯èƒ½é‡Šæ”¾ OpenVINO / VLM ç›¸å…³èµ„æºã€‚
        """
        # VLM
        try:
            vlm = getattr(self, "vlm_model", None)
            if vlm is not None:
                for m in ("close", "release"):
                    fn = getattr(vlm, m, None)
                    if callable(fn):
                        try:
                            fn()
                        except Exception:
                            pass
                        break
        except Exception:
            pass
        try:
            self.vlm_model = None
        except Exception:
            pass

        # Layout (optional)
        for name in ("layout_request", "layout_compiled_model"):
            try:
                obj = getattr(self, name, None)
                if obj is not None:
                    for m in ("close", "release"):
                        fn = getattr(obj, m, None)
                        if callable(fn):
                            try:
                                fn()
                            except Exception:
                                pass
                            break
            except Exception:
                pass
            try:
                setattr(self, name, None)
            except Exception:
                pass

        try:
            self.core = None
        except Exception:
            pass

